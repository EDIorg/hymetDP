[{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, gender identity expression, level experience, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best community Showing empathy towards community members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://EDIorg.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within project spaces public spaces individual representing project community. Examples representing project community include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team info@edirepository.org. project team review investigate complaints, respond way deems appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 1.4, available http://contributor-covenant.org/version/1/4","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"git-structure","dir":"","previous_headings":"","what":"Git structure","title":"Contributing Guidelines","text":"active branch development. development merged master releases. Please submit pull requests development.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"repository-structure","dir":"","previous_headings":"","what":"Repository structure","title":"Contributing Guidelines","text":"repository structured standard R package following conventions outlined R Packages book. additional files provided part built R package listed .Rbuildignore.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"code","dir":"","previous_headings":"","what":"Code","title":"Contributing Guidelines","text":"code package found R/. functions thoroughly documented roxygen2 notation; see Documentation. Code conform tidyverse Style guide.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"Contributing Guidelines","text":"new feature bug-fix include unit-test demonstrating change. Unit tests follow testthat framework files tests/testthat. Please make sure testing suite passes issuing pull request. can done running check() devtools package, also check consistent documentation, etc.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Contributing Guidelines","text":"function documentation generated automatically. Please edit documentation files man/ NAMESPACE. Instead, construct appropriate roxygen2 documentation function files R/ . documentation generated running devtools::document() function. Please consult R Packages book workflow unfamiliar . Note functions include examples documentation. Please use \\dontrun examples take seconds. Similarly, .md files base directory edited directly. Instead, edit .Rmd source files.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"dependencies","dir":"","previous_headings":"","what":"Dependencies","title":"Contributing Guidelines","text":"package already contains large number dependencies (imports suggests). Therefore, new packages added creating new features reasonably achieved within existing set dependencies.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"general-development-goals--guidelines","dir":"","previous_headings":"","what":"General Development Goals & Guidelines","title":"Contributing Guidelines","text":"Contribute code create, use, convert hymetDP datasets. Maintain consistent user-facing API.","code":""},{"path":"https://EDIorg.github.io/hymetDP/CONTRIBUTING.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributing Guidelines","text":"contributing guidelines based rOpenSci emld project.","code":""},{"path":"https://EDIorg.github.io/hymetDP/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 hymetDP authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/articles/create.html","id":"example-function","dir":"Articles","previous_headings":"For archive in a data repository","what":"Example function:","title":"Create hymetDP Data","text":"","code":"# ----------------------------------------------------------------------------- # This function converts source dataset \"knb-lter-mcm.9003\" (archived in the EDI # Data Repository) to hymetDP dataset \"edi.10101\" #  # Arguments: # # path        Where the hymetDP tables will be written # source_id   Identifier of the source dataset # derived_id  Identifier of the derived dataset # url         The URL by which the derived tables and metadata can be accessed  #             by a data repository. This argument is used when automating the  #             repository publication step, but not used when manually  #             publishing. # # Value: # # tables      (.csv) hymetDP tables # metadata    (.xml) EML metadata for tables #  # Details: #             This function facilitates automated updates to the derived  #             \"edi.10101\" whenever new data are added to the source  #             \"knb-lter-mcm.9003\". The framework executing this maintenance  #             routine is hosted on a remote server and jumps into action  #             whenever an update notification is received for  #             \"knb-lter-mcm.9003\". The maintenance routine parses the  #             notification to get the arguments to create_hymetDP(). # # Landing page to source dataset \"knb-lter-mcm.9003\": # https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-mcm&identifier=9003 # Landing page to derived dataset \"edi.10101\": # https://portal.edirepository.org/nis/mapbrowse?scope=edi&identifier=10101 # ----------------------------------------------------------------------------- # Libraries used by this function  library(hymetDP) library(EDIutils) library(magrittr) library(dplyr) library(tidyr) library(lubridate) library(xml2) library(lutz)  create_hymetDP <- function(path = NULL,                                  source_id = 'knb-lter-mcm.9003.11',                                  derived_id = 'edi.10101.1',                                  url = NULL) {    # Read source dataset -------------------------------------------------    # The source dataset contains seasonal high-frequency measurements of   # discharge, water temperature, and specific conductivity from a site in   # Antarctica. The dataset consists of a data table containing internal codes,   # datetimes, measurements, meaurement quality flags, and general comments.    # Once the table is read in using the `read_tables()`, any missing values    # will automatically be converted to `NA`, and columns for units will be added      eml <- read_metadata(source_id)    tables <- read_tables(     eml = eml,     strip.white = TRUE,     na.strings = \"\",     convert.missing.value = TRUE,     add.units = TRUE)    # Join and flatten the source dataset ---------------------------------------    # Joining all source data and relevant metadata into one big flat table    # simplifies parsing into hymetDP tables and facilitates referential    # integrity in the process.   #   # The first step towards creating our \"flat\" table is to create a wide table   # that consists of all relevant tables from the dataset. Since our dataset   # only contains a single table, nothing special needs to happen to create the   # preliminary wide table      wide <- tables$`mcmlter-strm-h1_andersen-15min-20210303.csv`      # Before we transform our \"wide\" table into a \"flat\" table, we should add a   # few columns, drop the ones we won't need, and make a few other changes that   # are easier to implement to the wide table:    # Specify timezone/offset      # Convert the datetime column to the ISO-8601 format, assign the timezone and   # UTCoffset, and create the hymetDP required date columns    wide$LocalDateTime <- wide$DATE_TIME %>% strptime(format = \"%m/%d/%y %H:%M\", tz = \"Antarctica/McMurdo\") %>% as.character() %>% lubridate::as_datetime(tz = \"Antarctica/McMurdo\")    wide$UTCOffset <- lutz::tz_offset(wide$LocalDateTime, \"Antarctica/McMurdo\")$utc_offset_h    wide$DateTimeUTC <- lubridate::with_tz(wide$LocalDateTime, \"Etc/UTC\")    # Remove columns that will not be used in the final hymetDP tables      wide <- wide %>%     dplyr::select(       -DATASET_CODE,       -STRMGAGEID,       -DATE_TIME,       -COMMENTS)      # Flatten ----------------------------------------------------------------    # Convert wide format to \"flat\" format. This is the wide form but gathered on    # core observation variables, which are often > 1 in source datasets. This    # \"flat\" table is the \"widest\" hymetDP datasets can be consistently returned    # to by the hymetDP::flatten_data() function, and is the input format    # required by the \"create table\" helpers we'll meet shortly.   #   # To make the transition from wide to flat, we need to rename columns to   # follow the scheme \"columnType.columnValue\". The unique columnTypes will   # become the names of new columns containing the columnValues. The   # columnValues will in turn be associated with their original values in the   # value column.      wide <- wide %>%     dplyr::rename_with(       ~paste0(\"DataValue.\", .),       .cols = c(\"DSCHRGE_RATE\",\"WATER_TEMP\",\"CONDUCTIVITY\"))    wide <- wide %>%     dplyr::rename(       Qualifier.DSCHRGE_RATE = DSCHRGE_QLTY,       Qualifier.WATER_TEMP = WATER_TEMP_QLTY,       Qualifier.CONDUCTIVITY = CONDUCTIVITY_QLTY,       unit.DSCHRGE_RATE = unit_DSCHRGE_RATE,       unit.WATER_TEMP = unit_WATER_TEMP,       unit.CONDUCTIVITY = unit_CONDUCTIVITY)    flat <- tidyr::pivot_longer(     wide,     cols = dplyr::matches(c(\"DSCHRGE\", \"WATER_TEMP\", \"CONDUCTIVITY\")),     names_to = c(\".value\", \"variable_name\"),     names_sep = \"\\\\.\")    # We're now in a good place to begin adding columns of the hymetDP tables we   # can create from this source dataset. We'll begin with the DataValues table.      # Add columns for the data values table -----------------------------------    # Every row of the flat table represents a single data value in the hymetDP   # model. We assign a unique, integer ValueID to every entry:      flat$ValueID <- seq(nrow(flat))    # Assign variable code, define variable code function ---------------------    # We need to create the entries for the Variables table. These will be added   # as columns to the flat table. To do this, we can take advantage of   # `define_variable()`, which gives us a convenient way to specify a variable   # by its name as it is listed in the flat table (i.e. \"DSCHRGE_RATE\").   #   # By specifying that we are working with the values \"DSCHRGE_RATE\" in the    # column \"variable_name\" from the flat table, `define_variable()` will   # handle assigning unique VariableCodes and joining the provided information   # to its correct place in the flat table.    #   # For fields that require an ODM Controlled Vocabulary term, use the *CV   # objects to find fitting terms. If a non-supported term is given,    # `define_variable()` will throw a warning (and occasionally a hint).      # Define variables using the ODM Controlled vocabularies    # View(VariableNameCV)              # variable_name   # View(UnitsCV)                     # variable_units and time_units   # View(SampleMediumCV)              # sample_medium   # View(ValueTypeCV)                 # value_type   # View(DataTypeCV)                  # data_type   # View(GeneralCategoryCV)           # general_category    flat <- hymetDP::define_variable(     L0_flat = flat,     local_variable_column = \"variable_name\",     local_variable = \"DSCHRGE_RATE\",     variable_name = \"Discharge\",     variable_units = \"liters per second\",     sample_medium = \"Surface water\",     value_type = \"Derived Value\",     is_regular = TRUE,     time_support = 15,     time_units = \"minute\",     data_type = \"Continuous\",     general_category = \"Hydrology\",     no_data = -9999)    flat <- hymetDP::define_variable(     L0_flat = flat,     local_variable_column = \"variable_name\",     local_variable = \"WATER_TEMP\",     variable_name = \"Temperature\",     variable_units = \"degree celsius\",     sample_medium = \"Surface water\",     value_type = \"Field Observation\",     is_regular = TRUE,     time_support = 15,     time_units = \"minute\",     data_type = \"Continuous\",     general_category = \"Hydrology\",     no_data = -9999)    flat <- hymetDP::define_variable(     L0_flat = flat,     local_variable_column = \"variable_name\",     local_variable = \"CONDUCTIVITY\",     variable_name = \"Specific conductance\",     variable_units = \"microsiemens per centimeter\",     sample_medium = \"Surface water\",     value_type = \"Field Observation\",     is_regular = TRUE,     time_support = 15,     time_units = \"minute\",     data_type = \"Continuous\",     general_category = \"Hydrology\",     no_data = -9999)    # define_methods ---------------------------------------------------------    # Define methods and link to specific variables (by code or by name)      # Similar to `define_variable()`, there is a function for defining dataset   # methods. `define_method()` works under the assumption that each variable   # only has a single method associated with it. For this reason,   # `define_method()` lets you associate a MethodDescription to one or more    # variables in the flat table by specifying the original variable name (i.e.   # \"DSCHRGE_RATE\") or by the variable's newly assigned VariableCode. If both   # parameters are specified, the VariableCode will take precedence.   #   # `define_method()` is a straightforward helper function unless it is    # necessary to associate multiple methods with a single variable (i.e. methods   # change over time). When this is the case, a useful tactic can be to split    # the flat table in pieces and running `define_method()` on the fragments,   # taking care to re-join the flat fragments and manually assign MethodCodes.    flat <- hymetDP::define_method(     L0_flat = flat,     local_variable_column = \"variable_name\",     local_variable = \"DSCHRGE_RATE\",     VariableCode = c(1,2,3),     MethodDescription = [2868 chars quoted with '\"'],     MethodLink = NULL)    # Add columns for the sites table -----------------------------------    # Ideally, for datasets with multiple Sites, the source dataset would include   # latitude, longitude, and elevation for each Site. Since this dataset only   # has a single site, we only need to extract the single coordinate from the   # metadata.      geo_cov <- eml %>%     xml2::xml_find_all('.//geographicCoverage')    site_name <- geo_cov %>%     xml2::xml_find_all('.//geographicDescription') %>%     xml2::xml_text() %>%     stringr::str_replace_all('\\\\n', '')    bounds <- geo_cov %>%     xml2::xml_find_all('.//boundingCoordinates')   lon <- lapply(bounds, function(x) {     mean(       xml_double(xml2::xml_find_all(x, './/westBoundingCoordinate')),       xml_double(xml2::xml_find_all(x, './/eastBoundingCoordinate')))   })    lat <- lapply(bounds, function(x) {     mean(       xml_double(xml2::xml_find_all(x, './/northBoundingCoordinate')),       xml_double(xml2::xml_find_all(x, './/southBoundingCoordinate')))   })     elev <- lapply(bounds, function(x) {     mean(       xml_double(xml2::xml_find_all(x, './/boundingAltitudes/altitudeMinimum')),       xml_double(xml2::xml_find_all(x, './/boundingAltitudes/altitudeMaximum')))   })    if (!is.na(elev) & xml_text(xml2::xml_find_all(bounds, './/boundingAltitudes/altitudeUnits')) != 'meter') warning(\"Altitude must be converted to meter for hymetDP\")    # create a Sites table      # We can now add the geographic information, and other required columns for   # the Sites table, to our flat table. For the columns that require a CV term,   # use the *CV objects with `View()` as demonstrated below.    # View(SpatialReferencesCV) # LatLongDatumSRSName   # View(SiteTypeCV)          # SiteType    flat$SiteCode <- 1   flat$SiteName <- site_name   flat$Latitude <- lat   flat$Longitude <- lon   flat$Elevation_m <- elev   flat$SiteType <- \"Stream\"    # Add columns for the Sources table ---------------------------------------    # Some information for the Sources table must be manually added to the flat    # table. Other information, specifically, SourceDescription, SourceLink,   # Citation can be sourced automatically from the metadata.      flat$Organization <- xml2::xml_text(xml2::xml_find_first(eml, './/metadataProvider/organizationName'))   flat$ContactName <- paste0(xml2::xml_text(xml2::xml_find_first(eml, './/contact/individualName/givenName')), ' ',                              xml2::xml_text(xml2::xml_find_first(eml, './/contact/individualName/surName')))   flat$Email <- xml2::xml_text(xml2::xml_find_first(eml, './/contact/electronicMailAddress'))   # flat$Address <- xml2::xml_text(xml2::xml_find_first(eml, './/contact/address/deliveryPoint'))   # flat$City <- xml2::xml_text(xml2::xml_find_first(eml, './/contact/address/city'))   # flat$State <- xml2::xml_text(xml2::xml_find_first(eml, './/contact/address/administrativeArea'))   # flat$ZipCode <- xml2::xml_text(xml2::xml_find_first(eml, './/contact/address/postalCode'))    flat <- define_source(L0_flat = flat,                         eml = eml)     # Add columns for the Quality Control Level table ----------------------------------------    # Assign and describe Quality Control information for the dataset. In this   # case, all of the data is considered \"Quality controlled data\"      flat$QualityControlLevelCode <- 1   flat$Definition <- \"Quality controlled data\"   flat$Explanation <- \"Quality controlled data that have passed quality assurance procedures such as routine estimation of timing and sensor calibration or visual inspection and removal of obvious errors. An example is USGS published streamflow records following parsing through USGS quality control procedures.\"    # Add columns for the optional tables -------------------------------------------    # Qualifiers      # Adding columns for the optional table Qualifiers using the information   # from the Qualifier column of the flat table    # Clean up the codes in the table    flat$Qualifier <- flat$Qualifier %>% tolower()    flat$Qualifier[grepl(\"fair\", flat$Qualifier, ignore.case=FALSE)] <- \"fair\"   flat$Qualifier[grepl(\"good\", flat$Qualifier, ignore.case=FALSE)] <- \"good\"   flat$Qualifier[grepl(\"poor\", flat$Qualifier, ignore.case=FALSE)] <- \"poor\"   flat$Qualifier[grepl(\"[^fair|good|missing|poor]\", flat$Qualifier, ignore.case=FALSE)] <- NA_character_     flat <- dplyr::mutate(     flat,     QualifierCode = Qualifier   ) %>%     dplyr::left_join(       data.frame(         \"QualifierCode\" = c(\"good\", \"fair\", \"poor\", \"missing\"),         \"QualifierDescription\" = c('most accurate within 10%',                                    'most data accurate within 25%',                                    'significant amounts of data may be >25% off',                                    \"missing\")),       by = 'QualifierCode'     )    # The hard work is done! The flat table contains all the source data and    # more! We can now use the \"create\" functions to parse this table into the    # hymetDP tables.      # Parse flat into hymetDP required tables -------------------------------------------    # Each hymetDP table has an associated \"create\" function. Begin with the    # core required tables.      Sources <- hymetDP::create_sources(     L0_flat = flat,     SourceCode = \"SourceCode\",     Organization = \"Organization\",     SourceDescription = \"SourceDescription\",     SourceLink = \"SourceLink\",     ContactName = \"ContactName\",     Phone = \"Phone\",     Email = \"Email\",     Address = \"Address\",     City = \"City\",     State = \"State\",     ZipCode = \"ZipCode\",     Citation = \"Citation\")      Methods <- hymetDP::create_methods(     L0_flat = flat,     MethodCode = \"MethodCode\",     MethodDescription = \"MethodDescription\")      Variables <- hymetDP::create_variables(     L0_flat = flat,     VariableCode = \"VariableCode\",     VariableName = \"VariableName\",     VariableUnitsName = \"VariableUnitsName\",     SampleMedium = \"SampleMedium\",     ValueType = \"ValueType\",     IsRegular = \"IsRegular\",     TimeSupport = \"TimeSupport\",     TimeUnitsName = \"TimeUnitsName\",     DataType = \"DataType\",     GeneralCategory = \"GeneralCategory\",     NoDataValue = \"NoDataValue\")      Sites <- hymetDP::create_sites(     L0_flat = flat,     SiteCode = \"SiteCode\",     SiteName = \"SiteName\",     Latitude = \"Latitude\",     Longitude = \"Longitude\",     LatLongDatumSRSName = NULL,     Elevation_m = NULL,     VerticalDatum = NULL,     LocalX = NULL,     LocalY = NULL,     LocalProjectionSRSName = NULL,     PosAccuracy_m = NULL,     State = NULL,     County = NULL,     Comments = NULL,     SiteType = \"SiteType\")      QualityControlLevels <- hymetDP::create_quality_control(     L0_flat = flat,     QualityControlLevelCode = \"QualityControlLevelCode\",     Definition = \"Definition\",     Explanation = \"Explanation\"   )      # Parse flat into hymetDP optional tables ---------------------------------      # Create the optional hymetDP tables. These are optional, but should be    # included if possible.      Qualifiers <- hymetDP::create_qualifiers(     L0_flat = flat,     QualifierCode = \"QualifierCode\",     QualifierDescription = \"QualifierDescription\"   )      # Parse flat into the DataValues table ------------------------------------      # Create the DataValues table      DataValues <- hymetDP::create_data_values(     L0_flat = flat,     ValueID = \"ValueID\",     DataValue = \"DataValue\",     ValueAccuracy = NULL,     LocalDateTime = \"LocalDateTime\",     UTCOffset = \"UTCOffset\",     DateTimeUTC = \"DateTimeUTC\",     SiteCode = \"SiteCode\",     VariableCode = \"VariableCode\",     OffsetValue = NULL,     OffsetTypeCode = NULL,     CensorCode = NULL,     QualifierCode = NULL,     MethodCode = \"MethodCode\",     QualityControlLevelCode = \"QualityControlLevelCode\",     SourceCode = \"SourceCode\",     NoDataValue = \"NoDataValue\")         # Create the SeriesCatalog table ------------------------------------------      # Finally, create the SeriesCatalog table. This table summarizes information   # across several other required hymetDP tables. Since it takes the other,    # finalized tables as input, it must be created last.      SeriesCatalog <- hymetDP::create_series_catalog(     Sources = Sources,     Methods = Methods,     Variables = Variables,     Sites = Sites,     QualityControlLevels = QualityControlLevels,     DataValues = DataValues)      # Write hymetDP tables ----------------------------------------------------    hymetDP::write_tables(     path = path,     DataValues = DataValues,     Variables = Variables,     Methods = Methods,     Sources = Sources,     Sites = Sites,     QualityControlLevels = QualityControlLevels,     Qualifiers = Qualifiers,     SeriesCatalog = SeriesCatalog)      # Validate tables -----------------------------------------------------------      # Validation checks ensure the derived set of tables comply with the hymetDP   # model. Any issues at this point should be addressed in the lines of code   # above, the tables rewritten, and another round of validation, to be certain   # the fix worked.    issues <- hymetDP::validate_data(path = path)      # Create metadata -----------------------------------------------------------      # Before publishing the derived hymetDP dataset, we need to describe it. The    # create_eml() function does this all for us. It knows the structure of the    # hymetDP model and applies standardized table descriptions and mixes in    # important elements of the source dataset metadata for purposes of    # communication and provenance tracking.      # Add contact information for the author of this script and dataset    additional_contact <- data.frame(     givenName = 'Kyle',     surName = 'Zollo-Venecek',     organizationName = 'Environmental Data Initiative',     electronicMailAddress = 'zollovenecek@wisc.edu',     stringsAsFactors = FALSE)    eml <- hymetDP::create_eml(     path = path,     source_id = source_id,     derived_id = derived_id,     script = \"create_hymetDP.R\",     script_description =       \"A function for converting knb-lter-mcm.9003 to hymetDP\",     contact = additional_contact,     user_id = 'kzollovenecek',     user_domain = 'edi') }"},{"path":"https://EDIorg.github.io/hymetDP/articles/create.html","id":"example-function-call","dir":"Articles","previous_headings":"For archive in a data repository","what":"Example function call:","title":"Create hymetDP Data","text":"","code":"# Create directory for tables and metadata  mypath <- paste0(tempdir(), \"/edi_10101\") dir.create(mypath)  # Create hymetDP dataset \"edi.10101.1\" from source dataset \"knb-lter-mcm.9003.11\"  #> create_hymetDP( #>   path = mypath,  #>   source_id = \"knb-lter-mcm.9003.11\",  #>   derived_id = \"edi.10101.1\") #>  #>  [100%] Downloaded 11310035 bytes... #> SourceDescription added #> SourceLink added #> Citation added #> Contact Info Added #> Writing tables to file: #>   DataValues #>   Variables #>   Methods #>   Sources #>   Sites #>   QualityControlLevels #>   SeriesCatalog #>   Qualifiers #> Validating ed_10101: #>   Required tables #>   Column names #>   Required columns #>   Column classes #>   Datetime formats #>   Primary keys #>   Composite keys #>   Referential integrity #>   Latitude and Longitude format #>   Latitude and Longitude range #>   Elevation #>   ODM Controlled Vocabulary terms #> Creating EML for derived data package (edi.10101.1) #> Reading EML of L0 data package knb-lter-mcm.9003.11 #> Creating EML of L1 data package edi.10101.1 #> Updating: #> <eml> #>   <dataset> #>     <alternateIdentifier> #>     <title> #>     <pubDate> #>     <keywordSet> #>     <contact> #>     <methods> #>     <dataTable> #>     <otherEntity> #>     <annotations> #> <\/eml> #> Writing EML #> Validating EML #>   Validation passed :) #> Done.  # The working directory contains a valid set of hymetDP tables and metadata,  # which is ready for upload to EDI (or any other EML based repository)  dir(mypath) #>  [1] \"create_hymetDP.R\"         #>  [2] \"DataValues.csv\"           #>  [3] \"edi.10101.1.xml\"          #>  [4] \"Methods.csv\"              #>  [5] \"Qualifiers.csv\"           #>  [6] \"QualityControlLevels.csv\" #>  [7] \"SeriesCatalog.csv\"        #>  [8] \"Sites.csv\"                #> [9] \"Sources.csv\"              #> [10] \"Variables.csv\""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/articles/use_usgs.html","id":"discover-usgs-sites","dir":"Articles","previous_headings":"Create a hymetDP dataset from USGS data","what":"Discover USGS sites","title":"Create hymetDP Dataset from USGS Data","text":"select specific sites using create_USGS_hymet(), need know site’s USGS Site ID (. Use dataRetrieval::whatNWISsites() discover USGS sites State area. can get table USGS stream sites measure discharge: See USGS Site Web Service complete list argument options dataRetrieval::whatNWISsites()","code":"sites <- dataRetrieval::whatNWISsites(stateCd=\"PR\", siteType=\"ST\", parameterCd=\"00060\") head(sites) #>   agency_cd  site_no                         station_nm site_tp_cd dec_lat_va #> 1      USGS 50146200           RIO GRANDE NR RINCON, PR         ST   18.36634 #> 2      USGS 50146400          RIO INGENIO NR AGUADA, PR         ST   18.37856 #> 3      USGS 50146600          RIO CULEBRA NR AGUADA, PR         ST   18.37189 #> 4      USGS 50130320       QUEBRADA MAMEY AT JOYUDA, PR         ST   18.12885 #> 5      USGS 50146100 RIO GRANDE DE ANASCO NR ANASCO, PR         ST   18.27273 #> 6      USGS 50149100       RIO CULEBRINAS NR AGUADA, PR         ST   18.39884 #>   dec_long_va colocated           queryTime #> 1   -67.23185     FALSE 2022-06-28 13:58:50 #> 2   -67.20907     FALSE 2022-06-28 13:58:50 #> 3   -67.19268     FALSE 2022-06-28 13:58:50 #> 4   -67.16879     FALSE 2022-06-28 13:58:50 #> 5   -67.16157     FALSE 2022-06-28 13:58:50 #> 6   -67.16074     FALSE 2022-06-28 13:58:50"},{"path":"https://EDIorg.github.io/hymetDP/articles/use_usgs.html","id":"select-usgs-parameters","dir":"Articles","previous_headings":"Create a hymetDP dataset from USGS data","what":"Select USGS parameters","title":"Create hymetDP Dataset from USGS Data","text":"Inspect supported_USGS_params see USGS parameters currently supported conversion hymetDP.","code":"View(supported_USGS_params)"},{"path":"https://EDIorg.github.io/hymetDP/articles/use_usgs.html","id":"create-the-hymetdp-formatted-dataset-from-usgs-data","dir":"Articles","previous_headings":"Create a hymetDP dataset from USGS data","what":"Create the hymetDP-formatted dataset from USGS data","title":"Create hymetDP Dataset from USGS Data","text":"Specify USGS sites, parameter codes, start end dates arguments create_USGS_hymet() compile format data given parameters location time period.","code":"site <- c(\"06879650\", \"50065500\") param <- c(\"00060\") start <- c(\"2021-01-01T12:30:00Z\") end <- c(\"2021-01-08T12:30:00Z\")  usgs_hymet <- hymetDP::create_USGS_hymet(site, param, start, end) #> Downloading data from USGS site 06879650, parameter 00060 #> Downloading data from USGS site 50065500, parameter 00060 #> Generating hymetDP tables...  str(usgs_hymet) #> List of 7 #>  $ Sources             :'data.frame':    2 obs. of  12 variables: #>   ..$ SourceCode       : chr [1:2] \"1\" \"2\" #>   ..$ Organization     : chr [1:2] \"USGS\" \"USGS\" #>   ..$ SourceDescription: chr [1:2] \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" #>   ..$ SourceLink       : chr [1:2] \"https://waterdata.usgs.gov/monitoring-location/06879650/#parameterCode=00060\" \"https://waterdata.usgs.gov/monitoring-location/50065500/#parameterCode=00060\" #>   ..$ ContactName      : chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ Phone            : chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ Email            : chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ Address          : chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ City             : chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ State            : chr [1:2] \"Kansas\" \"Puerto Rico\" #>   ..$ ZipCode          : chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ Citation         : chr [1:2] \"U.S. Geological Survey, 2001, National Water Information System data available on the World Wide Web (Water Dat\"| __truncated__ \"U.S. Geological Survey, 2001, National Water Information System data available on the World Wide Web (Water Dat\"| __truncated__ #>  $ Methods             :'data.frame':    2 obs. of  3 variables: #>   ..$ MethodCode       : chr [1:2] \"1\" \"2\" #>   ..$ MethodDescription: chr [1:2] \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" #>   ..$ MethodLink       : chr [1:2] NA NA #>  $ Variables           :'data.frame':    1 obs. of  11 variables: #>   ..$ VariableCode     : chr \"00060\" #>   ..$ VariableName     : chr \"Streamflow\" #>   ..$ VariableUnitsName: chr \"cubic feet per second\" #>   ..$ SampleMedium     : chr \"Surface water\" #>   ..$ ValueType        : chr \"Derived Value\" #>   ..$ IsRegular        : logi TRUE #>   ..$ TimeSupport      : num 15 #>   ..$ TimeUnitsName    : chr \"minute\" #>   ..$ DataType         : chr \"Continuous\" #>   ..$ GeneralCategory  : chr \"Hydrology\" #>   ..$ NoDataValue      : num -9999 #>  $ Sites               :'data.frame':    2 obs. of  15 variables: #>   ..$ SiteCode              : chr [1:2] \"06879650\" \"50065500\" #>   ..$ SiteName              : chr [1:2] \"KINGS C NR MANHATTAN, KS\" \"RIO MAMEYES NR SABANA, PR\" #>   ..$ Latitude              : num [1:2] 39.1 18.3 #>   ..$ Longitude             : num [1:2] -96.6 -65.8 #>   ..$ LatLongDatumSRSName   : chr [1:2] \"NAD83\" \"NAD27\" #>   ..$ Elevation_m           : num [1:2] NA NA #>   ..$ VerticalDatum         : chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ LocalX                : num [1:2] NA NA #>   ..$ LocalY                : num [1:2] NA NA #>   ..$ LocalProjectionSRSName: chr [1:2] \"Unknown\" \"Unknown\" #>   ..$ PosAccuracy_m         : num [1:2] NA NA #>   ..$ State                 : chr [1:2] \"Kansas\" \"Puerto Rico\" #>   ..$ County                : chr [1:2] \"Riley County\" \"Rio Grande Municipio\" #>   ..$ Comments              : chr [1:2] NA NA #>   ..$ SiteType              : chr [1:2] \"Stream\" \"Stream\" #>  $ QualityControlLevels:'data.frame':    1 obs. of  3 variables: #>   ..$ QualityControlLevelCode: chr \"A\" #>   ..$ Definition             : chr \"Approved for publication -- Processing and review completed.\" #>   ..$ Explanation            : chr \"Water-Level Approval-Status Codes\" #>  $ DataValues          :'data.frame':    1344 obs. of  15 variables: #>   ..$ ValueID                : chr [1:1344] \"1\" \"2\" \"3\" \"4\" ... #>   ..$ DataValue              : num [1:1344] 0 0 0 0 0 0 0 0 0 0 ... #>   ..$ ValueAccuracy          : num [1:1344] NA NA NA NA NA NA NA NA NA NA ... #>   ..$ LocalDateTime          : chr [1:1344] \"2021-01-01 07:30:00\" \"2021-01-01 07:45:00\" \"2021-01-01 08:00:00\" \"2021-01-01 08:15:00\" ... #>   ..$ UTCOffset              : num [1:1344] -6 -6 -6 -6 -6 -6 -6 -6 -6 -6 ... #>   ..$ DateTimeUTC            : chr [1:1344] \"2021-01-01 13:30:00\" \"2021-01-01 13:45:00\" \"2021-01-01 14:00:00\" \"2021-01-01 14:15:00\" ... #>   ..$ SiteCode               : chr [1:1344] \"06879650\" \"06879650\" \"06879650\" \"06879650\" ... #>   ..$ VariableCode           : chr [1:1344] \"00060\" \"00060\" \"00060\" \"00060\" ... #>   ..$ OffsetValue            : num [1:1344] NA NA NA NA NA NA NA NA NA NA ... #>   ..$ OffsetTypeCode         : chr [1:1344] NA NA NA NA ... #>   ..$ CensorCode             : chr [1:1344] \"unk\" \"unk\" \"unk\" \"unk\" ... #>   ..$ QualifierCode          : chr [1:1344] NA NA NA NA ... #>   ..$ MethodCode             : chr [1:1344] \"1\" \"1\" \"1\" \"1\" ... #>   ..$ SourceCode             : chr [1:1344] \"1\" \"1\" \"1\" \"1\" ... #>   ..$ QualityControlLevelCode: chr [1:1344] \"A\" \"A\" \"A\" \"A\" ... #>  $ SeriesCatalog       :'data.frame':    2 obs. of  24 variables: #>   ..$ SeriesID               : num [1:2] 1 2 #>   ..$ SiteCode               : chr [1:2] \"06879650\" \"50065500\" #>   ..$ SiteName               : chr [1:2] \"KINGS C NR MANHATTAN, KS\" \"RIO MAMEYES NR SABANA, PR\" #>   ..$ VariableCode           : chr [1:2] \"00060\" \"00060\" #>   ..$ VariableName           : chr [1:2] \"Streamflow\" \"Streamflow\" #>   ..$ VariableUnitsName      : chr [1:2] \"cubic feet per second\" \"cubic feet per second\" #>   ..$ SampleMedium           : chr [1:2] \"Surface water\" \"Surface water\" #>   ..$ ValueType              : chr [1:2] \"Derived Value\" \"Derived Value\" #>   ..$ TimeSupport            : num [1:2] 15 15 #>   ..$ TimeUnitsName          : chr [1:2] \"minute\" \"minute\" #>   ..$ DataType               : chr [1:2] \"Continuous\" \"Continuous\" #>   ..$ GeneralCategory        : chr [1:2] \"Hydrology\" \"Hydrology\" #>   ..$ MethodCode             : chr [1:2] \"1\" \"2\" #>   ..$ MethodDescription      : chr [1:2] \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" #>   ..$ SourceCode             : chr [1:2] \"1\" \"2\" #>   ..$ Organization           : chr [1:2] \"USGS\" \"USGS\" #>   ..$ SourceDescription      : chr [1:2] \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" \"Data pulled from USGS National Water Infrastructure Service (NWIS) using the dataRetrieval R package\" #>   ..$ Citation               : chr [1:2] \"U.S. Geological Survey, 2001, National Water Information System data available on the World Wide Web (Water Dat\"| __truncated__ \"U.S. Geological Survey, 2001, National Water Information System data available on the World Wide Web (Water Dat\"| __truncated__ #>   ..$ QualityControlLevelCode: chr [1:2] \"A\" \"A\" #>   ..$ BeginDateTime          : chr [1:2] \"2021-01-01 07:30:00\" \"2021-01-01 06:30:00\" #>   ..$ EndDateTime            : chr [1:2] \"2021-01-08 07:30:00\" \"2021-01-08 06:30:00\" #>   ..$ BeginDateTimeUTC       : chr [1:2] \"2021-01-01 13:30:00\" \"2021-01-01 12:30:00\" #>   ..$ EndDateTimeUTC         : chr [1:2] \"2021-01-08 13:30:00\" \"2021-01-08 12:30:00\" #>   ..$ ValueCount             : num [1:2] 673 671"},{"path":"https://EDIorg.github.io/hymetDP/articles/use_usgs.html","id":"write-hymetdp-tables-to-file","dir":"Articles","previous_headings":"Create a hymetDP dataset from USGS data","what":"Write hymetDP tables to file","title":"Create hymetDP Dataset from USGS Data","text":"","code":"path = tempdir()  hymetDP::write_tables(   path = path,   DataValues = usgs_hymet$DataValues,   Variables = usgs_hymet$Variables,   Methods = usgs_hymet$Methods,   Sources = usgs_hymet$Sources,   Sites = usgs_hymet$Sites,   QualityControlLevels = usgs_hymet$QualityControlLevels,   SeriesCatalog = usgs_hymet$SeriesCatalog) #> Writing tables to file: #>   DataValues #>   Variables #>   Methods #>   Sources #>   Sites #>   QualityControlLevels #>   SeriesCatalog"},{"path":"https://EDIorg.github.io/hymetDP/articles/use_usgs.html","id":"create-eml","dir":"Articles","previous_headings":"Create a hymetDP dataset from USGS data","what":"Create EML","title":"Create hymetDP Dataset from USGS Data","text":"Create Ecological Metadata Language (EML) metadata derived dataset.","code":"# Coming soon!"},{"path":"https://EDIorg.github.io/hymetDP/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kyle Zollo-Venecek. Author, maintainer.","code":""},{"path":"https://EDIorg.github.io/hymetDP/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zollo-Venecek K (2022). hymetDP: Tools Create, Use, Convert hymetDP data. R package version 0.0.0.9000, https://github.com/EDIorg/hymetDP.","code":"@Manual{,   title = {hymetDP: Tools to Create, Use, and Convert hymetDP data},   author = {Kyle Zollo-Venecek},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://github.com/EDIorg/hymetDP}, }"},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Tools to Create, Use, and Convert hymetDP data","text":"Tools create, use, convert ‘hymetDP’ datasets. ‘hymetDP’ dataset design pattern harmonizing hydrological meteorological data research question agnostic format, source datasets published across multiple repositories, methods keep derived datasets --date underlying sources change. Based ecocomDP R package.","code":""},{"path":"https://EDIorg.github.io/hymetDP/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools to Create, Use, and Convert hymetDP data","text":"Get latest development version:","code":"# install.packages(\"remotes\") remotes::install_github(\"EDIorg/hymetDP\")"},{"path":"https://EDIorg.github.io/hymetDP/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Tools to Create, Use, and Convert hymetDP data","text":"Use GitHub Issues bug reporting, feature requests, general questions/discussions. filling bug reports, please include minimal reproducible example.","code":""},{"path":"https://EDIorg.github.io/hymetDP/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Tools to Create, Use, and Convert hymetDP data","text":"Community contributions welcome! Please reference contributing guidelines details. Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://EDIorg.github.io/hymetDP/index.html","id":"logo","dir":"","previous_headings":"Contributing","what":"Logo","title":"Tools to Create, Use, and Convert hymetDP data","text":"Original photograph Michal Osmenda. file licensed Creative Commons Attribution-Share Alike 2.0 Generic license.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/CensorCodeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Censor Codes — CensorCodeCV","title":"Allowed Censor Codes — CensorCodeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Censor Codes","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/CensorCodeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Censor Codes — CensorCodeCV","text":"","code":"CensorCodeCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/CensorCodeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Censor Codes — CensorCodeCV","text":"data frame 6 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/CensorCodeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Censor Codes — CensorCodeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=CensorCodeCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/DataTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Data Types — DataTypeCV","title":"Allowed Data Types — DataTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Data Types","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/DataTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Data Types — DataTypeCV","text":"","code":"DataTypeCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/DataTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Data Types — DataTypeCV","text":"data frame 16 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/DataTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Data Types — DataTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=DataTypeCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/GeneralCategoryCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed General Categories — GeneralCategoryCV","title":"Allowed General Categories — GeneralCategoryCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary General Category","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/GeneralCategoryCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed General Categories — GeneralCategoryCV","text":"","code":"GeneralCategoryCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/GeneralCategoryCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed General Categories — GeneralCategoryCV","text":"data frame 10 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/GeneralCategoryCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed General Categories — GeneralCategoryCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=GeneralCategoryCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SampleMediumCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Sample Media — SampleMediumCV","title":"Allowed Sample Media — SampleMediumCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Sample Medium","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SampleMediumCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Sample Media — SampleMediumCV","text":"","code":"SampleMediumCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/SampleMediumCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Sample Media — SampleMediumCV","text":"data frame 24 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SampleMediumCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Sample Media — SampleMediumCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=SampleMediumCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SiteTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Site Types — SiteTypeCV","title":"Allowed Site Types — SiteTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Site Types","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SiteTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Site Types — SiteTypeCV","text":"","code":"SiteTypeCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/SiteTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Site Types — SiteTypeCV","text":"data frame 62 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SiteTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Site Types — SiteTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=SiteTypeCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SpatialReferencesCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Spatial References — SpatialReferencesCV","title":"Allowed Spatial References — SpatialReferencesCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Spatial References","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SpatialReferencesCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Spatial References — SpatialReferencesCV","text":"","code":"SpatialReferencesCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/SpatialReferencesCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Spatial References — SpatialReferencesCV","text":"data frame 343 rows 5 variables: SpatialReferenceID Integer identifier SRSID Spatial Reference System identifier SRSName Spatial Reference System name IsGeographic Boolean Notes Spatial Reference System notes","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/SpatialReferencesCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Spatial References — SpatialReferencesCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=SpatialReferences","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/UnitsCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Units — UnitsCV","title":"Allowed Units — UnitsCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Units","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/UnitsCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Units — UnitsCV","text":"","code":"UnitsCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/UnitsCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Units — UnitsCV","text":"data frame 394 rows 4 variables: UnitsID Unique unit identifier UnitsName Name unit UnitsType Type unit UnitsAbbreviation Standardized abbreviation symbol unit","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/UnitsCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Units — UnitsCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=Units","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/ValueTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Value Types — ValueTypeCV","title":"Allowed Value Types — ValueTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Value Type","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/ValueTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Value Types — ValueTypeCV","text":"","code":"ValueTypeCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/ValueTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Value Types — ValueTypeCV","text":"data frame 7 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/ValueTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Value Types — ValueTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=ValueTypeCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/VariableNameCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Variable Names — VariableNameCV","title":"Allowed Variable Names — VariableNameCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Variable Name","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/VariableNameCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Variable Names — VariableNameCV","text":"","code":"VariableNameCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/VariableNameCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Variable Names — VariableNameCV","text":"data frame 925 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/VariableNameCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Variable Names — VariableNameCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=VariableNameCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/VerticalDatumCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Vertical Datum — VerticalDatumCV","title":"Allowed Vertical Datum — VerticalDatumCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Vertical Datum","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/VerticalDatumCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Vertical Datum — VerticalDatumCV","text":"","code":"VerticalDatumCV"},{"path":"https://EDIorg.github.io/hymetDP/reference/VerticalDatumCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Vertical Datum — VerticalDatumCV","text":"data frame 5 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/VerticalDatumCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Vertical Datum — VerticalDatumCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=VerticalDatumCV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/check_odm_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"Check term ODM Controlled Vocabulary","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/check_odm_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"","code":"check_odm_cv(term, cv)"},{"path":"https://EDIorg.github.io/hymetDP/reference/check_odm_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"term (character) user-provided term needs validated cv (character) \"Term\" column corresponding CV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/check_odm_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"(logical) TRUE exact match CV, otherwise FALSE","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/convert_missing_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert missing value codes to NA — convert_missing_value","title":"Convert missing value codes to NA — convert_missing_value","text":"Convert missing value codes NA","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/convert_missing_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert missing value codes to NA — convert_missing_value","text":"","code":"convert_missing_value(v, code, type)"},{"path":"https://EDIorg.github.io/hymetDP/reference/convert_missing_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert missing value codes to NA — convert_missing_value","text":"v Vector values code (character) Missing value code type (character) Type (class) v . Supported types : \"character\", \"numeric\", \"datetime\"","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/convert_missing_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert missing value codes to NA — convert_missing_value","text":"Vector values code replaced NA class type","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_USGS_hymet.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"Create USGS hymetDP-formatted dataset","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_USGS_hymet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"","code":"create_USGS_hymet(site, param, start, end)"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_USGS_hymet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"site (character) USGS site code list site codes. Discover site codes dataRetrieval::whatNWISsites(). param (character) USGS parameter code list parameter codes. Discover parameter codes dataRetrieval::whatNWISdata(). start (character) Starting datetime data query. Format date strings YYYY-MM-DD, datetime strings YYYY-MM-DDThh:mm:ssZ. Format must match end parameter format. end (character) Ending datetime data query. Format date strings YYYY-MM-DD,","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_USGS_hymet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"list hymetDP tables","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_USGS_hymet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"","code":"if (FALSE) { site <- c(\"06879650\", \"50065500\") param <- c(\"00060\") start <- c(\"2020-06-01T12:30:00Z\") end <- c(\"2021-01-01T12:30:00Z\")  usgs_hymet <- create_USGS_hymet(site, param, start, end)  }"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_citation.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"Create EDI data package citation EML hosted EDI Data Portal","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_citation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"","code":"create_citation(eml = eml)"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_citation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"eml (character) EML document valid EDI package identifier can extracted.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_citation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"(character) EDI data package citation.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_data_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the DataValues table — create_data_values","title":"Create the DataValues table — create_data_values","text":"Create DataValues table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_data_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the DataValues table — create_data_values","text":"","code":"create_data_values(   L0_flat,   ValueID,   DataValue,   ValueAccuracy = NULL,   LocalDateTime,   UTCOffset,   DateTimeUTC = NULL,   SiteCode,   VariableCode,   OffsetValue = NULL,   OffsetTypeCode = NULL,   CensorCode = NULL,   QualifierCode = NULL,   MethodCode,   QualityControlLevelCode,   SourceCode,   NoDataValue )"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_data_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the DataValues table — create_data_values","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). ValueID (character) Column L0_flat containing identifier assigned unique data value. DataValue (character) Column L0_flat containing numeric value observation. ValueAccuracy (character) Optional. Column L0_flat containing umeric value describes measurement accuracy data value. LocalDateTime (character) Column L0_flat containing local date time data value observed. UTCOffset (character) Column L0_flat containing offset hours UTC time corresponding LocalDateTime value. DateTimeUTC (character) Column L0_flat containing UTC date time data value observed. SiteCode (character) Column L0_flat containing code used organization collects data identify site. VariableCode (character) Column L0_flat containing code used organization collects data identify variable. OffsetValue (character) Optional. Column L0_flat containing distance datum control point point data value observed. OffsetTypeCode (character) OffsetValue used. Column L0_flat containing code used organization collects data identify OffsetType. CensorCode (character) Column L0_flat containing text indication whether data value censored. Defaults \"nc\" (Censored). QualifierCode (character) Optional. Column L0_flat containing flag indicating peculiarity particular data value. MethodCode (character) Column L0_flat containing code used organization collects data identify Method. QualityControlLevelCode (character) Column L0_flat containing code identifies level quality control value subjected . SourceCode (character) Column L0_flat containing code identifies organization created data. NoDataValue (character) Column L0_flat containing numeric value used encode data value available variable.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_data_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the DataValues table — create_data_values","text":"(tbl_df, tbl, data.frame) DataValues table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_data_values.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the DataValues table — create_data_values","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/reference/create_data_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the DataValues table — create_data_values","text":"","code":"flat <- hymet_L0_flat    DataValues <- hymetDP::create_data_values(     L0_flat = flat,     ValueID = \"ValueID\",     DataValue = \"DataValue\",     ValueAccuracy = NULL,     LocalDateTime = \"LocalDateTime\",     UTCOffset = \"UTCOffset\",     DateTimeUTC = \"DateTimeUTC\",     SiteCode = \"SiteCode\",     VariableCode = \"VariableCode\",     OffsetValue = NULL,     OffsetTypeCode = NULL,     CensorCode = NULL,     QualifierCode = NULL,     MethodCode = \"MethodCode\",     QualityControlLevelCode = \"QualityControlLevelCode\",     SourceCode = \"SourceCode\",     NoDataValue = \"NoDataValue\")    DataValues #> # A tibble: 30,003 × 15 #>    ValueID DataValue ValueAccuracy LocalDateTime  UTCOffset DateTimeUTC SiteCode #>    <chr>       <dbl>         <dbl> <chr>              <dbl> <chr>       <chr>    #>  1 1           144.             NA 2002-01-11 23…        13 2002-01-11… 1        #>  2 2             0.1            NA 2002-01-11 23…        13 2002-01-11… 1        #>  3 3            16.3            NA 2002-01-11 23…        13 2002-01-11… 1        #>  4 4           121.             NA 2002-01-12 00…        13 2002-01-11… 1        #>  5 5             0.1            NA 2002-01-12 00…        13 2002-01-11… 1        #>  6 6            16.4            NA 2002-01-12 00…        13 2002-01-11… 1        #>  7 7           116.             NA 2002-01-12 00…        13 2002-01-11… 1        #>  8 8             0.1            NA 2002-01-12 00…        13 2002-01-11… 1        #>  9 9            16.9            NA 2002-01-12 00…        13 2002-01-11… 1        #> 10 10          139.             NA 2002-01-12 00…        13 2002-01-11… 1        #> # … with 29,993 more rows, and 8 more variables: VariableCode <chr>, #> #   OffsetValue <dbl>, OffsetTypeCode <chr>, CensorCode <chr>, #> #   QualifierCode <chr>, MethodCode <chr>, SourceCode <chr>, #> #   QualityControlLevelCode <chr>"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_eml.html","id":null,"dir":"Reference","previous_headings":"","what":"Create EML metadata — create_eml","title":"Create EML metadata — create_eml","text":"Create EML metadata","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_eml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create EML metadata — create_eml","text":"","code":"create_eml(   path,   source_id = NULL,   derived_id,   script,   script_description,   is_about = NULL,   contact,   user_id,   user_domain,   url = NULL )"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_eml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create EML metadata — create_eml","text":"path (character) Path directory containing hymetDP tables, conversion script, EML metadata written. source_id (character) Identifier data package published supported repository. Currently, EDI Data Repository supported. derived_id (character) Identifier dataset created. script (character) Name file used convert source_id derived_id. script_description (character) Description script. is_about (named character) optional argument specifying dataset level annotations describing dataset \"\". contact (data.frame) Contact information person created hymetDP dataset, containing columns: givenName surName organizationName electronicMailAddress user_id (character) Identifier user associated user_domain. user_domain (character) Domain (data repository) user_id belongs . Currently, EDI supported. url (character) URL publicly accessible directory containing hymetDP tables, conversion script, EML metadata. argument supports direct download data entities data repository used automated revisioning publication.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_eml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create EML metadata — create_eml","text":"EML metadata file.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_eml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create EML metadata — create_eml","text":"function creates EML record hymetDP dataset combining metadata source_id boiler-plate metadata describing hymetDP model. Changes source_id EML include: <access> Adds user_id list principals granted read write access hymetDP data package EML describes. <title> Adds note derived data package hymetDP format. <pubDate> Adds date EML created. <abstract> Adds note derived data package hymetDP format. <keywordSet> Adds \"hymetDP\" keyword enable search discovery hymetDP data packages data repository published. <intellectualRights> Keeps intact original intellectual rights license source_id released , uses CCO missing. <contact> Adds hymetDP creator point contact. <methodStep> Adds note data package created script, adds provenance metadata noting derived dataset describes source_id can accessed. <dataTables> Replaces source_id table metadata descriptions hymetDP tables. <otherEntity> Adds script script_description. otherEntities source_id removed. <annotations> Adds boilerplate annotations describing hymetDP dataset, entity, entity attribute levels.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_eml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create EML metadata — create_eml","text":"","code":"if (FALSE) { # Create directory with hymetDP tables for create_eml() mypath <- paste0(tempdir(), \"/data\") dir.create(mypath) inpts <- c(hymet_L1$tables, path = mypath) do.call(write_tables, inpts) file.copy(system.file(\"extdata\", \"create_hymetDP.R\", package = \"hymetDP\"), mypath) dir(mypath)  # Add self as contact information incase questions arise additional_contact <- data.frame(   givenName = 'Kyle',   surName = 'Zollo-Venecek',   organizationName = 'Environmental Data Initiative',   electronicMailAddress = 'hymetdp@gmail.com',   stringsAsFactors = FALSE)  # Create EML eml <- create_eml(   path = mypath,   source_id = \"knb-lter-mcm.9003.11\",   derived_id = \"edi.10101.1\",   is_about = dataset_annotations,   script = \"create_hymetDP.R\",   script_description = \"A function for converting knb-lter-mcm.9003 to hymetDP\",   contact = additional_contact,   user_id = 'hymetdp',   user_domain = 'EDI')  dir(mypath) View(eml)  # Clean up unlink(mypath, recursive = TRUE) }"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Methods table — create_methods","title":"Create the Methods table — create_methods","text":"Create Methods table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Methods table — create_methods","text":"","code":"create_methods(L0_flat, MethodCode, MethodDescription, MethodLink = NULL)"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Methods table — create_methods","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). MethodCode (character) Column L0_flat containing code used organization collects data identify Method. MethodDescription (character) Column L0_flat containing text description method. MethodLink (character) Optional. Column L0_flat containing link additional reference material method. single valid URL.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Methods table — create_methods","text":"(tbl_df, tbl, data.frame) Methods table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Methods table — create_methods","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/reference/create_methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Methods table — create_methods","text":"","code":"flat <- hymet_L0_flat   Methods <- hymetDP::create_methods(    L0_flat = flat,    MethodCode = \"MethodCode\",    MethodDescription = \"MethodDescription\")   Methods #> # A tibble: 1 × 3 #>   MethodCode MethodDescription                                        MethodLink #>   <chr>      <chr>                                                    <chr>      #> 1 1          Campbell CR10 dataloggers were used to record stream st… NA"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_qualifiers.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Qualifiers table — create_qualifiers","title":"Create the Qualifiers table — create_qualifiers","text":"Create Qualifiers table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_qualifiers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Qualifiers table — create_qualifiers","text":"","code":"create_qualifiers(L0_flat, QualifierCode, QualifierDescription)"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_qualifiers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Qualifiers table — create_qualifiers","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). QualifierCode (character) Column L0_flat containing code indicate given data qualifier. QualifierDescription (character) Column L0_flat containing text data qualifying comment, e.g., low battery voltage sensor.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_qualifiers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Qualifiers table — create_qualifiers","text":"flat <- hymet_L0_flat Qualifiers <- hymetDP::create_qualifiers( L0_flat = flat, QualifierCode = \"QualifierCode\", QualifierDescription = \"QualifierDescription\") Qualifiers","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_qualifiers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Qualifiers table — create_qualifiers","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_quality_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the QualityControlLevels table — create_quality_control","title":"Create the QualityControlLevels table — create_quality_control","text":"Create QualityControlLevels table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_quality_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the QualityControlLevels table — create_quality_control","text":"","code":"create_quality_control(   L0_flat,   QualityControlLevelCode,   Definition,   Explanation )"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_quality_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the QualityControlLevels table — create_quality_control","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). QualityControlLevelCode (character) Column L0_flat containing code used identify level quality control data values subjected. Definition (character) Column L0_flat containing definition Quality Control Level. Examples: Raw Data, Quality Controlled Data. confused data qualifiers. Explanation (character) Column L0_flat containing explanation Quality Control Level.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_quality_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the QualityControlLevels table — create_quality_control","text":"(tbl_df, tbl, data.frame) QualityControlLevels table. flat <- hymet_L0_flat QualityControlLevels <- hymetDP::create_quality_control( L0_flat = flat, QualityControlLevelCode = \"QualityControlLevelCode\", Definition = \"Definition\", Explanation = \"Explanation\") QualityControlLevels","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_quality_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the QualityControlLevels table — create_quality_control","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/reference/create_series_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the SeriesCatalog table — create_series_catalog","title":"Create the SeriesCatalog table — create_series_catalog","text":"Create SeriesCatalog table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_series_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the SeriesCatalog table — create_series_catalog","text":"","code":"create_series_catalog(   L0_flat = NULL,   Sources = NULL,   Methods = NULL,   Variables = NULL,   Sites = NULL,   QualityControlLevels = NULL,   DataValues = NULL )"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_series_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the SeriesCatalog table — create_series_catalog","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). Sources (tbl_df, tbl, data.frame) Sources table. Methods (tbl_df, tbl, data.frame) Methods table. Variables (tbl_df, tbl, data.frame) Variables table. Sites (tbl_df, tbl, data.frame) Sites table. QualityControlLevels (tbl_df, tbl, data.frame) QualityControlLevels table. DataValues (tbl_df, tbl, data.frame) DataValues table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_series_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the SeriesCatalog table — create_series_catalog","text":"(tbl_df, tbl, data.frame) SeriesCatalog table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_series_catalog.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the SeriesCatalog table — create_series_catalog","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/reference/create_series_catalog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the SeriesCatalog table — create_series_catalog","text":"","code":"flat <- hymet_L0_flat  Sources <- hymetDP::create_sources(   L0_flat = flat,   SourceCode = \"SourceCode\",   Organization = \"Organization\",   SourceDescription = \"SourceDescription\",   SourceLink = \"SourceLink\",   ContactName = \"ContactName\",   Phone = \"Phone\",   Email = \"Email\",   Address = \"Address\",   City = \"City\",   State = \"State\",   ZipCode = \"ZipCode\",   Citation = \"Citation\")  Methods <- hymetDP::create_methods(   L0_flat = flat,   MethodCode = \"MethodCode\",   MethodDescription = \"MethodDescription\")  Variables <- hymetDP::create_variables(   L0_flat = flat,   VariableCode = \"VariableCode\",   VariableName = \"VariableName\",   VariableUnitsName = \"VariableUnitsName\",   SampleMedium = \"SampleMedium\",   ValueType = \"ValueType\",   IsRegular = \"IsRegular\",   TimeSupport = \"TimeSupport\",   TimeUnitsName = \"TimeUnitsName\",   DataType = \"DataType\",   GeneralCategory = \"GeneralCategory\",   NoDataValue = \"NoDataValue\")  Sites <- hymetDP::create_sites(   L0_flat = flat,   SiteCode = \"SiteCode\",   SiteName = \"SiteName\",   Latitude = \"Latitude\",   Longitude = \"Longitude\",   LatLongDatumSRSName = NULL,   Elevation_m = NULL,   VerticalDatum = NULL,   LocalX = NULL,   LocalY = NULL,   LocalProjectionSRSName = NULL,   PosAccuracy_m = NULL,   State = NULL,   County = NULL,   Comments = NULL,   SiteType = \"SiteType\")  QualityControlLevels <- hymetDP::create_quality_control(   L0_flat = flat,   QualityControlLevelCode = \"QualityControlLevelCode\",   Definition = \"Definition\",   Explanation = \"Explanation\")  DataValues <- hymetDP::create_data_values(   L0_flat = flat,   ValueID = \"ValueID\",   DataValue = \"DataValue\",   ValueAccuracy = NULL,   LocalDateTime = \"LocalDateTime\",   UTCOffset = \"UTCOffset\",   DateTimeUTC = \"DateTimeUTC\",   SiteCode = \"SiteCode\",   VariableCode = \"VariableCode\",   OffsetValue = NULL,   OffsetTypeCode = NULL,   CensorCode = NULL,   QualifierCode = NULL,   MethodCode = \"MethodCode\",   QualityControlLevelCode = \"QualityControlLevelCode\",   SourceCode = \"SourceCode\",   NoDataValue = \"NoDataValue\")  SeriesCatalog <- hymetDP::create_series_catalog(   Sources = Sources,   Methods = Methods,   Variables = Variables,   Sites = Sites,   QualityControlLevels = QualityControlLevels,   DataValues = DataValues)  SeriesCatalog #>   SeriesID SiteCode #> 1        1        1 #> 2        2        1 #> 3        3        1 #>                                                                                                                                              SiteName #> 1 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #> 2 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #> 3 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #>   VariableCode         VariableName           VariableUnitsName  SampleMedium #> 1            1            Discharge           liters per second Surface water #> 2            2          Temperature              degree celsius Surface water #> 3            3 Specific conductance microsiemens per centimeter Surface water #>           ValueType TimeSupport TimeUnitsName   DataType GeneralCategory #> 1     Derived Value          15        minute Continuous       Hydrology #> 2 Field Observation          15        minute Continuous       Hydrology #> 3 Field Observation          15        minute Continuous       Hydrology #>   MethodCode #> 1          1 #> 2          1 #> 3          1 #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      MethodDescription #> 1 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #> 2 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #> 3 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #>   SourceCode             Organization #> 1          1 McMurdo Dry Valleys LTER #> 2          1 McMurdo Dry Valleys LTER #> 3          1 McMurdo Dry Valleys LTER #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         SourceDescription #> 1 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #> 2 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #> 3 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #>                                                                                                                                                                                                                                                                                                                                           Citation #> 1 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #> 2 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #> 3 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #>   QualityControlLevelCode       BeginDateTime         EndDateTime #> 1                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #> 2                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #> 3                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #>      BeginDateTimeUTC      EndDateTimeUTC ValueCount #> 1 2002-01-11 10:45:00 2003-12-25 20:30:00      10001 #> 2 2002-01-11 10:45:00 2003-12-25 20:30:00      10001 #> 3 2002-01-11 10:45:00 2003-12-25 20:30:00      10001"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Sites table — create_sites","title":"Create the Sites table — create_sites","text":"Create Sites table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Sites table — create_sites","text":"","code":"create_sites(   L0_flat,   SiteCode,   SiteName,   Latitude,   Longitude,   LatLongDatumSRSName = NULL,   Elevation_m = NULL,   VerticalDatum = NULL,   LocalX = NULL,   LocalY = NULL,   LocalProjectionSRSName = NULL,   PosAccuracy_m = NULL,   State = NULL,   County = NULL,   Comments = NULL,   SiteType = NULL )"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Sites table — create_sites","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). SiteCode (character) Column L0_flat containing user organization-defined code collects data identify site. SiteName (character) Column L0_flat containing full name sampling site. Latitude (character) Column L0_flat containing latitude decimal degrees. Longitude (character) Column L0_flat containing longitude decimal degrees. LatLongDatumSRSName (character) Column L0_flat containing spatial reference system latitude longitude coordinates. Choose SRSName IsGeographic=True SpatialReferencesCV. View possible options `SpatialReferencesCV$SRSName[SpatialReferencesCV$IsGeographic]` Elevation_m (character) Column L0_flat containing elevation sampling location meters. VerticalDatum (character) Column L0_flat containing Vertical datum elevation. Choose Term VerticalDatum controlled vocabulary. LocalX (character) Column L0_flat containing local projection X coordinate. LocalY (character) Column L0_flat containing local projection Y coordinate. LocalProjectionSRSName (character) Column L0_flat containing full text name spatial reference system local coordinates. field optional necessary local coordinates given. Choose SRSName SpatialReferencesCV. PosAccuracy_m (character) Column L0_flat containing value giving accuracy positional information specified meters. State (character) Column L0_flat containing name state monitoring site located. County (character) Column L0_flat containing name county monitoring site located. Comments (character) Column L0_flat containing comments related site. SiteType (character) Column L0_flat containing type site. Choose Term SiteTypeCV.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sites.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Sites table — create_sites","text":"(tbl_df, tbl, data.frame) Sites table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sites.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Sites table — create_sites","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Sites table — create_sites","text":"","code":"flat <- hymet_L0_flat    Sites <- hymetDP::create_sites(     L0_flat = flat,     SiteCode = \"SiteCode\",     SiteName = \"SiteName\",     Latitude = \"Latitude\",     Longitude = \"Longitude\",     LatLongDatumSRSName = NULL,     Elevation_m = NULL,     VerticalDatum = NULL,     LocalX = NULL,     LocalY = NULL,     LocalProjectionSRSName = NULL,     PosAccuracy_m = NULL,     State = NULL,     County = NULL,     Comments = NULL,     SiteType = \"SiteType\")    Sites #> # A tibble: 1 × 15 #>   SiteCode SiteName              Latitude Longitude LatLongDatumSRS… Elevation_m #>   <chr>    <chr>                    <dbl>     <dbl> <chr>                  <dbl> #> 1 1        USGS site 9; coordin…    -77.6      163. Unknown                   NA #> # … with 9 more variables: VerticalDatum <chr>, LocalX <dbl>, LocalY <dbl>, #> #   LocalProjectionSRSName <chr>, PosAccuracy_m <dbl>, State <chr>, #> #   County <chr>, Comments <chr>, SiteType <chr>"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sources.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Sources table — create_sources","title":"Create the Sources table — create_sources","text":"Create Sources table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Sources table — create_sources","text":"","code":"create_sources(   L0_flat,   SourceCode,   Organization,   SourceDescription,   SourceLink = NULL,   ContactName,   Phone,   Email,   Address,   City,   State,   ZipCode,   Citation )"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Sources table — create_sources","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). SourceCode (character) Column L0_flat containing code identifies organization created data. Organization (character) Column L0_flat containing name organization collected data. SourceDescription (character) Column L0_flat containing full text description source data. SourceLink (character) Column L0_flat containing link original data file data source. ContactName (character) Column L0_flat containing name contact person data source. Phone (character) Column L0_flat containing phone number contact person. Email (character) Column L0_flat containing email address contact person. Address (character) Column L0_flat containing street address contact person. City (character) Column L0_flat containing city contact person located. State (character) Column L0_flat containing state contact person located. ZipCode (character) Column L0_flat containing US Zip Code country postal code. Citation (character) Column L0_flat containing Text string gives citation used data source referenced.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sources.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Sources table — create_sources","text":"(tbl_df, tbl, data.frame) Sources table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sources.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Sources table — create_sources","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.#'","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/reference/create_sources.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Sources table — create_sources","text":"","code":"flat <- hymet_L0_flat    Sources <- hymetDP::create_sources(     L0_flat = flat,     SourceCode = \"SourceCode\",     Organization = \"Organization\",     SourceDescription = \"SourceDescription\",     SourceLink = \"SourceLink\",     ContactName = \"ContactName\",     Phone = \"Phone\",     Email = \"Email\",     Address = \"Address\",     City = \"City\",     State = \"State\",     ZipCode = \"ZipCode\",     Citation = \"Citation\")    Sources #> # A tibble: 1 × 12 #>   SourceCode Organization    SourceDescripti… SourceLink ContactName Phone Email #>   <chr>      <chr>           <chr>            <chr>      <chr>       <chr> <chr> #> 1 1          McMurdo Dry Va… As part of the … https://d… McMurdo Dr… Unkn… im@m… #> # … with 5 more variables: Address <chr>, City <chr>, State <chr>, #> #   ZipCode <chr>, Citation <chr>"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Variables table — create_variables","title":"Create the Variables table — create_variables","text":"Create Variables table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Variables table — create_variables","text":"","code":"create_variables(   L0_flat,   VariableCode,   VariableName,   VariableUnitsName,   SampleMedium,   ValueType,   IsRegular,   TimeSupport,   TimeUnitsName,   DataType,   GeneralCategory,   NoDataValue )"},{"path":"https://EDIorg.github.io/hymetDP/reference/create_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Variables table — create_variables","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). VariableCode (character) Column L0_flat containing user organization-defined code describe variable. VariableName (character) Column L0_flat containing full text name variable measured, observed, modeled, etc. Must ODM CV (see VariableNameCV) VariableUnitsName (character) Column L0_flat containing name units data values associated variable. Must ODM CV (see UnitsCV) SampleMedium (character) Column L0_flat containing medium sample observation taken made. Must ODM CV (see SampleMediumCV) ValueType (character) Column L0_flat indicates data value generated. Must ODM CV (see ValueTypeCV) IsRegular (character) Column L0_flat indicates whether data values regularly sampled time series. TimeSupport (character) Column L0_flat containing numerical value indicates time support (temporal footprint) data values. 0 used indicate data values instantaneous. values indicate time data values implicitly explicitly averaged aggregated. TimeUnitsName (character) Column L0_flat containing name units time support. TimeSupport 0, indicating instantaneous observation, unit needs still given completeness, although arbitrary. Must ODM CV (see UnitsCV) DataType (character) Column L0_flat indicates value applies time interval. Must ODM CV (see DataTypeCV) GeneralCategory (character) Column L0_flat containing general category data. Must ODM CV (see GeneralCategoryCV) NoDataValue (character) Column L0_flat containing numeric value used encode data value available variable.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Variables table — create_variables","text":"(tbl_df, tbl, data.frame) Variables table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/create_variables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Variables table — create_variables","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://EDIorg.github.io/hymetDP/reference/create_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Variables table — create_variables","text":"","code":"flat <- hymet_L0_flat    Variables <- hymetDP::create_variables(     L0_flat = flat,     VariableCode = \"VariableCode\",     VariableName = \"VariableName\",     VariableUnitsName = \"VariableUnitsName\",     SampleMedium = \"SampleMedium\",     ValueType = \"ValueType\",     IsRegular = \"IsRegular\",     TimeSupport = \"TimeSupport\",     TimeUnitsName = \"TimeUnitsName\",     DataType = \"DataType\",     GeneralCategory = \"GeneralCategory\",     NoDataValue = \"NoDataValue\")    Variables #> # A tibble: 3 × 11 #>   VariableCode VariableName    VariableUnitsNa… SampleMedium ValueType IsRegular #>   <chr>        <chr>           <chr>            <chr>        <chr>     <lgl>     #> 1 1            Discharge       liters per seco… Surface wat… Derived … TRUE      #> 2 2            Temperature     degree celsius   Surface wat… Field Ob… TRUE      #> 3 3            Specific condu… microsiemens pe… Surface wat… Field Ob… TRUE      #> # … with 5 more variables: TimeSupport <dbl>, TimeUnitsName <chr>, #> #   DataType <chr>, GeneralCategory <chr>, NoDataValue <dbl>"},{"path":"https://EDIorg.github.io/hymetDP/reference/define_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP method — define_method","title":"Define a hymetDP method — define_method","text":"Define hymetDP method","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP method — define_method","text":"","code":"define_method(   L0_flat,   local_variable_column = \"variable_name\",   local_variable = NULL,   VariableCode = NULL,   MethodDescription = NULL,   MethodLink = NULL )"},{"path":"https://EDIorg.github.io/hymetDP/reference/define_method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP method — define_method","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). local_variable_column (character) Column L0_flat table containing L0 variable name. local_variable (character) Reference value (values) local_variable_column L0_flat table new hymetDP method refers. VariableCode (character) auto-generated primary key variable (column VariableCode). Another way link method value (values). Takes priority local_variable. Provide one multiple codes. MethodDescription (character) Text description method. MethodLink (character) Optional. Link additional reference material method. single valid URL.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP method — define_method","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus one additional column method description (two additional columns method link defined). Column name includes auto-generated MethodCode (.e. MethodDescription_1), become primary key Methods table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_method.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP method — define_method","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a hymetDP method — define_method","text":"","code":"flat <- hymet_L0_flat[1:19]  flat <- hymetDP::define_method(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = \"DSCHRGE_RATE\",   VariableCode = c(1,2,3),   MethodDescription = paste(     \"Campbell CR10 dataloggers were used to record stream stage, water\",     \"temperature, and conductivity in a network of stream gages.\",     \"Stage is monitored with pressure transducers; PSS-1 and PS-2 models\",     \"form Paroscientific Corporation, and Accubars from Sutron\",     \"Corporation. The pressure transducers measure the backpressure in\",     \"orifice lines set into or above controls in the stream channel. In\",     \"addition, some of the sites monitor water temperature and\",     \"conductivity with either USGS minimonitor probes, or Campbell\",     \"temperature/conductivity probes. Ratings are developed for the\",     \"stage/discharge relationship at each site by measuring streamflow\",     \"with current meters or portable flumes, according to standard USGS\",     \"methods. Datum corrections to the stage are determined by\",     \"periodically surveying the elevation of the orifice line to the\",     \"control and nearby reference marks. Calibrations for the\",     \"temperature and conductivity are assessed by measuring these\",     \"parameters with portable field meters while simultaneously noting\",     \"the readings from the gage probes. Data is downloaded into Campbell\",     \"storage modules, and retrieved into pcs. From there, the data is\",     \"sent to a USGS computer, where time discrepancies are resolved, and\",     \"the data is loaded into ADAPS, a database system developed in the\",     \"USGS for maintaining and processing water data. A determination for\",     \"each site as to when the stream was flowing and when it was not is\",     \"made. For water temperature and conductivity, bad data is deleted.\",     \"Variable shifts are determined based on field calibration\",     \"measurements, and other indicators. The shifts are applied to the\",     \"remaining good data inside of ADAPS. The data is pulled out of\",     \"ADAPS, and reformatted for input into ORACLE. Cases of water\",     \"temperature below reasonable values are set to lower limits. A\",     \"quality code is assigned to every value. The resulting data is\",     \"uploaded into the ORACLE and the McMurdo database. Before 2011, For\",     \"stage/discharge, bad data is deleted. Survey data is reviewed to\",     \"compute weir elevations an datum corrections. A rating curve is\",     \"developed graphically, based on available data, and entered into\",     \"ADAPS. All applicable shifts and datum corrections are entered into\",     \"ADAPS. All corrections and ratings are run against the good stage\",     \"data to compute the discharge at each recording interval. The data\",     \"is pulled out of ADAPS, and reformatted for input into ORACLE. A\",     \"quality code is assigned to every value. The resulting data is\",     \"uploaded into ORACLE and the McMurdo database. ADAPS deprecated in\",     \"favor of Aquarius software in 2012. Similar procedure is used in\",     \"Aquarius to convert and curate the data. Metadata was enhanced in\",     \"2013 and 2014 by Inigo San Gil. In March 2021, data from the\",     \"2016-17 field season was replaced to correct a previously published\",     \"error, in which discharge was reported in cubicFeetPerSecond (CFS)\",     \"instead of litersPerSecond (l/s).\"     ),   MethodLink = NULL)"},{"path":"https://EDIorg.github.io/hymetDP/reference/define_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP source — define_source","title":"Define a hymetDP source — define_source","text":"Define hymetDP source","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_source.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP source — define_source","text":"","code":"define_source(   L0_flat,   eml = eml,   Organization = NULL,   SourceDescription = NULL,   SourceLink = NULL,   ContactName = NULL,   Phone = NULL,   Email = NULL,   Address = NULL,   City = NULL,   State = NULL,   ZipCode = NULL,   Citation = NULL )"},{"path":"https://EDIorg.github.io/hymetDP/reference/define_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP source — define_source","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). eml ('xml_document' 'xml_node') EML metadata. Organization (character) Name organization collected data. SourceDescription (character) Full text description source data. provided, default abstract EML document. SourceLink (character) Optional. Full text description source data. provided, default DOI EML document. ContactName (character) Name contact person data source. provided, contact information default first contact listed EML document. Phone (character) Phone number contact person. Email (character) Email addresss contact person. Address (character) Street address contact person. City (character) City contact person located. State (character) State contact person located. Use two letter abbreviations US. countries give full country name. ZipCode (character) US Zip Code country postal code. Citation (character) Text string gives citation used data source referenced. provided, default Citation appears (appear) EDI Data Portal EML document.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_source.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP source — define_source","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus additional columns Source information.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_source.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP source — define_source","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_source.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a hymetDP source — define_source","text":"","code":"flat <- hymet_L0_flat[1:30]  eml <- read_metadata('knb-lter-mcm.9003.11')  flat <- define_source(   L0_flat = flat,   eml = eml) #> SourceDescription added #> SourceLink added #> Citation added #> Contact Info Added"},{"path":"https://EDIorg.github.io/hymetDP/reference/define_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP variable — define_variable","title":"Define a hymetDP variable — define_variable","text":"Define hymetDP variable","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP variable — define_variable","text":"","code":"define_variable(   L0_flat,   local_variable_column = \"variable_name\",   local_variable = NULL,   variable_name = local_variable,   variable_units = NULL,   sample_medium = \"Unknown\",   value_type = \"Unknown\",   is_regular = FALSE,   time_support = 0,   time_units = \"hour\",   data_type = \"Unknown\",   general_category = \"Unknown\",   no_data = -9999 )"},{"path":"https://EDIorg.github.io/hymetDP/reference/define_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP variable — define_variable","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). local_variable_column (character) Column L0_flat table containing L0 variable name. local_variable (character) Reference value local_variable_column L0_flat table new hymetDP variable refers. variable_name (character) CUAHSI ODM Controlled Vocabulary name variable measured, observed, modeled, etc. Defaults local_variable value. variable_units (character) CUAHSI ODM Controlled Vocabulary name units data values associated variable. Defaults column unit L0_flat table left unspecified. sample_medium (character) CUAHSI ODM Controlled Vocabulary name medium sample observation taken made. value_type (character) CUAHSI ODM Controlled Vocabulary value indicates data value generated. is_regular (boolean) Value indicates whether data values regularly sampled time series. Choose TRUE FALSE. time_support (numeric) Numerical value indicates time support (temporal footprint) data values. 0 used indicate data values instantaneous. values indicate time data values implicitly explicitly averaged aggregated. Goes along time_units is_regular == TRUE. time_units (character) CUAHSI ODM Controlled Vocabulary name units time support. time_support == 0, indicating instantaneous observation, unit needs still given completeness, although arbitrary. data_type (character) CUAHSI ODM Controlled Vocabulary value indicates value applies time interval. general_category (character) CUAHSI ODM Controlled Vocabulary value general category data  (.e. Hydrology). no_data (numeric) Numeric value used encode data value available variable. DataValues reformatted match value.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP variable — define_variable","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus one specified variable values (.e. variable_name, variable_units, etc.), plus VariableCode column, auto-generated integer value become primary key Variables table. Columns added first time function run. Subsequent runs append values existing columns.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_variable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP variable — define_variable","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/define_variable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a hymetDP variable — define_variable","text":"","code":"flat <- hymet_L0_flat[1:8]  flat <- hymetDP::define_variable(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = \"DSCHRGE_RATE\",   variable_name = \"Discharge\",   variable_units = \"liters per second\",   sample_medium = \"Surface water\",   value_type = \"Derived Value\",   is_regular = TRUE,   time_support = 15,   time_units = \"minute\",   data_type = \"Continuous\",   general_category = \"Hydrology\",   no_data = -9999)"},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_sitetype.html","id":null,"dir":"Reference","previous_headings":"","what":"Get USGS site type — get_usgs_sitetype","title":"Get USGS site type — get_usgs_sitetype","text":"Get USGS site type","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_sitetype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get USGS site type — get_usgs_sitetype","text":"","code":"get_usgs_sitetype(s)"},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_sitetype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get USGS site type — get_usgs_sitetype","text":"s (character) USGS site type code site_type_cd","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_sitetype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get USGS site type — get_usgs_sitetype","text":"Site type","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Get USGS variable information — get_usgs_variable","title":"Get USGS variable information — get_usgs_variable","text":"Get USGS variable information","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get USGS variable information — get_usgs_variable","text":"","code":"get_usgs_variable(p)"},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get USGS variable information — get_usgs_variable","text":"p (character) USGS parameter code param","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/get_usgs_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get USGS variable information — get_usgs_variable","text":"Information associated USGS variable","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L0_flat.html","id":null,"dir":"Reference","previous_headings":"","what":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"fully joined flat version EDI data package knb-lter-mcm.9003.11 (Seasonal high-frequency measurements discharge, water temperature, specific conductivity Andersen Creek H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing)) relevant hymetDP L1 identifiers content added. Use dataset input L0_flat argument \"create\" functions.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L0_flat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"","code":"hymet_L0_flat"},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L0_flat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"data frame 30,000 rows 45 variables: LocalDateTime Local datetime UTCOffset Local timezone offset UTC DateTimeUTC Datetime UTC variable_name Variable name L0 dataset DataValue Numeric value observation Qualifier Code qualifier (flag) unit Unit name L0 dataset ValueID data value ID VariableCode variable ID VariableName ODM CV variable name VariableUnitsName ODM CV unit name variable SampleMedium ODM CV sample medium name ValueType ODM CV value type IsRegular Whether values regularly sampled dataset TimeSupport Temporal footprint samples TimeUnitsName ODM CV unit name time support DataType ODM CV data type GeneralCategory ODM CV general category NoDataValue numeric value used encode available data MethodCode method ID MethodDescription description method SiteCode site ID SiteName name site Latitude Latitude site Longitude Longitude site Elevation_m Elevation site meters SiteType ODM CV site type Organization Name organization collected data ContactName Name contact person data source Email Email contact SourceCode source ID SourceDescription description source data SourceLink URL source data Citation Citation source data Phone Contact phone Address Contact physical address City Contact city State Contact state US, otherwise full country name ZipCode Contact postal code QualityControlLevelCode quality control ID Definition Definition quality control level Explanation Explanation quality control level QualifierCode qualifier ID QualifierDescription Description qualifier","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L0_flat.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-mcm&identifier=9003&revision=11","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L1.html","id":null,"dir":"Reference","previous_headings":"","what":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"hymetDP (L1) formatted version EDI data package knb-lter-mcm.9003.11 (Seasonal high-frequency measurements discharge, water temperature, specific conductivity Andersen Creek H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing)) produced table hymet_L0_flat. Use dataset input data \"use\" functions.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"","code":"hymet_L1"},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"list : id dataset identifier metadata See source url metadata tables list data frames, hymetDP table","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/hymet_L1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"hymet_L0_flat","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://EDIorg.github.io/hymetDP/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Read published data — read_data","title":"Read published data — read_data","text":"Read published data","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read published data — read_data","text":"","code":"read_data(   id = NULL,   parse_datetime = TRUE,   unique_keys = FALSE,   from = NULL,   format = \"new\" )"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read published data — read_data","text":"id (character) Identifier dataset read. Identifiers listed \"id\" column search_data() output. Older versions datasets can read, warning issued. parse_datetime (logical) Parse datetime values TRUE, otherwise return character strings. unique_keys (logical) Whether create globally unique primary keys (associated foreign keys). Useful maintaining referential integrity working multiple datasets. TRUE, id appended table's primary key associated foreign key. Default FALSE. (character) Full path file read (.rds), path directory containing saved datasets (.csv). format (character) Format returned object, can : \"new\" (new implementation) \"old\" (original implementation; deprecated). new format, top level nesting containing \"id\" field moved level \"tables\", \"metadata\", \"validation_issues\" fields.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read published data — read_data","text":"(list) dataset structure: id - Dataset identifier metadata - List info dataset. NOTE: object underdevelopment content may change future releases. tables - List dataset tables data.frames. validation_issues - List validation issues. dataset fails validation checks, descriptions issue listed .","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read published data — read_data","text":"","code":"Validation checks are applied to each dataset ensuring it complies with the hymetDP model. A warning is issued when any validation checks fail. All datasets are returned, even if they fail validation.  Column classes are coerced to those defined in the hymetDP specification.  Validation happens each time files are read, from source APIs or local environments."},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Read published data — read_data","text":"function may work 01:00 - 03:00 UTC Wednesdays due regular maintenance EDI Data Repository.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data package report — read_data_package_report","title":"Read data package report — read_data_package_report","text":"Read data package report","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data package report — read_data_package_report","text":"","code":"read_data_package_report(packageId, frmt = \"xml\", env = \"production\")"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data package report — read_data_package_report","text":"packageId (character) Data package identifier frmt (character) Format returned report. Can : \"xml\", \"html\", \"char\". env (character) Repository environment. Can : \"production\", \"staging\", \"development\".","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data package report — read_data_package_report","text":"(xml_document) Data package report","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read data package report — read_data_package_report","text":"","code":"# Read as XML qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\") qualityReport #> {xml_document} #> <qualityReport schemaLocation=\"eml://ecoinformatics.org/qualityReport https://raw.githubusercontent.com/PASTAplus/PASTA/master/DataPackageManager/WebRoot/xml/qualityReportSchema.xsd\" xmlns=\"eml://ecoinformatics.org/qualityReport\" xmlns:qr=\"eml://ecoinformatics.org/qualityReport\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> #>  [1] <creationDate>2020-02-04T16:38:38<\/creationDate> #>  [2] <packageId>knb-lter-knz.260.4<\/packageId> #>  [3] <includeSystem>lter<\/includeSystem> #>  [4] <includeSystem>knb<\/includeSystem> #>  [5] <datasetReport>\\n  <qualityCheck qualityType=\"metadata\" system=\"lter\" st ... #>  [6] <entityReport>\\n  <entityName>GIS600<\/entityName>\\n  <qualityCheck quali ... #>  [7] <entityReport>\\n  <entityName>KMZGIS600<\/entityName>\\n  <qualityCheck qu ... #>  [8] <entityReport>\\n  <entityName>GIS605<\/entityName>\\n  <qualityCheck quali ... #>  [9] <entityReport>\\n  <entityName>KMZGIS605<\/entityName>\\n  <qualityCheck qu ... #> [10] <entityReport>\\n  <entityName>GIS610<\/entityName>\\n  <qualityCheck quali ... #> [11] <entityReport>\\n  <entityName>KMZGIS610<\/entityName>\\n  <qualityCheck qu ... #> [12] <entityReport>\\n  <entityName>GIS615<\/entityName>\\n  <qualityCheck quali ... #> [13] <entityReport>\\n  <entityName>KMZGIS615<\/entityName>\\n  <qualityCheck qu ... #> [14] <entityReport>\\n  <entityName>GIS620<\/entityName>\\n  <qualityCheck quali ... #> [15] <entityReport>\\n  <entityName>KMZGIS620<\/entityName>\\n  <qualityCheck qu ... #> [16] <entityReport>\\n  <entityName>GIS630<\/entityName>\\n  <qualityCheck quali ... #> [17] <entityReport>\\n  <entityName>KMZGIS630<\/entityName>\\n  <qualityCheck qu ... #> [18] <entityReport>\\n  <entityName>GIS635<\/entityName>\\n  <qualityCheck quali ... #> [19] <entityReport>\\n  <entityName>KMZGIS635<\/entityName>\\n  <qualityCheck qu ...  # Read as HTML qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\", frmt = \"html\") qualityReport #> {html_document} #> <html> #> [1] <body><table xmlns:qr=\"eml://ecoinformatics.org/qualityReport\"><tbody>\\n< ...  # Read as character qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\", frmt = \"char\") # writeLines(qualityReport, \"./data/report.txt\"))"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report_hymet.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data package report — read_data_package_report_hymet","title":"Read data package report — read_data_package_report_hymet","text":"Read data package report","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report_hymet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data package report — read_data_package_report_hymet","text":"","code":"read_data_package_report_hymet(packageId, frmt = \"xml\", env = \"production\")"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report_hymet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data package report — read_data_package_report_hymet","text":"packageId (character) Data package identifier frmt (character) Format returned report. Can : \"xml\", \"html\", \"char\". env (character) Repository environment. Can : \"production\", \"staging\", \"development\".","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report_hymet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data package report — read_data_package_report_hymet","text":"(xml_document) Data package report","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_data_package_report_hymet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read data package report — read_data_package_report_hymet","text":"","code":"# Read as XML qualityReport <- read_data_package_report_hymet(\"knb-lter-knz.260.4\") qualityReport #> {xml_document} #> <qualityReport schemaLocation=\"eml://ecoinformatics.org/qualityReport https://raw.githubusercontent.com/PASTAplus/PASTA/master/DataPackageManager/WebRoot/xml/qualityReportSchema.xsd\" xmlns=\"eml://ecoinformatics.org/qualityReport\" xmlns:qr=\"eml://ecoinformatics.org/qualityReport\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> #>  [1] <creationDate>2020-02-04T16:38:38<\/creationDate> #>  [2] <packageId>knb-lter-knz.260.4<\/packageId> #>  [3] <includeSystem>lter<\/includeSystem> #>  [4] <includeSystem>knb<\/includeSystem> #>  [5] <datasetReport>\\n  <qualityCheck qualityType=\"metadata\" system=\"lter\" st ... #>  [6] <entityReport>\\n  <entityName>GIS600<\/entityName>\\n  <qualityCheck quali ... #>  [7] <entityReport>\\n  <entityName>KMZGIS600<\/entityName>\\n  <qualityCheck qu ... #>  [8] <entityReport>\\n  <entityName>GIS605<\/entityName>\\n  <qualityCheck quali ... #>  [9] <entityReport>\\n  <entityName>KMZGIS605<\/entityName>\\n  <qualityCheck qu ... #> [10] <entityReport>\\n  <entityName>GIS610<\/entityName>\\n  <qualityCheck quali ... #> [11] <entityReport>\\n  <entityName>KMZGIS610<\/entityName>\\n  <qualityCheck qu ... #> [12] <entityReport>\\n  <entityName>GIS615<\/entityName>\\n  <qualityCheck quali ... #> [13] <entityReport>\\n  <entityName>KMZGIS615<\/entityName>\\n  <qualityCheck qu ... #> [14] <entityReport>\\n  <entityName>GIS620<\/entityName>\\n  <qualityCheck quali ... #> [15] <entityReport>\\n  <entityName>KMZGIS620<\/entityName>\\n  <qualityCheck qu ... #> [16] <entityReport>\\n  <entityName>GIS630<\/entityName>\\n  <qualityCheck quali ... #> [17] <entityReport>\\n  <entityName>KMZGIS630<\/entityName>\\n  <qualityCheck qu ... #> [18] <entityReport>\\n  <entityName>GIS635<\/entityName>\\n  <qualityCheck quali ... #> [19] <entityReport>\\n  <entityName>KMZGIS635<\/entityName>\\n  <qualityCheck qu ...  # Read as HTML qualityReport <- read_data_package_report_hymet(\"knb-lter-knz.260.4\", frmt = \"html\") qualityReport #> {html_document} #> <html> #> [1] <body><table xmlns:qr=\"eml://ecoinformatics.org/qualityReport\"><tbody>\\n< ...  # Read as character qualityReport <- read_data_package_report_hymet(\"knb-lter-knz.260.4\", frmt = \"char\") # writeLines(qualityReport, \"./data/report.txt\"))"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Read metadata — read_metadata","title":"Read metadata — read_metadata","text":"Read metadata","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read metadata — read_metadata","text":"","code":"read_metadata(packageId, env = \"production\")"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read metadata — read_metadata","text":"packageId (character) Data package identifier env (character) Repository environment. Can : \"production\", \"staging\", \"development\".","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read metadata — read_metadata","text":"(xml_document) EML metadata document. See emld library working EML list JSON-LD. See xml2 library working EML XML.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read metadata — read_metadata","text":"","code":"if (FALSE) {  # Read metadata eml <- read_metadata(\"edi.100.1\") eml #> {xml_document} #> <eml packageId=\"edi.100.1\" system=\"https://pasta.edirepository.org\"   ... #> [1] <access authSystem=\"https://pasta.edirepository.org/authenticatio ... #> [2] <dataset>\\n  <alternateIdentifier system=\"https://doi.org\">doi:10 ... }"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data tables of a data package — read_tables","title":"Read data tables of a data package — read_tables","text":"Read data tables data package EML metadata.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data tables of a data package — read_tables","text":"","code":"read_tables(   eml,   strip.white = FALSE,   na.strings = NULL,   convert.missing.value = NULL,   add.units = FALSE,   table.names = NULL )"},{"path":"https://EDIorg.github.io/hymetDP/reference/read_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data tables of a data package — read_tables","text":"eml (xml_document, xml_node) EML metadata returned read_eml(). strip.white (logical) Strips leading trailing whitespaces unquoted fields. Default FALSE. na.strings (character) Strings interpreted NA. Setting na.strings = \"\" converts \"\" NA. default, blank strings \"\" read . convert.missing.value (logical) Converts missing value codes specified eml (e.g. \"-99999\", \"NaN\", \"measured\") NA. Missing value codes vary across data packages converting consistent form recognized R makes downstream use simpler. However, care must exercised using argument. author dataset described eml may defined \"missing value code\" mean something different expect (e.g. \"detection limit\") therefore reviewing authors missing value code definitions good idea. Default FALSE. add.units (logical) TRUE, variable's unit measurement added table separate column column name form: <unit>_<variable_name>. argument useful gathering variables long (attribute-value) table. table.names (character) Character vector one table names (<objectName> EML) selectively download tables.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data tables of a data package — read_tables","text":"(list) List named data frames","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_tables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read data tables of a data package — read_tables","text":"function uses data.table::fread() uses default argument values EML based values return error. Default settings preserve form data originally published .","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/read_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read data tables of a data package — read_tables","text":"","code":"if (FALSE) { eml <- read_metadata('knb-lter-mcm.9003.11')  tables <- read_tables(   eml = eml,   strip.white = TRUE,   na.strings = \"\",   convert.missing.value = TRUE,   add.units = TRUE)  }"},{"path":"https://EDIorg.github.io/hymetDP/reference/return_close.html","id":null,"dir":"Reference","previous_headings":"","what":"Return values from the CV that may be close to users' term — return_close","title":"Return values from the CV that may be close to users' term — return_close","text":"Return values CV may close users' term","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/return_close.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return values from the CV that may be close to users' term — return_close","text":"","code":"return_close(term, cv)"},{"path":"https://EDIorg.github.io/hymetDP/reference/return_close.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return values from the CV that may be close to users' term — return_close","text":"term (character) user-provided term needs validated cv (character) \"Term\" column corresponding CV","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/return_close.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return values from the CV that may be close to users' term — return_close","text":"(list) Named list CV entries contain string","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/search_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Search published data — search_data","title":"Search published data — search_data","text":"Search published data","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/search_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search published data — search_data","text":"","code":"search_data(   text,   VariableName,   SampleMedium,   GeneralCategory,   SiteType,   TimeSupport,   starts_before,   ends_after,   num_years,   area,   boolean = \"AND\" )"},{"path":"https://EDIorg.github.io/hymetDP/reference/search_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search published data — search_data","text":"text (character) Text search dataset titles abstracts. Datasets matching exact words phrase returned. Can regular expression used stringr::str_detect(). case sensitive. Works boolean. VariableName (character) VariableName values search . VariableName values ODM Controlled Vocabulary. SampleMedium (character) SampleMedium values search . SampleMedium values ODM Controlled Vocabulary. GeneralCategory (character) GeneralCategory values search . GeneralCategory values ODM Controlled Vocabulary. SiteType (character) SiteType values search . SiteType values ODM Controlled Vocabulary. TimeSupport (numeric) Maximum TimeSupport value search . TimeSupport analogous frequency measurements. starts_before (date) Maximum start date filter . ends_after (date) Minimum end date filter . num_years (numeric) Minimum maximum number years sampled dataset contain. datasets within range returned. area (numeric) Bounding coordinates within data originate. Accepted values decimal degrees order: North, East, South, West. datasets overlapping areas contained points returned. boolean (character) Boolean operator use searching text, VariableName, SampleMedium, GeneralCategory, SiteType. Supported operators : \"\", \"\". Default \"\".","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/search_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search published data — search_data","text":"(tbl_df, tbl, data.frame) Search results fields: source - Source dataset originates. Currently supported \"EDI\" \"NEON\". id - Identifier dataset. title - Title dataset. abstract - Abstract dataset. years - Number years sampled. url - URL dataset. source_id - Identifier source L0 dataset. source_id_url - URL source L0 dataset.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/search_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search published data — search_data","text":"","code":"if (FALSE) { # Empty search returns all available datasets search_data()  # \"text\" searches titles, descriptions, and abstracts search_data(text = \"barometric\")  # \"VariableName\" searches VariableName values for a match search_data(VariableName = \"Discharge\")  # \"SampleMedium\" searches SampleMedium values for a match search_data(SampleMedium = \"Water\")  # \"GeneralCategory\" searches GeneralCategory values for a match search_data(GeneralCategory = \"Hydrology\")  # \"SiteType\" searches SiteType values for a match search_data(SiteType = \"Stream\")  # \"TimeSupport\" searches TimeSupport values for a match search_data(TimeSupport = 30)  # \"starts_before\" and \"ends_after\" can be used to filter on a time period search_data(starts_before = '2000-01-01', ends_after = '2010-01-01')  # \"num_years\" searches the number of years sampled search_data(num_years = c(10, 20))  # Use any combination of search fields to find the data you're looking for search_data(   text = c(\"stream\", \"river\"),   VariableName = c(\"Conductivity\", \"Discharge\"),   SampleMedium = \"water\",   GeneralCategory = \"hydrology\",   SiteType = \"Stream\",   TimeSupport = 30,   starts_before = \"2010-01-01\",   ends_after = \"2015-01-01\",   num_years = c(10, 100),   area = c(47.1, -86.7, 42.5, -92),   boolean = \"OR\") }"},{"path":"https://EDIorg.github.io/hymetDP/reference/supported_USGS_params.html","id":null,"dir":"Reference","previous_headings":"","what":"hymetDP Supported USGS parameters — supported_USGS_params","title":"hymetDP Supported USGS parameters — supported_USGS_params","text":"USGS NWIS parameter codes can reformatted hymetDP create_USGS_hymet()","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/supported_USGS_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"hymetDP Supported USGS parameters — supported_USGS_params","text":"","code":"supported_USGS_params"},{"path":"https://EDIorg.github.io/hymetDP/reference/supported_USGS_params.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"hymetDP Supported USGS parameters — supported_USGS_params","text":"data frame 1 row 11 variables: usgs_code USGS Parameter Code VariableName Corresponding hymetDP/ODM CV term VariableName VariableUnitsName Corresponding hymetDP/ODM CV term VariableUnitsName SampleMedium Corresponding hymetDP/ODM CV term SampleMedium ValueType Corresponding hymetDP/ODM CV term ValueType IsRegular Corresponding hymetDP/ODM CV term IsRegular TimeSupport Corresponding hymetDP/ODM CV term TimeSupport TimeUnitsName Corresponding hymetDP/ODM CV term TimeUnitsName DataType Corresponding hymetDP/ODM CV term DataType GeneralCategory Corresponding hymetDP/ODM CV term GeneralCategory NoDataValue Corresponding hymetDP/ODM CV term NoDataValue","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/template_hymet.html","id":null,"dir":"Reference","previous_headings":"","what":"Template create_hymetDP.R script — template_hymet","title":"Template create_hymetDP.R script — template_hymet","text":"Template create_hymetDP.R script","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/template_hymet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Template create_hymetDP.R script — template_hymet","text":"","code":"template_hymet(path, dir.name)"},{"path":"https://EDIorg.github.io/hymetDP/reference/template_hymet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Template create_hymetDP.R script — template_hymet","text":"path (character) Path new directory created dir.name (character) Name new directory contain create_hymetDP.R script","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/template_hymet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Template create_hymetDP.R script — template_hymet","text":"Empty create_hymetDP.R script.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/template_hymet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Template create_hymetDP.R script — template_hymet","text":"","code":"if (FALSE) { template_hymet(tempdir(), 'my_hymet') }"},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_arguments.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate arguments of hymetDP functions — validate_arguments","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"Validate input arguments to hymetDP functions."},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_arguments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"validate_arguments(fun.name, fun.args)"},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_arguments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate arguments of hymetDP functions — validate_arguments","text":"fun.name (character) Name function validate_arguments() called. fun.args (named list) Arguments passed calling function formatted .list(environment()).","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_arguments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"Validation checks are function specific."},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate tables against the model — validate_data","title":"Validate tables against the model — validate_data","text":"Validate tables model","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate tables against the model — validate_data","text":"","code":"validate_data(dataset = NULL, path = NULL)"},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate tables against the model — validate_data","text":"dataset (list) dataset structure returned read_data(). path (character) Path directory containing hymetDP tables files.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate tables against the model — validate_data","text":"(list) checks fail, list validation issues returned along warning. issues found NULL returned.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate tables against the model — validate_data","text":"Validation checks: File names - File names hymetDP table names. Table presence - Required tables present. Column names - Column names tables match model. Column presence - Required columns present. Column classes - Column classes match model specification. Datetime format - Date time formats follow model specification. Primary keys - Primary keys tables unique. Composite keys - Composite keys (unique constraints) table unique. Referential integrity - Foreign keys corresponding primary key. Coordinate format - Values decimal degree format. Coordinate range - Values within -90 90 -180 180. Elevation - Values less Mount Everest (8848 m) greater Mariana Trench (-10984 m). CV Terms - Terms used valid ODM controlled vocabulary terms, required.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Validate tables against the model — validate_data","text":"function used hymetDP creators (ensure created valid), maintainers (improve quality archived hymetDP datasets), users (ensure data used free error).","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate tables against the model — validate_data","text":"","code":"if (FALSE) { # Write a set of hymetDP tables to file for validation  mydir <- paste0(tempdir(), \"/dataset\") dir.create(mydir) write_tables(   path = mydir,   DataValues = hymet_L1$tables$DataValues,   Methods = hymet_L1$tables$Methods,   Variables = hymet_L1$tables$Variables,   Sources = hymet_L1$tables$Sources,   Sites = hymet_L1$tables$Sites,   QualityControlLevels = hymet_L1$tables$QualityControlLevels,   Qualifiers = hymet_L1$tables$Qualifiers,   SeriesCatalog = hymet_L1$tables$SeriesCatalog)  # Validate validate_data(path = mydir)  # Clean up unlink(mydir, recursive = TRUE) }"},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_odm_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"Validate input arguments to hymetDP functions that should have direct matches to terms in CUAHSI ODM CVs."},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_odm_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"validate_odm_terms(fun.name, fun.args)"},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_odm_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"fun.name (character) Name function validate_omd_terms() called. fun.args (named list) Arguments passed calling function formatted .list(environment()).","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/validate_odm_terms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"Validation checks are function specific."},{"path":"https://EDIorg.github.io/hymetDP/reference/write_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Write tables to file — write_tables","title":"Write tables to file — write_tables","text":"Write tables file","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/write_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write tables to file — write_tables","text":"","code":"write_tables(   path,   sep = \",\",   DataValues = NULL,   Variables = NULL,   Methods = NULL,   Sources = NULL,   Sites = NULL,   QualityControlLevels = NULL,   SeriesCatalog = NULL,   Qualifiers = NULL )"},{"path":"https://EDIorg.github.io/hymetDP/reference/write_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write tables to file — write_tables","text":"path (character) path directory files written. sep (character) Field delimiter use writing files. Default comma. DataValues (tbl_df, tbl, data.frame) DataValues table. Variables (tbl_df, tbl, data.frame) Variables table. Methods (tbl_df, tbl, data.frame) Methods table. Sources (tbl_df, tbl, data.frame) Sources table. Sites (tbl_df, tbl, data.frame) Sites table. QualityControlLevels (tbl_df, tbl, data.frame) QualityControlLevels table. SeriesCatalog (tbl_df, tbl, data.frame) SeriesCatalog table. Qualifiers (tbl_df, tbl, data.frame) Qualifiers table.","code":""},{"path":"https://EDIorg.github.io/hymetDP/reference/write_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write tables to file — write_tables","text":"hymetDP tables sep delimited files","code":""}]
