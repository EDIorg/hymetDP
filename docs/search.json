[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 hymetDP authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kyle Zollo-Venecek. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zollo-Venecek K (2022). hymetDP: Tools Create, Use, Convert hymetDP data. R package version 0.0.0.9000.","code":"@Manual{,   title = {hymetDP: Tools to Create, Use, and Convert hymetDP data},   author = {Kyle Zollo-Venecek},   year = {2022},   note = {R package version 0.0.0.9000}, }"},{"path":[]},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Tools to Create, Use, and Convert hymetDP data","text":"Tools create, use, convert ‘hymetDP’ datasets. ‘hymetDP’ dataset design pattern harmonizing hydrological meteorological data research question agnostic format, source datasets published across multiple repositories, methods keep derived datasets --date underlying sources change. Based ecocomDP R package.","code":""},{"path":"/reference/DataTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Data Types — DataTypeCV","title":"Allowed Data Types — DataTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Data Types","code":""},{"path":"/reference/DataTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Data Types — DataTypeCV","text":"","code":"DataTypeCV"},{"path":"/reference/DataTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Data Types — DataTypeCV","text":"data frame 16 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"/reference/DataTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Data Types — DataTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=DataTypeCV","code":""},{"path":"/reference/GeneralCategoryCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed General Categories — GeneralCategoryCV","title":"Allowed General Categories — GeneralCategoryCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary General Category","code":""},{"path":"/reference/GeneralCategoryCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed General Categories — GeneralCategoryCV","text":"","code":"GeneralCategoryCV"},{"path":"/reference/GeneralCategoryCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed General Categories — GeneralCategoryCV","text":"data frame 10 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"/reference/GeneralCategoryCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed General Categories — GeneralCategoryCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=GeneralCategoryCV","code":""},{"path":"/reference/SampleMediumCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Sample Media — SampleMediumCV","title":"Allowed Sample Media — SampleMediumCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Sample Medium","code":""},{"path":"/reference/SampleMediumCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Sample Media — SampleMediumCV","text":"","code":"SampleMediumCV"},{"path":"/reference/SampleMediumCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Sample Media — SampleMediumCV","text":"data frame 24 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"/reference/SampleMediumCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Sample Media — SampleMediumCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=SampleMediumCV","code":""},{"path":"/reference/UnitsCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Units — UnitsCV","title":"Allowed Units — UnitsCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Units","code":""},{"path":"/reference/UnitsCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Units — UnitsCV","text":"","code":"UnitsCV"},{"path":"/reference/UnitsCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Units — UnitsCV","text":"data frame 394 rows 4 variables: UnitsID Unique unit identifier UnitsName Name unit UnitsType Type unit UnitsAbbreviation Standardized abbreviation symbol unit","code":""},{"path":"/reference/UnitsCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Units — UnitsCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=Units","code":""},{"path":"/reference/ValueTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Value Types — ValueTypeCV","title":"Allowed Value Types — ValueTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Value Type","code":""},{"path":"/reference/ValueTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Value Types — ValueTypeCV","text":"","code":"ValueTypeCV"},{"path":"/reference/ValueTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Value Types — ValueTypeCV","text":"data frame 7 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"/reference/ValueTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Value Types — ValueTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=ValueTypeCV","code":""},{"path":"/reference/VariableNameCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Variable Names — VariableNameCV","title":"Allowed Variable Names — VariableNameCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Variable Name","code":""},{"path":"/reference/VariableNameCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Variable Names — VariableNameCV","text":"","code":"VariableNameCV"},{"path":"/reference/VariableNameCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Variable Names — VariableNameCV","text":"data frame 925 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"/reference/VariableNameCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Variable Names — VariableNameCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=VariableNameCV","code":""},{"path":"/reference/check_odm_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"Check term ODM Controlled Vocabulary","code":""},{"path":"/reference/check_odm_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"","code":"check_odm_cv(term, cv)"},{"path":"/reference/check_odm_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"term (character) user-provided term needs validated cv (character) \"Term\" column corresponding CV","code":""},{"path":"/reference/check_odm_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"(logical) TRUE exact match CV, otherwise FALSE","code":""},{"path":"/reference/convert_missing_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert missing value codes to NA — convert_missing_value","title":"Convert missing value codes to NA — convert_missing_value","text":"Convert missing value codes NA","code":""},{"path":"/reference/convert_missing_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert missing value codes to NA — convert_missing_value","text":"","code":"convert_missing_value(v, code, type)"},{"path":"/reference/convert_missing_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert missing value codes to NA — convert_missing_value","text":"v Vector values code (character) Missing value code type (character) Type (class) v . Supported types : \"character\", \"numeric\", \"datetime\"","code":""},{"path":"/reference/convert_missing_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert missing value codes to NA — convert_missing_value","text":"Vector values code replaced NA class type","code":""},{"path":"/reference/create_USGS_hymet.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"Create USGS hymetDP-formatted dataset","code":""},{"path":"/reference/create_USGS_hymet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"","code":"create_USGS_hymet(site, param, start, end)"},{"path":"/reference/create_USGS_hymet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"site (character) USGS site code list site codes. Discover site codes dataRetrieval::whatNWISsites(). param (character) USGS parameter code list parameter codes. Discover parameter codes dataRetrieval::whatNWISdata(). start (character) Starting datetime data query. Format date strings YYYY-MM-DD, datetime strings YYYY-MM-DDThh:mm:ssZ. Format must match end parameter format. end (character) Ending datetime data query. Format date strings YYYY-MM-DD,","code":""},{"path":"/reference/create_USGS_hymet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"list hymetDP tables","code":""},{"path":"/reference/create_USGS_hymet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"","code":"site <- c(\"06879650\", \"50065500\") param <- c(\"00060\") start <- c(\"2020-06-01T12:30:00Z\") end <- c(\"2021-01-01T12:30:00Z\")  usgs_hymet <- create_USGS_hymet(site, param, start, end) #> Downloading data from USGS site 06879650, parameter 00060 #> Downloading data from USGS site 50065500, parameter 00060 #> Generating hymetDP tables..."},{"path":"/reference/create_citation.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"Create EDI data package citation EML hosted EDI Data Portal","code":""},{"path":"/reference/create_citation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"","code":"create_citation(eml = eml)"},{"path":"/reference/create_citation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"eml (character) EML document valid EDI package identifier can extracted.","code":""},{"path":"/reference/create_citation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"(character) EDI data package citation.","code":""},{"path":[]},{"path":"/reference/create_data_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the DataValues table — create_data_values","title":"Create the DataValues table — create_data_values","text":"Create DataValues table","code":""},{"path":"/reference/create_data_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the DataValues table — create_data_values","text":"","code":"create_data_values(   L0_flat = flat,   ValueID,   DataValue,   ValueAccuracy = NULL,   LocalDateTime,   UTCOffset,   DateTimeUTC = NULL,   SiteCode,   VariableCode,   OffsetValue = NULL,   OffsetTypeCode = NULL,   CensorCode = NULL,   QualifierCode = NULL,   MethodCode,   QualityControlLevelCode,   SourceCode,   NoDataValue )"},{"path":"/reference/create_data_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the DataValues table — create_data_values","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). ValueID (character) Column L0_flat containing identifier assigned unique data value. DataValue (character) Column L0_flat containing numeric value observation. ValueAccuracy (character) Optional. Column L0_flat containing umeric value describes measurement accuracy data value. LocalDateTime (character) Column L0_flat containing local date time data value observed. UTCOffset (character) Column L0_flat containing offset hours UTC time corresponding LocalDateTime value. DateTimeUTC (character) Column L0_flat containing UTC date time data value observed. SiteCode (character) Column L0_flat containing code used organization collects data identify site. VariableCode (character) Column L0_flat containing code used organization collects data identify variable. OffsetValue (character) Optional. Column L0_flat containing distance datum control point point data value observed. CensorCode (character) Column L0_flat containing text indication whether data value censored. Defaults \"nc\" (Censored). QualifierCode (character) Optional. Column L0_flat containing flag indicating peculiarity particular data value. MethodCode (character) Column L0_flat containing code used organization collects data identify Method. QualityControlLevelCode (character) Column L0_flat containing code identifies level quality control value subjected . SourceCode (character) Column L0_flat containing code identifies organization created data. NoDataValue (character) Column L0_flat containing numeric value used encode data value available variable. OffsetTypeCodeMandatory (character) OffsetValue used. Column L0_flat containing code used organization collects data identify OffsetType.","code":""},{"path":"/reference/create_data_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the DataValues table — create_data_values","text":"(tbl_df, tbl, data.frame) DataValues table.","code":""},{"path":"/reference/create_data_values.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the DataValues table — create_data_values","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/create_data_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the DataValues table — create_data_values","text":"","code":"flat <- hymet_L0_flat    DataValues <- hymetDP::create_data_values(     L0_flat = flat,     ValueID = \"ValueID\",     DataValue = \"DataValue\",     ValueAccuracy = NULL,     LocalDateTime = \"LocalDateTime\",     UTCOffset = \"UTCOffset\",     DateTimeUTC = \"DateTimeUTC\",     SiteCode = \"SiteCode\",     VariableCode = \"VariableCode\",     OffsetValue = NULL,     OffsetTypeCode = NULL,     CensorCode = NULL,     QualifierCode = NULL,     MethodCode = \"MethodCode\",     QualityControlLevelCode = \"QualityControlLevelCode\",     SourceCode = \"SourceCode\",     NoDataValue = \"NoDataValue\")    DataValues #> # A tibble: 30,003 × 15 #>    ValueID DataValue ValueAccuracy LocalDateTime       UTCOffset #>    <chr>       <dbl>         <dbl> <dttm>                  <dbl> #>  1 1           144.             NA 2002-01-11 23:45:00        13 #>  2 2             0.1            NA 2002-01-11 23:45:00        13 #>  3 3            16.3            NA 2002-01-11 23:45:00        13 #>  4 4           121.             NA 2002-01-12 00:00:00        13 #>  5 5             0.1            NA 2002-01-12 00:00:00        13 #>  6 6            16.4            NA 2002-01-12 00:00:00        13 #>  7 7           116.             NA 2002-01-12 00:15:00        13 #>  8 8             0.1            NA 2002-01-12 00:15:00        13 #>  9 9            16.9            NA 2002-01-12 00:15:00        13 #> 10 10          139.             NA 2002-01-12 00:30:00        13 #> # … with 29,993 more rows, and 10 more variables: DateTimeUTC <dttm>, #> #   SiteCode <chr>, VariableCode <chr>, OffsetValue <dbl>, #> #   OffsetTypeCode <chr>, CensorCode <chr>, QualifierCode <chr>, #> #   MethodCode <chr>, SourceCode <chr>, QualityControlLevelCode <chr>"},{"path":"/reference/create_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Methods table — create_methods","title":"Create the Methods table — create_methods","text":"Create Methods table","code":""},{"path":"/reference/create_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Methods table — create_methods","text":"","code":"create_methods(   L0_flat = flat,   MethodCode,   MethodDescription,   MethodLink = NULL )"},{"path":"/reference/create_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Methods table — create_methods","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). MethodCode (character) Column L0_flat containing code used organization collects data identify Method. MethodDescription (character) Column L0_flat containing text description method. MethodLink (character) Optional. Column L0_flat containing link additional reference material method. single valid URL.","code":""},{"path":"/reference/create_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Methods table — create_methods","text":"(tbl_df, tbl, data.frame) Methods table.","code":""},{"path":"/reference/create_methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Methods table — create_methods","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/create_methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Methods table — create_methods","text":"","code":"flat <- hymet_L0_flat   Methods <- hymetDP::create_methods(    L0_flat = flat,    MethodCode = \"MethodCode\",    MethodDescription = \"MethodDescription\")   Methods #> # A tibble: 1 × 3 #>   MethodCode MethodDescription                                        MethodLink #>   <chr>      <chr>                                                    <chr>      #> 1 1          Campbell CR10 dataloggers were used to record stream st… NA"},{"path":"/reference/create_qualifiers.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Qualifiers table — create_qualifiers","title":"Create the Qualifiers table — create_qualifiers","text":"Create Qualifiers table","code":""},{"path":"/reference/create_qualifiers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Qualifiers table — create_qualifiers","text":"","code":"create_qualifiers(L0_flat = flat, QualifierCode, QualifierDescription)"},{"path":"/reference/create_qualifiers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Qualifiers table — create_qualifiers","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). QualifierCode (character) Column L0_flat containing code indicate given data qualifier. QualifierDescription (character) Column L0_flat containing text data qualifying comment, e.g., low battery voltage sensor.","code":""},{"path":"/reference/create_qualifiers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Qualifiers table — create_qualifiers","text":"flat <- hymet_L0_flat Qualifiers <- hymetDP::create_qualifiers( L0_flat = flat, QualifierCode = \"QualifierCode\", QualifierDescription = \"QualifierDescription\") Qualifiers","code":""},{"path":"/reference/create_qualifiers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Qualifiers table — create_qualifiers","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"/reference/create_quality_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the QualityControlLevels table — create_quality_control","title":"Create the QualityControlLevels table — create_quality_control","text":"Create QualityControlLevels table","code":""},{"path":"/reference/create_quality_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the QualityControlLevels table — create_quality_control","text":"","code":"create_quality_control(   L0_flat = flat,   QualityControlLevelCode,   Definition,   Explanation )"},{"path":"/reference/create_quality_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the QualityControlLevels table — create_quality_control","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). QualityControlLevelCode (character) Column L0_flat containing code used identify level quality control data values subjected. Definition (character) Column L0_flat containing definition Quality Control Level. Examples: Raw Data, Quality Controlled Data. confused data qualifiers. Explanation (character) Column L0_flat containing explanation Quality Control Level.","code":""},{"path":[]},{"path":"/reference/create_quality_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the QualityControlLevels table — create_quality_control","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/create_quality_control.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the QualityControlLevels table — create_quality_control","text":"","code":"flat <- hymet_L0_flat    QualityControlLevels <- hymetDP::create_quality_control(     L0_flat = flat,     QualityControlLevelCode = \"QualityControlLevelCode\",     Definition = \"Definition\",     Explanation = \"Explanation\")    QualityControlLevels #> # A tibble: 1 × 3 #>   QualityControlLevelCode Definition              Explanation                    #>   <chr>                   <chr>                   <chr>                          #> 1 1                       Quality controlled data Quality controlled data that …"},{"path":"/reference/create_series_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the SeriesCatalog table — create_series_catalog","title":"Create the SeriesCatalog table — create_series_catalog","text":"Create SeriesCatalog table","code":""},{"path":"/reference/create_series_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the SeriesCatalog table — create_series_catalog","text":"","code":"create_series_catalog(   L0_flat = NULL,   Sources = NULL,   Methods = NULL,   Variables = NULL,   Sites = NULL,   QualityControlLevels = NULL,   DataValues = NULL )"},{"path":"/reference/create_series_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the SeriesCatalog table — create_series_catalog","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). Sources (tbl_df, tbl, data.frame) Sources table. Methods (tbl_df, tbl, data.frame) Methods table. Variables (tbl_df, tbl, data.frame) Variables table. Sites (tbl_df, tbl, data.frame) Sites table. QualityControlLevels (tbl_df, tbl, data.frame) QualityControlLevels table. DataValues (tbl_df, tbl, data.frame) DataValues table.","code":""},{"path":"/reference/create_series_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the SeriesCatalog table — create_series_catalog","text":"(tbl_df, tbl, data.frame) SeriesCatalog table.","code":""},{"path":"/reference/create_series_catalog.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the SeriesCatalog table — create_series_catalog","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/create_series_catalog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the SeriesCatalog table — create_series_catalog","text":"","code":"flat <- hymet_L0_flat  Sources <- hymetDP::create_sources(   L0_flat = flat,   SourceCode = \"SourceCode\",   Organization = \"Organization\",   SourceDescription = \"SourceDescription\",   SourceLink = \"SourceLink\",   ContactName = \"ContactName\",   Phone = \"Phone\",   Email = \"Email\",   Address = \"Address\",   City = \"City\",   State = \"State\",   ZipCode = \"ZipCode\",   Citation = \"Citation\")  Methods <- hymetDP::create_methods(   L0_flat = flat,   MethodCode = \"MethodCode\",   MethodDescription = \"MethodDescription\")  Variables <- hymetDP::create_variables(   L0_flat = flat,   VariableCode = \"VariableCode\",   VariableName = \"VariableName\",   VariableUnitsName = \"VariableUnitsName\",   SampleMedium = \"SampleMedium\",   ValueType = \"ValueType\",   IsRegular = \"IsRegular\",   TimeSupport = \"TimeSupport\",   TimeUnitsName = \"TimeUnitsName\",   DataType = \"DataType\",   GeneralCategory = \"GeneralCategory\",   NoDataValue = \"NoDataValue\")  Sites <- hymetDP::create_sites(   L0_flat = flat,   SiteCode = \"SiteCode\",   SiteName = \"SiteName\",   Latitude = \"Latitude\",   Longitude = \"Longitude\",   LatLongDatumSRSName = NULL,   Elevation_m = NULL,   VerticalDatum = NULL,   LocalX = NULL,   LocalY = NULL,   LocalProjectionSRSName = NULL,   PosAccuracy_m = NULL,   State = NULL,   County = NULL,   Comments = NULL,   SiteType = \"SiteType\")  QualityControlLevels <- hymetDP::create_quality_control(   L0_flat = flat,   QualityControlLevelCode = \"QualityControlLevelCode\",   Definition = \"Definition\",   Explanation = \"Explanation\")  DataValues <- hymetDP::create_data_values(   L0_flat = flat,   ValueID = \"ValueID\",   DataValue = \"DataValue\",   ValueAccuracy = NULL,   LocalDateTime = \"LocalDateTime\",   UTCOffset = \"UTCOffset\",   DateTimeUTC = \"DateTimeUTC\",   SiteCode = \"SiteCode\",   VariableCode = \"VariableCode\",   OffsetValue = NULL,   OffsetTypeCode = NULL,   CensorCode = NULL,   QualifierCode = NULL,   MethodCode = \"MethodCode\",   QualityControlLevelCode = \"QualityControlLevelCode\",   SourceCode = \"SourceCode\",   NoDataValue = \"NoDataValue\")  SeriesCatalog <- hymetDP::create_series_catalog(   Sources = Sources,   Methods = Methods,   Variables = Variables,   Sites = Sites,   QualityControlLevels = QualityControlLevels,   DataValues = DataValues)  SeriesCatalog #>   SeriesID SiteCode #> 1        1        1 #> 2        2        1 #> 3        3        1 #>                                                                                                                                              SiteName #> 1 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #> 2 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #> 3 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #>   VariableCode         VariableName           VariableUnitsName  SampleMedium #> 1            1            Discharge           liters per second Surface water #> 2            2          Temperature              degree celsius Surface water #> 3            3 Specific conductance microsiemens per centimeter Surface water #>           ValueType TimeSupport TimeUnitsName   DataType GeneralCategory #> 1     Derived Value          15        minute Continuous       Hydrology #> 2 Field Observation          15        minute Continuous       Hydrology #> 3 Field Observation          15        minute Continuous       Hydrology #>   MethodCode #> 1          1 #> 2          1 #> 3          1 #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      MethodDescription #> 1 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #> 2 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #> 3 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #>   SourceCode             Organization #> 1          1 McMurdo Dry Valleys LTER #> 2          1 McMurdo Dry Valleys LTER #> 3          1 McMurdo Dry Valleys LTER #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         SourceDescription #> 1 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #> 2 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #> 3 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #>                                                                                                                                                                                                                                                                                                                                           Citation #> 1 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #> 2 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #> 3 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #>   QualityControlLevelCode       BeginDateTime         EndDateTime #> 1                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #> 2                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #> 3                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #>      BeginDateTimeUTC      EndDateTimeUTC ValueCount #> 1 2002-01-11 10:45:00 2003-12-25 20:30:00      10001 #> 2 2002-01-11 10:45:00 2003-12-25 20:30:00      10001 #> 3 2002-01-11 10:45:00 2003-12-25 20:30:00      10001"},{"path":"/reference/create_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Sites table — create_sites","title":"Create the Sites table — create_sites","text":"Create Sites table","code":""},{"path":"/reference/create_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Sites table — create_sites","text":"","code":"create_sites(   L0_flat = flat,   SiteCode,   SiteName,   Latitude,   Longitude,   LatLongDatumSRSName = NULL,   Elevation_m = NULL,   VerticalDatum = NULL,   LocalX = NULL,   LocalY = NULL,   LocalProjectionSRSName = NULL,   PosAccuracy_m = NULL,   State = NULL,   County = NULL,   Comments = NULL,   SiteType = NULL )"},{"path":"/reference/create_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Sites table — create_sites","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). SiteCode (character) Column L0_flat containing user organization-defined code collects data identify site. SiteName (character) Column L0_flat containing full name sampling site. Latitude (character) Column L0_flat containing latitude decimal degrees. Longitude (character) Column L0_flat containing longitude decimal degrees. LatLongDatumSRSName (character) Column L0_flat containing spatial reference system latitude longitude coordinates. Choose SRSName IsGeographic=True SpatialReferencesCV. View possible options SpatialReferencesCV$SRSName[SpatialReferencesCV$IsGeographic] Elevation_m (character) Column L0_flat containing elevation sampling location meters. VerticalDatum (character) Column L0_flat containing Vertical datum elevation. Choose Term VerticalDatum controlled vocabulary. LocalX (character) Column L0_flat containing local projection X coordinate. LocalY (character) Column L0_flat containing local projection Y coordinate. LocalProjectionSRSName (character) Column L0_flat containing full text name spatial reference system local coordinates. field optional necessary local coordinates given. Choose SRSName SpatialReferencesCV. PosAccuracy_m (character) Column L0_flat containing value giving accuracy positional information specified meters. State (character) Column L0_flat containing name state monitoring site located. County (character) Column L0_flat containing name county monitoring site located. Comments (character) Column L0_flat containing comments related site. SiteType (character) Column L0_flat containing type site. Choose Term SiteTypeCV.","code":""},{"path":[]},{"path":"/reference/create_sites.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Sites table — create_sites","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/create_sites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Sites table — create_sites","text":"","code":"flat <- hymet_L0_flat    Sites <- hymetDP::create_sites(     L0_flat = flat,     SiteCode = \"SiteCode\",     SiteName = \"SiteName\",     Latitude = \"Latitude\",     Longitude = \"Longitude\",     LatLongDatumSRSName = NULL,     Elevation_m = NULL,     VerticalDatum = NULL,     LocalX = NULL,     LocalY = NULL,     LocalProjectionSRSName = NULL,     PosAccuracy_m = NULL,     State = NULL,     County = NULL,     Comments = NULL,     SiteType = \"SiteType\")    Sites #> # A tibble: 1 × 15 #>   SiteCode SiteName              Latitude Longitude LatLongDatumSRS… Elevation_m #>   <chr>    <chr>                    <dbl>     <dbl> <chr>                  <dbl> #> 1 1        USGS site 9; coordin…    -77.6      163. Unknown                   NA #> # … with 9 more variables: VerticalDatum <chr>, LocalX <dbl>, LocalY <dbl>, #> #   LocalProjectionSRSName <chr>, PosAccuracy_m <dbl>, State <chr>, #> #   County <chr>, Comments <chr>, SiteType <chr>"},{"path":"/reference/create_sources.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Sources table — create_sources","title":"Create the Sources table — create_sources","text":"Create Sources table","code":""},{"path":"/reference/create_sources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Sources table — create_sources","text":"","code":"create_sources(   L0_flat = flat,   SourceCode,   Organization,   SourceDescription,   SourceLink = NULL,   ContactName,   Phone,   Email,   Address,   City,   State,   ZipCode,   Citation )"},{"path":"/reference/create_sources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Sources table — create_sources","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). SourceCode (character) Column L0_flat containing code identifies organization created data. Organization (character) Column L0_flat containing name organization collected data. SourceDescription (character) Column L0_flat containing full text description source data. SourceLink (character) Column L0_flat containing link original data file data source. ContactName (character) Column L0_flat containing name contact person data source. Phone (character) Column L0_flat containing phone number contact person. Email (character) Column L0_flat containing email address contact person. Address (character) Column L0_flat containing street address contact person. City (character) Column L0_flat containing city contact person located. State (character) Column L0_flat containing state contact person located. ZipCode (character) Column L0_flat containing US Zip Code country postal code. Citation (character) Column L0_flat containing Text string gives citation used data source referenced.","code":""},{"path":"/reference/create_sources.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Sources table — create_sources","text":"(tbl_df, tbl, data.frame) Sources table.","code":""},{"path":"/reference/create_sources.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Sources table — create_sources","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.#'","code":""},{"path":[]},{"path":"/reference/create_sources.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Sources table — create_sources","text":"","code":"flat <- hymet_L0_flat    Sources <- hymetDP::create_sources(     L0_flat = flat,     SourceCode = \"SourceCode\",     Organization = \"Organization\",     SourceDescription = \"SourceDescription\",     SourceLink = \"SourceLink\",     ContactName = \"ContactName\",     Phone = \"Phone\",     Email = \"Email\",     Address = \"Address\",     City = \"City\",     State = \"State\",     ZipCode = \"ZipCode\",     Citation = \"Citation\")    Sources #> # A tibble: 1 × 12 #>   SourceCode Organization    SourceDescripti… SourceLink ContactName Phone Email #>   <chr>      <chr>           <chr>            <chr>      <chr>       <chr> <chr> #> 1 1          McMurdo Dry Va… As part of the … https://d… McMurdo Dr… Unkn… im@m… #> # … with 5 more variables: Address <chr>, City <chr>, State <chr>, #> #   ZipCode <chr>, Citation <chr>"},{"path":"/reference/create_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Variables table — create_variables","title":"Create the Variables table — create_variables","text":"Create Variables table","code":""},{"path":"/reference/create_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Variables table — create_variables","text":"","code":"create_variables(   L0_flat = flat,   VariableCode,   VariableName,   VariableUnitsName,   SampleMedium,   ValueType,   IsRegular,   TimeSupport,   TimeUnitsName,   DataType,   GeneralCategory,   NoDataValue )"},{"path":"/reference/create_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Variables table — create_variables","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). VariableCode (character) Column L0_flat containing user organization-defined code describe variable. VariableName (character) Column L0_flat containing full text name variable measured, observed, modeled, etc. Must ODM CV (see VariableNameCV) VariableUnitsName (character) Column L0_flat containing name units data values associated variable. Must ODM CV (see UnitsCV) SampleMedium (character) Column L0_flat containing medium sample observation taken made. Must ODM CV (see SampleMediumCV) ValueType (character) Column L0_flat indicates data value generated. Must ODM CV (see ValueTypeCV) IsRegular (character) Column L0_flat indicates whether data values regularly sampled time series. TimeSupport (character) Column L0_flat containing numerical value indicates time support (temporal footprint) data values. 0 used indicate data values instantaneous. values indicate time data values implicitly explicitly averaged aggregated. TimeUnitsName (character) Column L0_flat containing name units time support. TimeSupport 0, indicating instantaneous observation, unit needs still given completeness, although arbitrary. Must ODM CV (see UnitsCV) DataType (character) Column L0_flat indicates value applies time interval. Must ODM CV (see DataTypeCV) GeneralCategory (character) Column L0_flat containing general category data. Must ODM CV (see GeneralCategoryCV) NoDataValue (character) Column L0_flat containing numeric value used encode data value available variable.","code":""},{"path":"/reference/create_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Variables table — create_variables","text":"(tbl_df, tbl, data.frame) Variables table.","code":""},{"path":"/reference/create_variables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Variables table — create_variables","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/create_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Variables table — create_variables","text":"","code":"flat <- hymet_L0_flat    Variables <- hymetDP::create_variables(     L0_flat = flat,     VariableCode = \"VariableCode\",     VariableName = \"VariableName\",     VariableUnitsName = \"VariableUnitsName\",     SampleMedium = \"SampleMedium\",     ValueType = \"ValueType\",     IsRegular = \"IsRegular\",     TimeSupport = \"TimeSupport\",     TimeUnitsName = \"TimeUnitsName\",     DataType = \"DataType\",     GeneralCategory = \"GeneralCategory\",     NoDataValue = \"NoDataValue\")    Variables #> # A tibble: 3 × 11 #>   VariableCode VariableName    VariableUnitsNa… SampleMedium ValueType IsRegular #>   <chr>        <chr>           <chr>            <chr>        <chr>     <lgl>     #> 1 1            Discharge       liters per seco… Surface wat… Derived … TRUE      #> 2 2            Temperature     degree celsius   Surface wat… Field Ob… TRUE      #> 3 3            Specific condu… microsiemens pe… Surface wat… Field Ob… TRUE      #> # … with 5 more variables: TimeSupport <dbl>, TimeUnitsName <chr>, #> #   DataType <chr>, GeneralCategory <chr>, NoDataValue <dbl>"},{"path":"/reference/define_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP method — define_method","title":"Define a hymetDP method — define_method","text":"Define hymetDP method","code":""},{"path":"/reference/define_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP method — define_method","text":"","code":"define_method(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = NULL,   VariableCode = NULL,   MethodDescription = NULL,   MethodLink = NULL )"},{"path":"/reference/define_method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP method — define_method","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). local_variable_column (character) Column L0_flat table containing L0 variable name. local_variable (character) Reference value (values) local_variable_column L0_flat table new hymetDP method refers. VariableCode (character) auto-generated primary key variable (column VariableCode). Another way link method value (values). Takes priority local_variable. Provide one multiple codes. MethodDescription (character) Text description method. MethodLink (character) Optional. Link additional reference material method. single valid URL.","code":""},{"path":"/reference/define_method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP method — define_method","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus one additional column method description (two additional columns method link defined). Column name includes auto-generated MethodCode (.e. MethodDescription_1), become primary key Methods table.","code":""},{"path":"/reference/define_method.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP method — define_method","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/define_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP source — define_source","title":"Define a hymetDP source — define_source","text":"Define hymetDP source","code":""},{"path":"/reference/define_source.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP source — define_source","text":"","code":"define_source(   L0_flat = flat,   eml = eml,   Organization = NULL,   SourceDescription = NULL,   SourceLink = NULL,   ContactName = NULL,   Phone = NULL,   Email = NULL,   Address = NULL,   City = NULL,   State = NULL,   ZipCode = NULL,   Citation = NULL )"},{"path":"/reference/define_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP source — define_source","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). eml ('xml_document' 'xml_node') EML metadata. Organization (character) Name organization collected data. SourceDescription (character) Full text description source data. provided, default abstract EML document. SourceLink (character) Optional. Full text description source data. provided, default DOI EML document. ContactName (character) Name contact person data source. provided, contact information default first contact listed EML document. Phone (character) Phone number contact person. Email (character) Email addresss contact person. Address (character) Street address contact person. City (character) City contact person located. State (character) State contact person located. Use two letter abbreviations US. countries give full country name. ZipCode (character) US Zip Code country postal code. Citation (character) Text string gives citation used data source referenced. provided, default Citation appears (appear) EDI Data Portal EML document.","code":""},{"path":"/reference/define_source.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP source — define_source","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus additional columns Source information.","code":""},{"path":"/reference/define_source.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP source — define_source","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/define_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP variable — define_variable","title":"Define a hymetDP variable — define_variable","text":"Define hymetDP variable","code":""},{"path":"/reference/define_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP variable — define_variable","text":"","code":"define_variable(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = NULL,   variable_name = local_variable,   variable_units = NULL,   sample_medium = \"Unknown\",   value_type = \"Unknown\",   is_regular = FALSE,   time_support = 0,   time_units = \"hour\",   data_type = \"Unknown\",   general_category = \"Unknown\",   no_data = -9999 )"},{"path":"/reference/define_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP variable — define_variable","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). local_variable_column (character) Column L0_flat table containing L0 variable name. local_variable (character) Reference value local_variable_column L0_flat table new hymetDP variable refers. variable_name (character) CUAHSI ODM Controlled Vocabulary name variable measured, observed, modeled, etc. Defaults local_variable value. variable_units (character) CUAHSI ODM Controlled Vocabulary name units data values associated variable. Defaults column unit L0_flat table left unspecified. sample_medium (character) CUAHSI ODM Controlled Vocabulary name medium sample observation taken made. value_type (character) CUAHSI ODM Controlled Vocabulary value indicates data value generated. is_regular (boolean) Value indicates whether data values regularly sampled time series. Choose TRUE FALSE. time_support (numeric) Numerical value indicates time support (temporal footprint) data values. 0 used indicate data values instantaneous. values indicate time data values implicitly explicitly averaged aggregated. Goes along time_units is_regular == TRUE. time_units (character) CUAHSI ODM Controlled Vocabulary name units time support. time_support == 0, indicating instantaneous observation, unit needs still given completeness, although arbitrary. data_type (character) CUAHSI ODM Controlled Vocabulary value indicates value applies time interval. general_category (character) CUAHSI ODM Controlled Vocabulary value general category data  (.e. Hydrology). no_data (numeric) Numeric value used encode data value available variable. DataValues reformatted match value.","code":""},{"path":"/reference/define_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP variable — define_variable","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus one specified variable values (.e. variable_name, variable_units, etc.), plus VariableCode column, auto-generated integer value become primary key Variables table. Columns added first time function run. Subsequent runs append values existing columns.","code":""},{"path":"/reference/define_variable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP variable — define_variable","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"/reference/get_usgs_sitetype.html","id":null,"dir":"Reference","previous_headings":"","what":"Get USGS site type — get_usgs_sitetype","title":"Get USGS site type — get_usgs_sitetype","text":"Get USGS site type","code":""},{"path":"/reference/get_usgs_sitetype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get USGS site type — get_usgs_sitetype","text":"","code":"get_usgs_sitetype(s)"},{"path":"/reference/get_usgs_sitetype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get USGS site type — get_usgs_sitetype","text":"s (character) USGS site type code site_type_cd","code":""},{"path":"/reference/get_usgs_sitetype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get USGS site type — get_usgs_sitetype","text":"Site type","code":""},{"path":"/reference/get_usgs_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Get USGS variable information — get_usgs_variable","title":"Get USGS variable information — get_usgs_variable","text":"Get USGS variable information","code":""},{"path":"/reference/get_usgs_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get USGS variable information — get_usgs_variable","text":"","code":"get_usgs_variable(p)"},{"path":"/reference/get_usgs_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get USGS variable information — get_usgs_variable","text":"p (character) USGS parameter code param","code":""},{"path":"/reference/get_usgs_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get USGS variable information — get_usgs_variable","text":"Information associated USGS variable","code":""},{"path":"/reference/hymet_L0_flat.html","id":null,"dir":"Reference","previous_headings":"","what":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"fully joined flat version EDI data package knb-lter-mcm.9003.11 (Seasonal high-frequency measurements discharge, water temperature, specific conductivity Andersen Creek H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing)) relevant hymetDP L1 identifiers content added. Use dataset input L0_flat argument \"create\" functions.","code":""},{"path":"/reference/hymet_L0_flat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"","code":"hymet_L0_flat"},{"path":"/reference/hymet_L0_flat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"data frame 30,000 rows 45 variables: LocalDateTime Local datetime UTCOffset Local timezone offset UTC DateTimeUTC Datetime UTC Variable_name Variable name L0 dataset DataValue Numeric value observation Qualifier Code qualifier (flag) Unit Unit name L0 dataset ValueID data value ID VariableCode variable ID VariableName ODM CV variable name VariableUnitsName ODM CV unit name variable SampleMedium ODM CV sample medium name ValueType ODM CV value type IsRegular Whether values regularly sampled dataset TimeSupport Temporal footprint samples TimeUnitsName ODM CV unit name time support DataType ODM CV data type GeneralCategory ODM CV general category NoDataValue numeric value used encode available data MethodCode method ID MethodDescription description method SiteCode site ID SiteName name site Latitude Latitude site Longitude Longitude site Elevation_m Elevation site meters LatLongDatumSRSName Spatial reference system latitude longitude coordinates SiteType ODM CV site type Organization Name organization collected data ContactName Name contact person data source Email Email contact SourceCode source ID SourceDescription description source data SourceLink URL source data Citation Citation source data Phone Contact phone Address Contact physical address City Contact city State Contact state US, otherwise full country name ZipCode Contact postal code QualityControlLevelCode quality control ID Definition Definition quality control level Explanation Explanation quality control level QualifierCode qualifier ID QualifierDescription Description qualifier","code":""},{"path":"/reference/hymet_L0_flat.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-mcm&identifier=9003&revision=11","code":""},{"path":"/reference/hymet_L1.html","id":null,"dir":"Reference","previous_headings":"","what":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"hymetDP (L1) formatted version EDI data package knb-lter-mcm.9003.11 (Seasonal high-frequency measurements discharge, water temperature, specific conductivity Andersen Creek H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing)) produced table hymet_L0_flat. Use dataset input data \"use\" functions.","code":""},{"path":"/reference/hymet_L1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"","code":"hymet_L1"},{"path":"/reference/hymet_L1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"list : id dataset identifier metadata See source url metadata tables list data frames, ecocomDP table","code":""},{"path":"/reference/hymet_L1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"hymet_L0_flat","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"/reference/read_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Read published data — read_data","title":"Read published data — read_data","text":"Read published data","code":""},{"path":"/reference/read_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read published data — read_data","text":"","code":"read_data(   id = NULL,   parse_datetime = TRUE,   unique_keys = FALSE,   from = NULL,   format = \"new\" )"},{"path":"/reference/read_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read published data — read_data","text":"id (character) Identifier dataset read. Identifiers listed \"id\" column search_data() output. Older versions datasets can read, warning issued. parse_datetime (logical) Parse datetime values TRUE, otherwise return character strings. unique_keys (logical) Whether create globally unique primary keys (associated foreign keys). Useful maintaining referential integrity working multiple datasets. TRUE, id appended table's primary key associated foreign key. Default FALSE. (character) Full path file read (.rds), path directory containing saved datasets (.csv). format (character) Format returned object, can : \"new\" (new implementation) \"old\" (original implementation; deprecated). new format, top level nesting containing \"id\" field moved level \"tables\", \"metadata\", \"validation_issues\" fields.","code":""},{"path":"/reference/read_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read published data — read_data","text":"(list) dataset structure: id - Dataset identifier metadata - List info dataset. NOTE: object underdevelopment content may change future releases. tables - List dataset tables data.frames. validation_issues - List validation issues. dataset fails validation checks, descriptions issue listed .","code":""},{"path":"/reference/read_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read published data — read_data","text":"","code":"Validation checks are applied to each dataset ensuring it complies with the hymetDP model. A warning is issued when any validation checks fail. All datasets are returned, even if they fail validation.  Column classes are coerced to those defined in the hymetDP specification.  Validation happens each time files are read, from source APIs or local environments."},{"path":"/reference/read_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Read published data — read_data","text":"function may work 01:00 - 03:00 UTC Wednesdays due regular maintenance EDI Data Repository.","code":""},{"path":[]},{"path":"/reference/read_data_package_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data package report — read_data_package_report","title":"Read data package report — read_data_package_report","text":"Read data package report","code":""},{"path":"/reference/read_data_package_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data package report — read_data_package_report","text":"","code":"read_data_package_report(packageId, frmt = \"xml\", env = \"production\")"},{"path":"/reference/read_data_package_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data package report — read_data_package_report","text":"packageId (character) Data package identifier frmt (character) Format returned report. Can : \"xml\", \"html\", \"char\". env (character) Repository environment. Can : \"production\", \"staging\", \"development\".","code":""},{"path":"/reference/read_data_package_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data package report — read_data_package_report","text":"(xml_document) Data package report","code":""},{"path":"/reference/read_data_package_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read data package report — read_data_package_report","text":"","code":"# Read as XML qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\") qualityReport #> {xml_document} #> <qualityReport schemaLocation=\"eml://ecoinformatics.org/qualityReport https://raw.githubusercontent.com/PASTAplus/PASTA/master/DataPackageManager/WebRoot/xml/qualityReportSchema.xsd\" xmlns=\"eml://ecoinformatics.org/qualityReport\" xmlns:qr=\"eml://ecoinformatics.org/qualityReport\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> #>  [1] <creationDate>2020-02-04T16:38:38<\/creationDate> #>  [2] <packageId>knb-lter-knz.260.4<\/packageId> #>  [3] <includeSystem>lter<\/includeSystem> #>  [4] <includeSystem>knb<\/includeSystem> #>  [5] <datasetReport>\\n  <qualityCheck qualityType=\"metadata\" system=\"lter\" st ... #>  [6] <entityReport>\\n  <entityName>GIS600<\/entityName>\\n  <qualityCheck quali ... #>  [7] <entityReport>\\n  <entityName>KMZGIS600<\/entityName>\\n  <qualityCheck qu ... #>  [8] <entityReport>\\n  <entityName>GIS605<\/entityName>\\n  <qualityCheck quali ... #>  [9] <entityReport>\\n  <entityName>KMZGIS605<\/entityName>\\n  <qualityCheck qu ... #> [10] <entityReport>\\n  <entityName>GIS610<\/entityName>\\n  <qualityCheck quali ... #> [11] <entityReport>\\n  <entityName>KMZGIS610<\/entityName>\\n  <qualityCheck qu ... #> [12] <entityReport>\\n  <entityName>GIS615<\/entityName>\\n  <qualityCheck quali ... #> [13] <entityReport>\\n  <entityName>KMZGIS615<\/entityName>\\n  <qualityCheck qu ... #> [14] <entityReport>\\n  <entityName>GIS620<\/entityName>\\n  <qualityCheck quali ... #> [15] <entityReport>\\n  <entityName>KMZGIS620<\/entityName>\\n  <qualityCheck qu ... #> [16] <entityReport>\\n  <entityName>GIS630<\/entityName>\\n  <qualityCheck quali ... #> [17] <entityReport>\\n  <entityName>KMZGIS630<\/entityName>\\n  <qualityCheck qu ... #> [18] <entityReport>\\n  <entityName>GIS635<\/entityName>\\n  <qualityCheck quali ... #> [19] <entityReport>\\n  <entityName>KMZGIS635<\/entityName>\\n  <qualityCheck qu ...  # Read as HTML qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\", frmt = \"html\") qualityReport #> {html_document} #> <html> #> [1] <body><table xmlns:qr=\"eml://ecoinformatics.org/qualityReport\"><tbody>\\n< ...  # Read as character qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\", frmt = \"char\") #> Error in report2char(xml2::read_xml(res), env = env): could not find function \"report2char\" # writeLines(qualityReport, \"./data/report.txt\"))"},{"path":"/reference/read_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data tables of a data package — read_tables","title":"Read data tables of a data package — read_tables","text":"Read data tables data package EML metadata.","code":""},{"path":"/reference/read_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data tables of a data package — read_tables","text":"","code":"read_tables(   eml,   strip.white = FALSE,   na.strings = NULL,   convert.missing.value = NULL,   add.units = FALSE )"},{"path":"/reference/read_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data tables of a data package — read_tables","text":"eml (xml_document, xml_node) EML metadata returned read_eml(). strip.white (logical) Strips leading trailing whitespaces unquoted fields. Default FALSE. na.strings (character) Strings interpreted NA. Setting na.strings = \"\" converts \"\" NA. default, blank strings \"\" read . convert.missing.value (logical) Converts missing value codes specified eml (e.g. \"-99999\", \"NaN\", \"measured\") NA. Missing value codes vary across data packages converting consistent form recognized R makes downstream use simpler. However, care must exercised using argument. author dataset described eml may defined \"missing value code\" mean something different expect (e.g. \"detection limit\") therefore reviewing authors missing value code definitions good idea. Default FALSE. add.units (logical) TRUE, variable's unit measurement added table separate column column name form: <unit>_<variable_name>. argument useful gathering variables long (attribute-value) table.","code":""},{"path":"/reference/read_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data tables of a data package — read_tables","text":"(list) List named data frames","code":""},{"path":"/reference/read_tables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read data tables of a data package — read_tables","text":"","code":"This function uses \\code{data.table::fread()} and uses default argument values if the EML based values return an error.  Default settings preserve the form the data were originally published in."},{"path":[]},{"path":"/reference/return_close.html","id":null,"dir":"Reference","previous_headings":"","what":"Return values from the CV that may be close to users' term — return_close","title":"Return values from the CV that may be close to users' term — return_close","text":"Return values CV may close users' term","code":""},{"path":"/reference/return_close.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return values from the CV that may be close to users' term — return_close","text":"","code":"return_close(term, cv)"},{"path":"/reference/return_close.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return values from the CV that may be close to users' term — return_close","text":"term (character) user-provided term needs validated cv (character) \"Term\" column corresponding CV","code":""},{"path":"/reference/return_close.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return values from the CV that may be close to users' term — return_close","text":"(list) Named list CV entries contain string","code":""},{"path":"/reference/validate_arguments.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate arguments of hymetDP functions — validate_arguments","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"Validate input arguments to hymetDP functions."},{"path":"/reference/validate_arguments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"validate_arguments(fun.name, fun.args)"},{"path":"/reference/validate_arguments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate arguments of hymetDP functions — validate_arguments","text":"fun.name (character) Name function validate_arguments() called. fun.args (named list) Arguments passed calling function formatted .list(environment()).","code":""},{"path":"/reference/validate_arguments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"Validation checks are function specific."},{"path":"/reference/validate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate tables against the model — validate_data","title":"Validate tables against the model — validate_data","text":"Validate tables model","code":""},{"path":"/reference/validate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate tables against the model — validate_data","text":"","code":"validate_data(dataset = NULL, path = NULL)"},{"path":"/reference/validate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate tables against the model — validate_data","text":"dataset (list) dataset structure returned read_data(). path (character) Path directory containing hymetDP tables files.","code":""},{"path":"/reference/validate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate tables against the model — validate_data","text":"(list) checks fail, list validation issues returned along warning. issues found NULL returned.","code":""},{"path":"/reference/validate_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate tables against the model — validate_data","text":"Validation checks: File names - File names hymetDP table names. Table presence - Required tables present. Column names - Column names tables match model. Column presence - Required columns present. Column classes - Column classes match model specification. Datetime format - Date time formats follow model specification. Primary keys - Primary keys tables unique. Composite keys - Composite keys (unique constraints) table unique. Referential integrity - Foreign keys corresponding primary key. Coordinate format - Values decimal degree format. Coordinate range - Values within -90 90 -180 180. Elevation - Values less Mount Everest (8848 m) greater Mariana Trench (-10984 m). CV Terms - Terms used valid ODM controlled vocabulary terms, required.","code":""},{"path":"/reference/validate_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Validate tables against the model — validate_data","text":"function used hymetDP creators (ensure created valid), maintainers (improve quality archived hymetDP datasets), users (ensure data used free error).","code":""},{"path":[]},{"path":"/reference/validate_odm_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"Validate input arguments to hymetDP functions that should have direct matches to terms in CUAHSI ODM CVs."},{"path":"/reference/validate_odm_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"validate_odm_terms(fun.name, fun.args)"},{"path":"/reference/validate_odm_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"fun.name (character) Name function validate_omd_terms() called. fun.args (named list) Arguments passed calling function formatted .list(environment()).","code":""},{"path":"/reference/validate_odm_terms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"Validation checks are function specific."},{"path":"/reference/write_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Write tables to file — write_tables","title":"Write tables to file — write_tables","text":"Write tables file","code":""},{"path":"/reference/write_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write tables to file — write_tables","text":"","code":"write_tables(   path,   sep = \",\",   DataValues = NULL,   Variables = NULL,   Methods = NULL,   Sources = NULL,   Sites = NULL,   QualityControlLevels = NULL,   SeriesCatalog = NULL,   Qualifiers = NULL )"},{"path":"/reference/write_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write tables to file — write_tables","text":"path (character) path directory files written. sep (character) Field delimiter use writing files. Default comma. DataValues (tbl_df, tbl, data.frame) DataValues table. Variables (tbl_df, tbl, data.frame) Variables table. Methods (tbl_df, tbl, data.frame) Methods table. Sources (tbl_df, tbl, data.frame) Sources table. Sites (tbl_df, tbl, data.frame) Sites table. QualityControlLevels (tbl_df, tbl, data.frame) QualityControlLevels table. SeriesCatalog (tbl_df, tbl, data.frame) SeriesCatalog table.","code":""},{"path":"/reference/write_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write tables to file — write_tables","text":"hymetDP tables sep delimited files","code":""},{"path":[]}]
