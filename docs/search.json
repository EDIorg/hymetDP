[{"path":[]},{"path":"https://kzollove.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, gender identity expression, level experience, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"https://kzollove.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best community Showing empathy towards community members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://kzollove.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"https://kzollove.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within project spaces public spaces individual representing project community. Examples representing project community include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"https://kzollove.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team info@environmentaldatainitiative.org. project team review investigate complaints, respond way deems appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"https://kzollove.github.io/hymetDP/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 1.4, available http://contributor-covenant.org/version/1/4","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"git-structure","dir":"","previous_headings":"","what":"Git structure","title":"Contributing Guidelines","text":"active branch development. development merged master releases. Please submit pull requests development.","code":""},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"repository-structure","dir":"","previous_headings":"","what":"Repository structure","title":"Contributing Guidelines","text":"repository structured standard R package following conventions outlined R Packages book. additional files provided part built R package listed .Rbuildignore.","code":""},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"code","dir":"","previous_headings":"","what":"Code","title":"Contributing Guidelines","text":"code package found R/. functions thoroughly documented roxygen2 notation; see Documentation. Code conform tidyverse Style guide.","code":""},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"Contributing Guidelines","text":"new feature bug-fix include unit-test demonstrating change. Unit tests follow testthat framework files tests/testthat. Please make sure testing suite passes issuing pull request. can done running check() devtools package, also check consistent documentation, etc.","code":""},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Contributing Guidelines","text":"function documentation generated automatically. Please edit documentation files man/ NAMESPACE. Instead, construct appropriate roxygen2 documentation function files R/ . documentation generated running devtools::document() function. Please consult R Packages book workflow unfamiliar . Note functions include examples documentation. Please use \\dontrun examples take seconds. Similarly, .md files base directory edited directly. Instead, edit .Rmd source files.","code":""},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"dependencies","dir":"","previous_headings":"","what":"Dependencies","title":"Contributing Guidelines","text":"package already contains large number dependencies (imports suggests). Therefore, new packages added creating new features reasonably achieved within existing set dependencies.","code":""},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"general-development-goals--guidelines","dir":"","previous_headings":"","what":"General Development Goals & Guidelines","title":"Contributing Guidelines","text":"Contribute code create, use, convert ecocomDP datasets. Maintain consistent user-facing API.","code":""},{"path":"https://kzollove.github.io/hymetDP/CONTRIBUTING.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributing Guidelines","text":"contributing guidelines based rOpenSci emld project.","code":""},{"path":"https://kzollove.github.io/hymetDP/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 hymetDP authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://kzollove.github.io/hymetDP/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kyle Zollo-Venecek. Author, maintainer.","code":""},{"path":"https://kzollove.github.io/hymetDP/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zollo-Venecek K (2022). hymetDP: Tools Create, Use, Convert hymetDP data. R package version 0.0.0.9000, https://github.com/kzollove/hymetDP.","code":"@Manual{,   title = {hymetDP: Tools to Create, Use, and Convert hymetDP data},   author = {Kyle Zollo-Venecek},   year = {2022},   note = {R package version 0.0.0.9000},   url = {https://github.com/kzollove/hymetDP}, }"},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Tools to Create, Use, and Convert hymetDP data","text":"Tools create, use, convert ‘hymetDP’ datasets. ‘hymetDP’ dataset design pattern harmonizing hydrological meteorological data research question agnostic format, source datasets published across multiple repositories, methods keep derived datasets --date underlying sources change. Based ecocomDP R package.","code":""},{"path":"https://kzollove.github.io/hymetDP/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Tools to Create, Use, and Convert hymetDP data","text":"Get latest development version:","code":"# install.packages(\"remotes\") remotes::install_github(\"kzollove/hymetDP\")"},{"path":"https://kzollove.github.io/hymetDP/index.html","id":"getting-help","dir":"","previous_headings":"","what":"Getting help","title":"Tools to Create, Use, and Convert hymetDP data","text":"Use GitHub Issues bug reporting, feature requests, general questions/discussions. filling bug reports, please include minimal reproducible example.","code":""},{"path":"https://kzollove.github.io/hymetDP/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Tools to Create, Use, and Convert hymetDP data","text":"Community contributions welcome! Please reference contributing guidelines details. Please note project released Contributor Code Conduct. participating project agree abide terms.","code":""},{"path":"https://kzollove.github.io/hymetDP/index.html","id":"logo","dir":"","previous_headings":"Contributing","what":"Logo","title":"Tools to Create, Use, and Convert hymetDP data","text":"Original photograph Michal Osmenda. file licensed Creative Commons Attribution-Share Alike 2.0 Generic license.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/CensorCodeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Censor Codes — CensorCodeCV","title":"Allowed Censor Codes — CensorCodeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Censor Codes","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/CensorCodeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Censor Codes — CensorCodeCV","text":"","code":"CensorCodeCV"},{"path":"https://kzollove.github.io/hymetDP/reference/CensorCodeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Censor Codes — CensorCodeCV","text":"data frame 6 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/CensorCodeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Censor Codes — CensorCodeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=CensorCodeCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/DataTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Data Types — DataTypeCV","title":"Allowed Data Types — DataTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Data Types","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/DataTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Data Types — DataTypeCV","text":"","code":"DataTypeCV"},{"path":"https://kzollove.github.io/hymetDP/reference/DataTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Data Types — DataTypeCV","text":"data frame 16 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/DataTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Data Types — DataTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=DataTypeCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/GeneralCategoryCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed General Categories — GeneralCategoryCV","title":"Allowed General Categories — GeneralCategoryCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary General Category","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/GeneralCategoryCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed General Categories — GeneralCategoryCV","text":"","code":"GeneralCategoryCV"},{"path":"https://kzollove.github.io/hymetDP/reference/GeneralCategoryCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed General Categories — GeneralCategoryCV","text":"data frame 10 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/GeneralCategoryCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed General Categories — GeneralCategoryCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=GeneralCategoryCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SampleMediumCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Sample Media — SampleMediumCV","title":"Allowed Sample Media — SampleMediumCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Sample Medium","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SampleMediumCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Sample Media — SampleMediumCV","text":"","code":"SampleMediumCV"},{"path":"https://kzollove.github.io/hymetDP/reference/SampleMediumCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Sample Media — SampleMediumCV","text":"data frame 24 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SampleMediumCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Sample Media — SampleMediumCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=SampleMediumCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SiteTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Site Types — SiteTypeCV","title":"Allowed Site Types — SiteTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Site Types","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SiteTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Site Types — SiteTypeCV","text":"","code":"SiteTypeCV"},{"path":"https://kzollove.github.io/hymetDP/reference/SiteTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Site Types — SiteTypeCV","text":"data frame 62 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SiteTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Site Types — SiteTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=SiteTypeCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SpatialReferencesCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Spatial References — SpatialReferencesCV","title":"Allowed Spatial References — SpatialReferencesCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Spatial References","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SpatialReferencesCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Spatial References — SpatialReferencesCV","text":"","code":"SpatialReferencesCV"},{"path":"https://kzollove.github.io/hymetDP/reference/SpatialReferencesCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Spatial References — SpatialReferencesCV","text":"data frame 343 rows 5 variables: SpatialReferencesID Integer identifier SRSID Spatial Reference System identifier SRSName Spatial Reference System name IsGeographic Boolean Notes Spatial Reference System notes","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/SpatialReferencesCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Spatial References — SpatialReferencesCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=SpatialReferences","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/UnitsCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Units — UnitsCV","title":"Allowed Units — UnitsCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Units","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/UnitsCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Units — UnitsCV","text":"","code":"UnitsCV"},{"path":"https://kzollove.github.io/hymetDP/reference/UnitsCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Units — UnitsCV","text":"data frame 394 rows 4 variables: UnitsID Unique unit identifier UnitsName Name unit UnitsType Type unit UnitsAbbreviation Standardized abbreviation symbol unit","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/UnitsCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Units — UnitsCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=Units","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/ValueTypeCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Value Types — ValueTypeCV","title":"Allowed Value Types — ValueTypeCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Value Type","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/ValueTypeCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Value Types — ValueTypeCV","text":"","code":"ValueTypeCV"},{"path":"https://kzollove.github.io/hymetDP/reference/ValueTypeCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Value Types — ValueTypeCV","text":"data frame 7 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/ValueTypeCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Value Types — ValueTypeCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=ValueTypeCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/VariableNameCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Variable Names — VariableNameCV","title":"Allowed Variable Names — VariableNameCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Variable Name","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/VariableNameCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Variable Names — VariableNameCV","text":"","code":"VariableNameCV"},{"path":"https://kzollove.github.io/hymetDP/reference/VariableNameCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Variable Names — VariableNameCV","text":"data frame 925 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/VariableNameCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Variable Names — VariableNameCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=VariableNameCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/VerticalDatumCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Allowed Vertical Datum — VerticalDatumCV","title":"Allowed Vertical Datum — VerticalDatumCV","text":"data frame representation CUAHSI ODM 1.1 Controlled Vocabulary Vertical Datum","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/VerticalDatumCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allowed Vertical Datum — VerticalDatumCV","text":"","code":"VerticalDatumCV"},{"path":"https://kzollove.github.io/hymetDP/reference/VerticalDatumCV.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Allowed Vertical Datum — VerticalDatumCV","text":"data frame 5 rows 2 variables: Term Controlled Vocabulary term Definition Definition Controlled Vocabulary term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/VerticalDatumCV.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Allowed Vertical Datum — VerticalDatumCV","text":"http://.cuahsi.org/mastercvreg/edit_cv11.aspx?tbl=VerticalDatumCV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/check_odm_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"Check term ODM Controlled Vocabulary","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/check_odm_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"","code":"check_odm_cv(term, cv)"},{"path":"https://kzollove.github.io/hymetDP/reference/check_odm_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"term (character) user-provided term needs validated cv (character) \"Term\" column corresponding CV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/check_odm_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check that a term is in a ODM Controlled Vocabulary — check_odm_cv","text":"(logical) TRUE exact match CV, otherwise FALSE","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/convert_missing_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert missing value codes to NA — convert_missing_value","title":"Convert missing value codes to NA — convert_missing_value","text":"Convert missing value codes NA","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/convert_missing_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert missing value codes to NA — convert_missing_value","text":"","code":"convert_missing_value(v, code, type)"},{"path":"https://kzollove.github.io/hymetDP/reference/convert_missing_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert missing value codes to NA — convert_missing_value","text":"v Vector values code (character) Missing value code type (character) Type (class) v . Supported types : \"character\", \"numeric\", \"datetime\"","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/convert_missing_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert missing value codes to NA — convert_missing_value","text":"Vector values code replaced NA class type","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_USGS_hymet.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"Create USGS hymetDP-formatted dataset","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_USGS_hymet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"","code":"create_USGS_hymet(site, param, start, end)"},{"path":"https://kzollove.github.io/hymetDP/reference/create_USGS_hymet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"site (character) USGS site code list site codes. Discover site codes dataRetrieval::whatNWISsites(). param (character) USGS parameter code list parameter codes. Discover parameter codes dataRetrieval::whatNWISdata(). start (character) Starting datetime data query. Format date strings YYYY-MM-DD, datetime strings YYYY-MM-DDThh:mm:ssZ. Format must match end parameter format. end (character) Ending datetime data query. Format date strings YYYY-MM-DD,","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_USGS_hymet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"list hymetDP tables","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_USGS_hymet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a USGS hymetDP-formatted dataset — create_USGS_hymet","text":"","code":"site <- c(\"06879650\", \"50065500\") param <- c(\"00060\") start <- c(\"2020-06-01T12:30:00Z\") end <- c(\"2021-01-01T12:30:00Z\")  usgs_hymet <- create_USGS_hymet(site, param, start, end) #> Downloading data from USGS site 06879650, parameter 00060 #> Downloading data from USGS site 50065500, parameter 00060 #> Generating hymetDP tables..."},{"path":"https://kzollove.github.io/hymetDP/reference/create_citation.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"Create EDI data package citation EML hosted EDI Data Portal","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_citation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"","code":"create_citation(eml = eml)"},{"path":"https://kzollove.github.io/hymetDP/reference/create_citation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"eml (character) EML document valid EDI package identifier can extracted.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_citation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an EDI data package citation from EML hosted on the EDI Data Portal — create_citation","text":"(character) EDI data package citation.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_data_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the DataValues table — create_data_values","title":"Create the DataValues table — create_data_values","text":"Create DataValues table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_data_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the DataValues table — create_data_values","text":"","code":"create_data_values(   L0_flat = flat,   ValueID,   DataValue,   ValueAccuracy = NULL,   LocalDateTime,   UTCOffset,   DateTimeUTC = NULL,   SiteCode,   VariableCode,   OffsetValue = NULL,   OffsetTypeCode = NULL,   CensorCode = NULL,   QualifierCode = NULL,   MethodCode,   QualityControlLevelCode,   SourceCode,   NoDataValue )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_data_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the DataValues table — create_data_values","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). ValueID (character) Column L0_flat containing identifier assigned unique data value. DataValue (character) Column L0_flat containing numeric value observation. ValueAccuracy (character) Optional. Column L0_flat containing umeric value describes measurement accuracy data value. LocalDateTime (character) Column L0_flat containing local date time data value observed. UTCOffset (character) Column L0_flat containing offset hours UTC time corresponding LocalDateTime value. DateTimeUTC (character) Column L0_flat containing UTC date time data value observed. SiteCode (character) Column L0_flat containing code used organization collects data identify site. VariableCode (character) Column L0_flat containing code used organization collects data identify variable. OffsetValue (character) Optional. Column L0_flat containing distance datum control point point data value observed. CensorCode (character) Column L0_flat containing text indication whether data value censored. Defaults \"nc\" (Censored). QualifierCode (character) Optional. Column L0_flat containing flag indicating peculiarity particular data value. MethodCode (character) Column L0_flat containing code used organization collects data identify Method. QualityControlLevelCode (character) Column L0_flat containing code identifies level quality control value subjected . SourceCode (character) Column L0_flat containing code identifies organization created data. NoDataValue (character) Column L0_flat containing numeric value used encode data value available variable. OffsetTypeCodeMandatory (character) OffsetValue used. Column L0_flat containing code used organization collects data identify OffsetType.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_data_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the DataValues table — create_data_values","text":"(tbl_df, tbl, data.frame) DataValues table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_data_values.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the DataValues table — create_data_values","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_data_values.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the DataValues table — create_data_values","text":"","code":"flat <- hymet_L0_flat    DataValues <- hymetDP::create_data_values(     L0_flat = flat,     ValueID = \"ValueID\",     DataValue = \"DataValue\",     ValueAccuracy = NULL,     LocalDateTime = \"LocalDateTime\",     UTCOffset = \"UTCOffset\",     DateTimeUTC = \"DateTimeUTC\",     SiteCode = \"SiteCode\",     VariableCode = \"VariableCode\",     OffsetValue = NULL,     OffsetTypeCode = NULL,     CensorCode = NULL,     QualifierCode = NULL,     MethodCode = \"MethodCode\",     QualityControlLevelCode = \"QualityControlLevelCode\",     SourceCode = \"SourceCode\",     NoDataValue = \"NoDataValue\")    DataValues #> # A tibble: 30,003 × 15 #>    ValueID DataValue ValueAccuracy LocalDateTime  UTCOffset DateTimeUTC SiteCode #>    <chr>       <dbl>         <dbl> <chr>              <dbl> <chr>       <chr>    #>  1 1           144.             NA 2002-01-11 23…        13 2002-01-11… 1        #>  2 2             0.1            NA 2002-01-11 23…        13 2002-01-11… 1        #>  3 3            16.3            NA 2002-01-11 23…        13 2002-01-11… 1        #>  4 4           121.             NA 2002-01-12 00…        13 2002-01-11… 1        #>  5 5             0.1            NA 2002-01-12 00…        13 2002-01-11… 1        #>  6 6            16.4            NA 2002-01-12 00…        13 2002-01-11… 1        #>  7 7           116.             NA 2002-01-12 00…        13 2002-01-11… 1        #>  8 8             0.1            NA 2002-01-12 00…        13 2002-01-11… 1        #>  9 9            16.9            NA 2002-01-12 00…        13 2002-01-11… 1        #> 10 10          139.             NA 2002-01-12 00…        13 2002-01-11… 1        #> # … with 29,993 more rows, and 8 more variables: VariableCode <chr>, #> #   OffsetValue <dbl>, OffsetTypeCode <chr>, CensorCode <chr>, #> #   QualifierCode <chr>, MethodCode <chr>, SourceCode <chr>, #> #   QualityControlLevelCode <chr>"},{"path":"https://kzollove.github.io/hymetDP/reference/create_eml.html","id":null,"dir":"Reference","previous_headings":"","what":"Create EML metadata — create_eml","title":"Create EML metadata — create_eml","text":"Create EML metadata","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_eml.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create EML metadata — create_eml","text":"","code":"create_eml(   path,   source_id = NULL,   derived_id,   script,   script_description,   is_about = NULL,   contact,   user_id,   user_domain,   url = NULL )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_eml.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create EML metadata — create_eml","text":"path (character) Path directory containing hymetDP tables, conversion script, EML metadata written. source_id (character) Identifier data package published supported repository. Currently, EDI Data Repository supported. derived_id (character) Identifier dataset created. script (character) Name file used convert source_id derived_id. script_description (character) Description script. is_about (named character) optional argument specifying dataset level annotations describing dataset \"\". contact (data.frame) Contact information person created hymetDP dataset, containing columns: givenName surName organizationName electronicMailAddress user_id (character) Identifier user associated user_domain. user_domain (character) Domain (data repository) user_id belongs . Currently, EDI supported. url (character) URL publicly accessible directory containing hymetDP tables, conversion script, EML metadata. argument supports direct download data entities data repository used automated revisioning publication.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_eml.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create EML metadata — create_eml","text":"EML metadata file.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_eml.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create EML metadata — create_eml","text":"function creates EML record hymetDP dataset combining metadata source_id boiler-plate metadata describing hymetDP model. Changes source_id EML include: <access> Adds user_id list principals granted read write access hymetDP data package EML describes. <title> Adds note derived data package hymetDP format. <pubDate> Adds date EML created. <abstract> Adds note derived data package hymetDP format. <keywordSet> Adds \"hymetDP\" keyword enable search discovery hymetDP data packages data repository published. <intellectualRights> Keeps intact original intellectual rights license source_id released , uses CCO missing. <contact> Adds hymetDP creator point contact. <methodStep> Adds note data package created script, adds provenance metadata noting derived dataset describes source_id can accessed. <dataTables> Replaces source_id table metadata descriptions hymetDP tables. <otherEntity> Adds script script_description. otherEntities source_id removed. <annotations> Adds boilerplate annotations describing hymetDP dataset, entity, entity attribute levels.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_eml.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create EML metadata — create_eml","text":"","code":"if (FALSE) { # Create directory with hymetDP tables for create_eml() mypath <- paste0(tempdir(), \"/data\") dir.create(mypath) inpts <- c(hymet_L1$tables, path = mypath) do.call(write_tables, inpts) file.copy(system.file(\"extdata\", \"create_hymetDP.R\", package = \"hymetDP\"), mypath) dir(mypath)  # Add self as contact information incase questions arise additional_contact <- data.frame(   givenName = 'Kyle',   surName = 'Zollo-Venecek',   organizationName = 'Environmental Data Initiative',   electronicMailAddress = 'hymetdp@gmail.com',   stringsAsFactors = FALSE)  # Create EML eml <- create_eml(   path = mypath,   source_id = \"knb-lter-mcm.9003.11\",   derived_id = \"edi.10101.1\",   is_about = dataset_annotations,   script = \"create_ecocomDP.R\",   script_description = \"A function for converting knb-lter-mcm.9003 to hymetDP\",   contact = additional_contact,   user_id = 'hymetdp',   user_domain = 'EDI')  dir(mypath) View(eml)  # Clean up unlink(mypath, recursive = TRUE) }"},{"path":"https://kzollove.github.io/hymetDP/reference/create_methods.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Methods table — create_methods","title":"Create the Methods table — create_methods","text":"Create Methods table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_methods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Methods table — create_methods","text":"","code":"create_methods(   L0_flat = flat,   MethodCode,   MethodDescription,   MethodLink = NULL )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_methods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Methods table — create_methods","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). MethodCode (character) Column L0_flat containing code used organization collects data identify Method. MethodDescription (character) Column L0_flat containing text description method. MethodLink (character) Optional. Column L0_flat containing link additional reference material method. single valid URL.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_methods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Methods table — create_methods","text":"(tbl_df, tbl, data.frame) Methods table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_methods.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Methods table — create_methods","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_methods.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Methods table — create_methods","text":"","code":"flat <- hymet_L0_flat   Methods <- hymetDP::create_methods(    L0_flat = flat,    MethodCode = \"MethodCode\",    MethodDescription = \"MethodDescription\")   Methods #> # A tibble: 1 × 3 #>   MethodCode MethodDescription                                        MethodLink #>   <chr>      <chr>                                                    <chr>      #> 1 1          Campbell CR10 dataloggers were used to record stream st… NA"},{"path":"https://kzollove.github.io/hymetDP/reference/create_qualifiers.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Qualifiers table — create_qualifiers","title":"Create the Qualifiers table — create_qualifiers","text":"Create Qualifiers table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_qualifiers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Qualifiers table — create_qualifiers","text":"","code":"create_qualifiers(L0_flat = flat, QualifierCode, QualifierDescription)"},{"path":"https://kzollove.github.io/hymetDP/reference/create_qualifiers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Qualifiers table — create_qualifiers","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). QualifierCode (character) Column L0_flat containing code indicate given data qualifier. QualifierDescription (character) Column L0_flat containing text data qualifying comment, e.g., low battery voltage sensor.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_qualifiers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Qualifiers table — create_qualifiers","text":"flat <- hymet_L0_flat Qualifiers <- hymetDP::create_qualifiers( L0_flat = flat, QualifierCode = \"QualifierCode\", QualifierDescription = \"QualifierDescription\") Qualifiers","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_qualifiers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Qualifiers table — create_qualifiers","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_quality_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the QualityControlLevels table — create_quality_control","title":"Create the QualityControlLevels table — create_quality_control","text":"Create QualityControlLevels table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_quality_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the QualityControlLevels table — create_quality_control","text":"","code":"create_quality_control(   L0_flat = flat,   QualityControlLevelCode,   Definition,   Explanation )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_quality_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the QualityControlLevels table — create_quality_control","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). QualityControlLevelCode (character) Column L0_flat containing code used identify level quality control data values subjected. Definition (character) Column L0_flat containing definition Quality Control Level. Examples: Raw Data, Quality Controlled Data. confused data qualifiers. Explanation (character) Column L0_flat containing explanation Quality Control Level.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_quality_control.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the QualityControlLevels table — create_quality_control","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_quality_control.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the QualityControlLevels table — create_quality_control","text":"","code":"flat <- hymet_L0_flat    QualityControlLevels <- hymetDP::create_quality_control(     L0_flat = flat,     QualityControlLevelCode = \"QualityControlLevelCode\",     Definition = \"Definition\",     Explanation = \"Explanation\")    QualityControlLevels #> # A tibble: 1 × 3 #>   QualityControlLevelCode Definition              Explanation                    #>   <chr>                   <chr>                   <chr>                          #> 1 1                       Quality controlled data Quality controlled data that …"},{"path":"https://kzollove.github.io/hymetDP/reference/create_series_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the SeriesCatalog table — create_series_catalog","title":"Create the SeriesCatalog table — create_series_catalog","text":"Create SeriesCatalog table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_series_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the SeriesCatalog table — create_series_catalog","text":"","code":"create_series_catalog(   L0_flat = NULL,   Sources = NULL,   Methods = NULL,   Variables = NULL,   Sites = NULL,   QualityControlLevels = NULL,   DataValues = NULL )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_series_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the SeriesCatalog table — create_series_catalog","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). Sources (tbl_df, tbl, data.frame) Sources table. Methods (tbl_df, tbl, data.frame) Methods table. Variables (tbl_df, tbl, data.frame) Variables table. Sites (tbl_df, tbl, data.frame) Sites table. QualityControlLevels (tbl_df, tbl, data.frame) QualityControlLevels table. DataValues (tbl_df, tbl, data.frame) DataValues table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_series_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the SeriesCatalog table — create_series_catalog","text":"(tbl_df, tbl, data.frame) SeriesCatalog table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_series_catalog.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the SeriesCatalog table — create_series_catalog","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_series_catalog.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the SeriesCatalog table — create_series_catalog","text":"","code":"flat <- hymet_L0_flat  Sources <- hymetDP::create_sources(   L0_flat = flat,   SourceCode = \"SourceCode\",   Organization = \"Organization\",   SourceDescription = \"SourceDescription\",   SourceLink = \"SourceLink\",   ContactName = \"ContactName\",   Phone = \"Phone\",   Email = \"Email\",   Address = \"Address\",   City = \"City\",   State = \"State\",   ZipCode = \"ZipCode\",   Citation = \"Citation\")  Methods <- hymetDP::create_methods(   L0_flat = flat,   MethodCode = \"MethodCode\",   MethodDescription = \"MethodDescription\")  Variables <- hymetDP::create_variables(   L0_flat = flat,   VariableCode = \"VariableCode\",   VariableName = \"VariableName\",   VariableUnitsName = \"VariableUnitsName\",   SampleMedium = \"SampleMedium\",   ValueType = \"ValueType\",   IsRegular = \"IsRegular\",   TimeSupport = \"TimeSupport\",   TimeUnitsName = \"TimeUnitsName\",   DataType = \"DataType\",   GeneralCategory = \"GeneralCategory\",   NoDataValue = \"NoDataValue\")  Sites <- hymetDP::create_sites(   L0_flat = flat,   SiteCode = \"SiteCode\",   SiteName = \"SiteName\",   Latitude = \"Latitude\",   Longitude = \"Longitude\",   LatLongDatumSRSName = NULL,   Elevation_m = NULL,   VerticalDatum = NULL,   LocalX = NULL,   LocalY = NULL,   LocalProjectionSRSName = NULL,   PosAccuracy_m = NULL,   State = NULL,   County = NULL,   Comments = NULL,   SiteType = \"SiteType\") #> Warning: Unknown or uninitialised column: `LatLongDatumSRSName`.  QualityControlLevels <- hymetDP::create_quality_control(   L0_flat = flat,   QualityControlLevelCode = \"QualityControlLevelCode\",   Definition = \"Definition\",   Explanation = \"Explanation\")  DataValues <- hymetDP::create_data_values(   L0_flat = flat,   ValueID = \"ValueID\",   DataValue = \"DataValue\",   ValueAccuracy = NULL,   LocalDateTime = \"LocalDateTime\",   UTCOffset = \"UTCOffset\",   DateTimeUTC = \"DateTimeUTC\",   SiteCode = \"SiteCode\",   VariableCode = \"VariableCode\",   OffsetValue = NULL,   OffsetTypeCode = NULL,   CensorCode = NULL,   QualifierCode = NULL,   MethodCode = \"MethodCode\",   QualityControlLevelCode = \"QualityControlLevelCode\",   SourceCode = \"SourceCode\",   NoDataValue = \"NoDataValue\")  SeriesCatalog <- hymetDP::create_series_catalog(   Sources = Sources,   Methods = Methods,   Variables = Variables,   Sites = Sites,   QualityControlLevels = QualityControlLevels,   DataValues = DataValues)  SeriesCatalog #>   SeriesID SiteCode #> 1        1        1 #> 2        2        1 #> 3        3        1 #>                                                                                                                                              SiteName #> 1 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #> 2 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #> 3 USGS site 9; coordinates taken from 1996-97 GPS measurements at center of weir Parent Stream: Andersen Creek Provenance : GPS96-97.DOCID: andrsn_h1 #>   VariableCode         VariableName           VariableUnitsName  SampleMedium #> 1            1            Discharge           liters per second Surface water #> 2            2          Temperature              degree celsius Surface water #> 3            3 Specific conductance microsiemens per centimeter Surface water #>           ValueType TimeSupport TimeUnitsName   DataType GeneralCategory #> 1     Derived Value          15        minute Continuous       Hydrology #> 2 Field Observation          15        minute Continuous       Hydrology #> 3 Field Observation          15        minute Continuous       Hydrology #>   MethodCode #> 1          1 #> 2          1 #> 3          1 #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      MethodDescription #> 1 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #> 2 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #> 3 Campbell CR10 dataloggers were used to record stream stage, water temperature, and conductivity in a network of stream gages. Stage is monitored with pressure transducers; PSS-1 and PS-2 models form Paroscientific Corporation, and Accubars from Sutron Corporation. The pressure transducers measure the backpressure in orifice lines set into or above controls in the stream channel. In addition, some of the sites monitor water temperature and conductivity with either USGS minimonitor probes, or Campbell temperature/conductivity probes. Ratings are developed for the stage/discharge relationship at each site by measuring streamflow with current meters or portable flumes, according to standard USGS methods. Datum corrections to the stage are determined by periodically surveying the elevation of the orifice line to the control and nearby reference marks. Calibrations for the temperature and conductivity are assessed by measuring these parameters with portable field meters while simultaneously noting the readings from the gage probes. Data is downloaded into Campbell storage modules, and retrieved into pcs. From there, the data is sent to a USGS computer, where time discrepancies are resolved, and the data is loaded into ADAPS, a database system developed in the USGS for maintaining and processing water data. A determination for each site as to when the stream was flowing and when it was not is made. For water temperature and conductivity, bad data is deleted. Variable shifts are determined based on field calibration measurements, and other indicators. The shifts are applied to the remaining good data inside of ADAPS. The data is pulled out of ADAPS, and reformatted for input into ORACLE. Cases of water temperature below reasonable values are set to lower limits. A quality code is assigned to every value. The resulting data is uploaded into the ORACLE and the McMurdo database. Before 2011, For stage/discharge, bad data is deleted. Survey data is reviewed to compute weir elevations an datum corrections. A rating curve is developed graphically, based on available data, and entered into ADAPS. All applicable shifts and datum corrections are entered into ADAPS. All corrections and ratings are run against the good stage data to compute the discharge at each recording interval. The data is pulled out of ADAPS, and reformatted for input into ORACLE. A quality code is assigned to every value. The resulting data is uploaded into ORACLE and the McMurdo database. ADAPS deprecated in favor of Aquarius software in 2012. Similar procedure is used in Aquarius to convert and curate the data. Metadata was enhanced in 2013 and 2014 by Inigo San Gil. In March 2021, data from the 2016-17 field season was replaced to correct a previously published error, in which discharge was reported in cubicFeetPerSecond (CFS) instead of litersPerSecond (l/s). #>   SourceCode             Organization #> 1          1 McMurdo Dry Valleys LTER #> 2          1 McMurdo Dry Valleys LTER #> 3          1 McMurdo Dry Valleys LTER #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         SourceDescription #> 1 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #> 2 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #> 3 As part of the Long Term Ecological Research (LTER) project in the McMurdo Dry Valleys of Antarctica, a systematic sampling program has been undertaken to monitor the glacial meltwater streams in that region. This package contains data pertaining to continuous monitored water quality and quantity parameters measured with automatic recording devices on streams in this region. Specifically, this metadata record describes the hydrology data set for the McMurdo Dry Valleys' Andersen Creek at the H1 streamgage, located in the Hoare Basin of Taylor Valley. Measurements commenced during the 1993-94 season and are ongoing. This dataset extends through the first half of the 2019-20 field season. #>                                                                                                                                                                                                                                                                                                                                           Citation #> 1 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #> 2 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #> 3 Gooseff, M. and D. McKnight. 2021. Seasonal high-frequency measurements of discharge, water temperature, and specific conductivity from Andersen Creek at H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing) ver 11. Environmental Data Initiative. https://doi.org/10.6073/pasta/7dd79fd8d81b421f8b64d446babbab65. (Accessed 2022-04-11). #>   QualityControlLevelCode       BeginDateTime         EndDateTime #> 1                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #> 2                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #> 3                       1 2002-01-11 23:45:00 2003-12-26 09:30:00 #>      BeginDateTimeUTC      EndDateTimeUTC ValueCount #> 1 2002-01-11 10:45:00 2003-12-25 20:30:00      10001 #> 2 2002-01-11 10:45:00 2003-12-25 20:30:00      10001 #> 3 2002-01-11 10:45:00 2003-12-25 20:30:00      10001"},{"path":"https://kzollove.github.io/hymetDP/reference/create_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Sites table — create_sites","title":"Create the Sites table — create_sites","text":"Create Sites table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Sites table — create_sites","text":"","code":"create_sites(   L0_flat = flat,   SiteCode,   SiteName,   Latitude,   Longitude,   LatLongDatumSRSName = NULL,   Elevation_m = NULL,   VerticalDatum = NULL,   LocalX = NULL,   LocalY = NULL,   LocalProjectionSRSName = NULL,   PosAccuracy_m = NULL,   State = NULL,   County = NULL,   Comments = NULL,   SiteType = NULL )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Sites table — create_sites","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). SiteCode (character) Column L0_flat containing user organization-defined code collects data identify site. SiteName (character) Column L0_flat containing full name sampling site. Latitude (character) Column L0_flat containing latitude decimal degrees. Longitude (character) Column L0_flat containing longitude decimal degrees. LatLongDatumSRSName (character) Column L0_flat containing spatial reference system latitude longitude coordinates. Choose SRSName IsGeographic=True SpatialReferencesCV. View possible options SpatialReferencesCV$SRSName[SpatialReferencesCV$IsGeographic] Elevation_m (character) Column L0_flat containing elevation sampling location meters. VerticalDatum (character) Column L0_flat containing Vertical datum elevation. Choose Term VerticalDatum controlled vocabulary. LocalX (character) Column L0_flat containing local projection X coordinate. LocalY (character) Column L0_flat containing local projection Y coordinate. LocalProjectionSRSName (character) Column L0_flat containing full text name spatial reference system local coordinates. field optional necessary local coordinates given. Choose SRSName SpatialReferencesCV. PosAccuracy_m (character) Column L0_flat containing value giving accuracy positional information specified meters. State (character) Column L0_flat containing name state monitoring site located. County (character) Column L0_flat containing name county monitoring site located. Comments (character) Column L0_flat containing comments related site. SiteType (character) Column L0_flat containing type site. Choose Term SiteTypeCV.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_sites.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Sites table — create_sites","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_sites.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Sites table — create_sites","text":"","code":"flat <- hymet_L0_flat    Sites <- hymetDP::create_sites(     L0_flat = flat,     SiteCode = \"SiteCode\",     SiteName = \"SiteName\",     Latitude = \"Latitude\",     Longitude = \"Longitude\",     LatLongDatumSRSName = NULL,     Elevation_m = NULL,     VerticalDatum = NULL,     LocalX = NULL,     LocalY = NULL,     LocalProjectionSRSName = NULL,     PosAccuracy_m = NULL,     State = NULL,     County = NULL,     Comments = NULL,     SiteType = \"SiteType\") #> Warning: Unknown or uninitialised column: `LatLongDatumSRSName`.    Sites #> # A tibble: 1 × 15 #>   SiteCode SiteName              Latitude Longitude LatLongDatumSRS… Elevation_m #>   <chr>    <chr>                    <dbl>     <dbl> <chr>                  <dbl> #> 1 1        USGS site 9; coordin…    -77.6      163. Unknown                   NA #> # … with 9 more variables: VerticalDatum <chr>, LocalX <dbl>, LocalY <dbl>, #> #   LocalProjectionSRSName <chr>, PosAccuracy_m <dbl>, State <chr>, #> #   County <chr>, Comments <chr>, SiteType <chr>"},{"path":"https://kzollove.github.io/hymetDP/reference/create_sources.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Sources table — create_sources","title":"Create the Sources table — create_sources","text":"Create Sources table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_sources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Sources table — create_sources","text":"","code":"create_sources(   L0_flat = flat,   SourceCode,   Organization,   SourceDescription,   SourceLink = NULL,   ContactName,   Phone,   Email,   Address,   City,   State,   ZipCode,   Citation )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_sources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Sources table — create_sources","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). SourceCode (character) Column L0_flat containing code identifies organization created data. Organization (character) Column L0_flat containing name organization collected data. SourceDescription (character) Column L0_flat containing full text description source data. SourceLink (character) Column L0_flat containing link original data file data source. ContactName (character) Column L0_flat containing name contact person data source. Phone (character) Column L0_flat containing phone number contact person. Email (character) Column L0_flat containing email address contact person. Address (character) Column L0_flat containing street address contact person. City (character) Column L0_flat containing city contact person located. State (character) Column L0_flat containing state contact person located. ZipCode (character) Column L0_flat containing US Zip Code country postal code. Citation (character) Column L0_flat containing Text string gives citation used data source referenced.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_sources.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Sources table — create_sources","text":"(tbl_df, tbl, data.frame) Sources table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_sources.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Sources table — create_sources","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.#'","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_sources.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Sources table — create_sources","text":"","code":"flat <- hymet_L0_flat    Sources <- hymetDP::create_sources(     L0_flat = flat,     SourceCode = \"SourceCode\",     Organization = \"Organization\",     SourceDescription = \"SourceDescription\",     SourceLink = \"SourceLink\",     ContactName = \"ContactName\",     Phone = \"Phone\",     Email = \"Email\",     Address = \"Address\",     City = \"City\",     State = \"State\",     ZipCode = \"ZipCode\",     Citation = \"Citation\")    Sources #> # A tibble: 1 × 12 #>   SourceCode Organization    SourceDescripti… SourceLink ContactName Phone Email #>   <chr>      <chr>           <chr>            <chr>      <chr>       <chr> <chr> #> 1 1          McMurdo Dry Va… As part of the … https://d… McMurdo Dr… Unkn… im@m… #> # … with 5 more variables: Address <chr>, City <chr>, State <chr>, #> #   ZipCode <chr>, Citation <chr>"},{"path":"https://kzollove.github.io/hymetDP/reference/create_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the Variables table — create_variables","title":"Create the Variables table — create_variables","text":"Create Variables table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the Variables table — create_variables","text":"","code":"create_variables(   L0_flat = flat,   VariableCode,   VariableName,   VariableUnitsName,   SampleMedium,   ValueType,   IsRegular,   TimeSupport,   TimeUnitsName,   DataType,   GeneralCategory,   NoDataValue )"},{"path":"https://kzollove.github.io/hymetDP/reference/create_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the Variables table — create_variables","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). VariableCode (character) Column L0_flat containing user organization-defined code describe variable. VariableName (character) Column L0_flat containing full text name variable measured, observed, modeled, etc. Must ODM CV (see VariableNameCV) VariableUnitsName (character) Column L0_flat containing name units data values associated variable. Must ODM CV (see UnitsCV) SampleMedium (character) Column L0_flat containing medium sample observation taken made. Must ODM CV (see SampleMediumCV) ValueType (character) Column L0_flat indicates data value generated. Must ODM CV (see ValueTypeCV) IsRegular (character) Column L0_flat indicates whether data values regularly sampled time series. TimeSupport (character) Column L0_flat containing numerical value indicates time support (temporal footprint) data values. 0 used indicate data values instantaneous. values indicate time data values implicitly explicitly averaged aggregated. TimeUnitsName (character) Column L0_flat containing name units time support. TimeSupport 0, indicating instantaneous observation, unit needs still given completeness, although arbitrary. Must ODM CV (see UnitsCV) DataType (character) Column L0_flat indicates value applies time interval. Must ODM CV (see DataTypeCV) GeneralCategory (character) Column L0_flat containing general category data. Must ODM CV (see GeneralCategoryCV) NoDataValue (character) Column L0_flat containing numeric value used encode data value available variable.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_variables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the Variables table — create_variables","text":"(tbl_df, tbl, data.frame) Variables table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/create_variables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create the Variables table — create_variables","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/create_variables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create the Variables table — create_variables","text":"","code":"flat <- hymet_L0_flat    Variables <- hymetDP::create_variables(     L0_flat = flat,     VariableCode = \"VariableCode\",     VariableName = \"VariableName\",     VariableUnitsName = \"VariableUnitsName\",     SampleMedium = \"SampleMedium\",     ValueType = \"ValueType\",     IsRegular = \"IsRegular\",     TimeSupport = \"TimeSupport\",     TimeUnitsName = \"TimeUnitsName\",     DataType = \"DataType\",     GeneralCategory = \"GeneralCategory\",     NoDataValue = \"NoDataValue\")    Variables #> # A tibble: 3 × 11 #>   VariableCode VariableName    VariableUnitsNa… SampleMedium ValueType IsRegular #>   <chr>        <chr>           <chr>            <chr>        <chr>     <lgl>     #> 1 1            Discharge       liters per seco… Surface wat… Derived … TRUE      #> 2 2            Temperature     degree celsius   Surface wat… Field Ob… TRUE      #> 3 3            Specific condu… microsiemens pe… Surface wat… Field Ob… TRUE      #> # … with 5 more variables: TimeSupport <dbl>, TimeUnitsName <chr>, #> #   DataType <chr>, GeneralCategory <chr>, NoDataValue <dbl>"},{"path":"https://kzollove.github.io/hymetDP/reference/define_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP method — define_method","title":"Define a hymetDP method — define_method","text":"Define hymetDP method","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP method — define_method","text":"","code":"define_method(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = NULL,   VariableCode = NULL,   MethodDescription = NULL,   MethodLink = NULL )"},{"path":"https://kzollove.github.io/hymetDP/reference/define_method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP method — define_method","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). local_variable_column (character) Column L0_flat table containing L0 variable name. local_variable (character) Reference value (values) local_variable_column L0_flat table new hymetDP method refers. VariableCode (character) auto-generated primary key variable (column VariableCode). Another way link method value (values). Takes priority local_variable. Provide one multiple codes. MethodDescription (character) Text description method. MethodLink (character) Optional. Link additional reference material method. single valid URL.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP method — define_method","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus one additional column method description (two additional columns method link defined). Column name includes auto-generated MethodCode (.e. MethodDescription_1), become primary key Methods table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_method.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP method — define_method","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a hymetDP method — define_method","text":"","code":"flat <- hymet_L0_flat[1:19]  flat <- hymetDP::define_method(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = \"DSCHRGE_RATE\",   VariableCode = c(1,2,3),   MethodDescription = [2868 chars quoted with '\"'],   MethodLink = NULL)"},{"path":"https://kzollove.github.io/hymetDP/reference/define_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP source — define_source","title":"Define a hymetDP source — define_source","text":"Define hymetDP source","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_source.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP source — define_source","text":"","code":"define_source(   L0_flat = flat,   eml = eml,   Organization = NULL,   SourceDescription = NULL,   SourceLink = NULL,   ContactName = NULL,   Phone = NULL,   Email = NULL,   Address = NULL,   City = NULL,   State = NULL,   ZipCode = NULL,   Citation = NULL )"},{"path":"https://kzollove.github.io/hymetDP/reference/define_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP source — define_source","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). eml ('xml_document' 'xml_node') EML metadata. Organization (character) Name organization collected data. SourceDescription (character) Full text description source data. provided, default abstract EML document. SourceLink (character) Optional. Full text description source data. provided, default DOI EML document. ContactName (character) Name contact person data source. provided, contact information default first contact listed EML document. Phone (character) Phone number contact person. Email (character) Email addresss contact person. Address (character) Street address contact person. City (character) City contact person located. State (character) State contact person located. Use two letter abbreviations US. countries give full country name. ZipCode (character) US Zip Code country postal code. Citation (character) Text string gives citation used data source referenced. provided, default Citation appears (appear) EDI Data Portal EML document.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_source.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP source — define_source","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus additional columns Source information.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_source.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP source — define_source","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_source.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a hymetDP source — define_source","text":"","code":"flat <- hymet_L0_flat[1:30]  eml <- EDIutils::read_metadata('knb-lter-mcm.9003.11')  flat <- define_source(   L0_flat = flat,   eml = eml) #> SourceDescription added #> SourceLink added #> Citation added #> Contact Info Added"},{"path":"https://kzollove.github.io/hymetDP/reference/define_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Define a hymetDP variable — define_variable","title":"Define a hymetDP variable — define_variable","text":"Define hymetDP variable","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Define a hymetDP variable — define_variable","text":"","code":"define_variable(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = NULL,   variable_name = local_variable,   variable_units = NULL,   sample_medium = \"Unknown\",   value_type = \"Unknown\",   is_regular = FALSE,   time_support = 0,   time_units = \"hour\",   data_type = \"Unknown\",   general_category = \"Unknown\",   no_data = -9999 )"},{"path":"https://kzollove.github.io/hymetDP/reference/define_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Define a hymetDP variable — define_variable","text":"L0_flat (tbl_df, tbl, data.frame) fully joined source L0 dataset, \"flat\" format (see details). local_variable_column (character) Column L0_flat table containing L0 variable name. local_variable (character) Reference value local_variable_column L0_flat table new hymetDP variable refers. variable_name (character) CUAHSI ODM Controlled Vocabulary name variable measured, observed, modeled, etc. Defaults local_variable value. variable_units (character) CUAHSI ODM Controlled Vocabulary name units data values associated variable. Defaults column unit L0_flat table left unspecified. sample_medium (character) CUAHSI ODM Controlled Vocabulary name medium sample observation taken made. value_type (character) CUAHSI ODM Controlled Vocabulary value indicates data value generated. is_regular (boolean) Value indicates whether data values regularly sampled time series. Choose TRUE FALSE. time_support (numeric) Numerical value indicates time support (temporal footprint) data values. 0 used indicate data values instantaneous. values indicate time data values implicitly explicitly averaged aggregated. Goes along time_units is_regular == TRUE. time_units (character) CUAHSI ODM Controlled Vocabulary name units time support. time_support == 0, indicating instantaneous observation, unit needs still given completeness, although arbitrary. data_type (character) CUAHSI ODM Controlled Vocabulary value indicates value applies time interval. general_category (character) CUAHSI ODM Controlled Vocabulary value general category data  (.e. Hydrology). no_data (numeric) Numeric value used encode data value available variable. DataValues reformatted match value.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Define a hymetDP variable — define_variable","text":"(tbl_df, tbl, data.frame) augmented version original flat table, original columns plus one specified variable values (.e. variable_name, variable_units, etc.), plus VariableCode column, auto-generated integer value become primary key Variables table. Columns added first time function run. Subsequent runs append values existing columns.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_variable.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Define a hymetDP variable — define_variable","text":"function appends columns L0_flat table returns augmented table. \"flat\" format refers fully joined source L0 dataset \"wide\" form exception core observation variables, \"long\" form (.e. using variable_name, value, unit columns observation table). \"flat\" format \"widest\" L1 hymetDP dataset can consistently spread due frequent occurrence L0 source datasets > 1 core observation variable.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/define_variable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Define a hymetDP variable — define_variable","text":"","code":"flat <- hymet_L0_flat[1:9]  flat <- hymetDP::define_variable(   L0_flat = flat,   local_variable_column = \"variable_name\",   local_variable = \"DSCHRGE_RATE\",   variable_name = \"Discharge\",   variable_units = \"liters per second\",   sample_medium = \"Surface water\",   value_type = \"Derived Value\",   is_regular = TRUE,   time_support = 15,   time_units = \"minute\",   data_type = \"Continuous\",   general_category = \"Hydrology\",   no_data = -9999) #> Error in dplyr::mutate(., VariableCode = dplyr::coalesce(VariableCode.x,     VariableCode.y), VariableName = dplyr::coalesce(VariableName.x,     VariableName.y), VariableUnitsName = dplyr::coalesce(VariableUnitsName.x,     VariableUnitsName.y), SampleMedium = dplyr::coalesce(SampleMedium.x,     SampleMedium.y), ValueType = dplyr::coalesce(ValueType.x,     ValueType.y), IsRegular = dplyr::coalesce(IsRegular.x, IsRegular.y),     TimeSupport = dplyr::coalesce(TimeSupport.x, TimeSupport.y),     TimeUnitsName = dplyr::coalesce(TimeUnitsName.x, TimeUnitsName.y),     DataType = dplyr::coalesce(DataType.x, DataType.y), GeneralCategory = dplyr::coalesce(GeneralCategory.x,         GeneralCategory.y), NoDataValue = dplyr::coalesce(NoDataValue.x,         NoDataValue.y)): Problem while computing `VariableName = dplyr::coalesce(VariableName.x, #> VariableName.y)`. #> Caused by error in `list2()`: #> ! object 'VariableName.x' not found"},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_sitetype.html","id":null,"dir":"Reference","previous_headings":"","what":"Get USGS site type — get_usgs_sitetype","title":"Get USGS site type — get_usgs_sitetype","text":"Get USGS site type","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_sitetype.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get USGS site type — get_usgs_sitetype","text":"","code":"get_usgs_sitetype(s)"},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_sitetype.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get USGS site type — get_usgs_sitetype","text":"s (character) USGS site type code site_type_cd","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_sitetype.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get USGS site type — get_usgs_sitetype","text":"Site type","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_variable.html","id":null,"dir":"Reference","previous_headings":"","what":"Get USGS variable information — get_usgs_variable","title":"Get USGS variable information — get_usgs_variable","text":"Get USGS variable information","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_variable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get USGS variable information — get_usgs_variable","text":"","code":"get_usgs_variable(p)"},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_variable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get USGS variable information — get_usgs_variable","text":"p (character) USGS parameter code param","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/get_usgs_variable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get USGS variable information — get_usgs_variable","text":"Information associated USGS variable","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L0_flat.html","id":null,"dir":"Reference","previous_headings":"","what":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"fully joined flat version EDI data package knb-lter-mcm.9003.11 (Seasonal high-frequency measurements discharge, water temperature, specific conductivity Andersen Creek H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing)) relevant hymetDP L1 identifiers content added. Use dataset input L0_flat argument \"create\" functions.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L0_flat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"","code":"hymet_L0_flat"},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L0_flat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"data frame 30,000 rows 45 variables: LocalDateTime Local datetime UTCOffset Local timezone offset UTC DateTimeUTC Datetime UTC Variable_name Variable name L0 dataset DataValue Numeric value observation Qualifier Code qualifier (flag) Unit Unit name L0 dataset ValueID data value ID VariableCode variable ID VariableName ODM CV variable name VariableUnitsName ODM CV unit name variable SampleMedium ODM CV sample medium name ValueType ODM CV value type IsRegular Whether values regularly sampled dataset TimeSupport Temporal footprint samples TimeUnitsName ODM CV unit name time support DataType ODM CV data type GeneralCategory ODM CV general category NoDataValue numeric value used encode available data MethodCode method ID MethodDescription description method SiteCode site ID SiteName name site Latitude Latitude site Longitude Longitude site Elevation_m Elevation site meters LatLongDatumSRSName Spatial reference system latitude longitude coordinates SiteType ODM CV site type Organization Name organization collected data ContactName Name contact person data source Email Email contact SourceCode source ID SourceDescription description source data SourceLink URL source data Citation Citation source data Phone Contact phone Address Contact physical address City Contact city State Contact state US, otherwise full country name ZipCode Contact postal code QualityControlLevelCode quality control ID Definition Definition quality control level Explanation Explanation quality control level QualifierCode qualifier ID QualifierDescription Description qualifier","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L0_flat.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Joined and flat version of EDI data package knb-lter-mcm.9003.11 — hymet_L0_flat","text":"https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-mcm&identifier=9003&revision=11","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L1.html","id":null,"dir":"Reference","previous_headings":"","what":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"hymetDP (L1) formatted version EDI data package knb-lter-mcm.9003.11 (Seasonal high-frequency measurements discharge, water temperature, specific conductivity Andersen Creek H1, McMurdo Dry Valleys, Antarctica (1993-2020, ongoing)) produced table hymet_L0_flat. Use dataset input data \"use\" functions.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"","code":"hymet_L1"},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"list : id dataset identifier metadata See source url metadata tables list data frames, ecocomDP table","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/hymet_L1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"The hymetDP (L1) version of EDI data package knb-lter-mcm.9003.11 — hymet_L1","text":"hymet_L0_flat","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://kzollove.github.io/hymetDP/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Read published data — read_data","title":"Read published data — read_data","text":"Read published data","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read published data — read_data","text":"","code":"read_data(   id = NULL,   parse_datetime = TRUE,   unique_keys = FALSE,   from = NULL,   format = \"new\" )"},{"path":"https://kzollove.github.io/hymetDP/reference/read_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read published data — read_data","text":"id (character) Identifier dataset read. Identifiers listed \"id\" column search_data() output. Older versions datasets can read, warning issued. parse_datetime (logical) Parse datetime values TRUE, otherwise return character strings. unique_keys (logical) Whether create globally unique primary keys (associated foreign keys). Useful maintaining referential integrity working multiple datasets. TRUE, id appended table's primary key associated foreign key. Default FALSE. (character) Full path file read (.rds), path directory containing saved datasets (.csv). format (character) Format returned object, can : \"new\" (new implementation) \"old\" (original implementation; deprecated). new format, top level nesting containing \"id\" field moved level \"tables\", \"metadata\", \"validation_issues\" fields.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read published data — read_data","text":"(list) dataset structure: id - Dataset identifier metadata - List info dataset. NOTE: object underdevelopment content may change future releases. tables - List dataset tables data.frames. validation_issues - List validation issues. dataset fails validation checks, descriptions issue listed .","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read published data — read_data","text":"","code":"Validation checks are applied to each dataset ensuring it complies with the hymetDP model. A warning is issued when any validation checks fail. All datasets are returned, even if they fail validation.  Column classes are coerced to those defined in the hymetDP specification.  Validation happens each time files are read, from source APIs or local environments."},{"path":"https://kzollove.github.io/hymetDP/reference/read_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Read published data — read_data","text":"function may work 01:00 - 03:00 UTC Wednesdays due regular maintenance EDI Data Repository.","code":""},{"path":[]},{"path":"https://kzollove.github.io/hymetDP/reference/read_data_package_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data package report — read_data_package_report","title":"Read data package report — read_data_package_report","text":"Read data package report","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_data_package_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data package report — read_data_package_report","text":"","code":"read_data_package_report(packageId, frmt = \"xml\", env = \"production\")"},{"path":"https://kzollove.github.io/hymetDP/reference/read_data_package_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data package report — read_data_package_report","text":"packageId (character) Data package identifier frmt (character) Format returned report. Can : \"xml\", \"html\", \"char\". env (character) Repository environment. Can : \"production\", \"staging\", \"development\".","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_data_package_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data package report — read_data_package_report","text":"(xml_document) Data package report","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_data_package_report.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read data package report — read_data_package_report","text":"","code":"# Read as XML qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\") qualityReport #> {xml_document} #> <qualityReport schemaLocation=\"eml://ecoinformatics.org/qualityReport https://raw.githubusercontent.com/PASTAplus/PASTA/master/DataPackageManager/WebRoot/xml/qualityReportSchema.xsd\" xmlns=\"eml://ecoinformatics.org/qualityReport\" xmlns:qr=\"eml://ecoinformatics.org/qualityReport\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> #>  [1] <creationDate>2020-02-04T16:38:38<\/creationDate> #>  [2] <packageId>knb-lter-knz.260.4<\/packageId> #>  [3] <includeSystem>lter<\/includeSystem> #>  [4] <includeSystem>knb<\/includeSystem> #>  [5] <datasetReport>\\n  <qualityCheck qualityType=\"metadata\" system=\"lter\" st ... #>  [6] <entityReport>\\n  <entityName>GIS600<\/entityName>\\n  <qualityCheck quali ... #>  [7] <entityReport>\\n  <entityName>KMZGIS600<\/entityName>\\n  <qualityCheck qu ... #>  [8] <entityReport>\\n  <entityName>GIS605<\/entityName>\\n  <qualityCheck quali ... #>  [9] <entityReport>\\n  <entityName>KMZGIS605<\/entityName>\\n  <qualityCheck qu ... #> [10] <entityReport>\\n  <entityName>GIS610<\/entityName>\\n  <qualityCheck quali ... #> [11] <entityReport>\\n  <entityName>KMZGIS610<\/entityName>\\n  <qualityCheck qu ... #> [12] <entityReport>\\n  <entityName>GIS615<\/entityName>\\n  <qualityCheck quali ... #> [13] <entityReport>\\n  <entityName>KMZGIS615<\/entityName>\\n  <qualityCheck qu ... #> [14] <entityReport>\\n  <entityName>GIS620<\/entityName>\\n  <qualityCheck quali ... #> [15] <entityReport>\\n  <entityName>KMZGIS620<\/entityName>\\n  <qualityCheck qu ... #> [16] <entityReport>\\n  <entityName>GIS630<\/entityName>\\n  <qualityCheck quali ... #> [17] <entityReport>\\n  <entityName>KMZGIS630<\/entityName>\\n  <qualityCheck qu ... #> [18] <entityReport>\\n  <entityName>GIS635<\/entityName>\\n  <qualityCheck quali ... #> [19] <entityReport>\\n  <entityName>KMZGIS635<\/entityName>\\n  <qualityCheck qu ...  # Read as HTML qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\", frmt = \"html\") qualityReport #> {html_document} #> <html> #> [1] <body><table xmlns:qr=\"eml://ecoinformatics.org/qualityReport\"><tbody>\\n< ...  # Read as character qualityReport <- read_data_package_report(\"knb-lter-knz.260.4\", frmt = \"char\") #> Error in report2char(xml2::read_xml(res), env = env): could not find function \"report2char\" # writeLines(qualityReport, \"./data/report.txt\"))"},{"path":"https://kzollove.github.io/hymetDP/reference/read_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Read data tables of a data package — read_tables","title":"Read data tables of a data package — read_tables","text":"Read data tables data package EML metadata.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read data tables of a data package — read_tables","text":"","code":"read_tables(   eml,   strip.white = FALSE,   na.strings = NULL,   convert.missing.value = NULL,   add.units = FALSE )"},{"path":"https://kzollove.github.io/hymetDP/reference/read_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read data tables of a data package — read_tables","text":"eml (xml_document, xml_node) EML metadata returned read_eml(). strip.white (logical) Strips leading trailing whitespaces unquoted fields. Default FALSE. na.strings (character) Strings interpreted NA. Setting na.strings = \"\" converts \"\" NA. default, blank strings \"\" read . convert.missing.value (logical) Converts missing value codes specified eml (e.g. \"-99999\", \"NaN\", \"measured\") NA. Missing value codes vary across data packages converting consistent form recognized R makes downstream use simpler. However, care must exercised using argument. author dataset described eml may defined \"missing value code\" mean something different expect (e.g. \"detection limit\") therefore reviewing authors missing value code definitions good idea. Default FALSE. add.units (logical) TRUE, variable's unit measurement added table separate column column name form: <unit>_<variable_name>. argument useful gathering variables long (attribute-value) table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read data tables of a data package — read_tables","text":"(list) List named data frames","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/read_tables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read data tables of a data package — read_tables","text":"","code":"This function uses \\code{data.table::fread()} and uses default argument values if the EML based values return an error.  Default settings preserve the form the data were originally published in."},{"path":"https://kzollove.github.io/hymetDP/reference/read_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read data tables of a data package — read_tables","text":"","code":"eml <- EDIutils::read_metadata('knb-lter-mcm.9003.11')  tables <- read_tables(   eml = eml,   strip.white = TRUE,   na.strings = \"\",   convert.missing.value = TRUE,   add.units = TRUE)"},{"path":"https://kzollove.github.io/hymetDP/reference/return_close.html","id":null,"dir":"Reference","previous_headings":"","what":"Return values from the CV that may be close to users' term — return_close","title":"Return values from the CV that may be close to users' term — return_close","text":"Return values CV may close users' term","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/return_close.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return values from the CV that may be close to users' term — return_close","text":"","code":"return_close(term, cv)"},{"path":"https://kzollove.github.io/hymetDP/reference/return_close.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return values from the CV that may be close to users' term — return_close","text":"term (character) user-provided term needs validated cv (character) \"Term\" column corresponding CV","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/return_close.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return values from the CV that may be close to users' term — return_close","text":"(list) Named list CV entries contain string","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/template_hymet.html","id":null,"dir":"Reference","previous_headings":"","what":"Template create_hymetDP.R script — template_hymet","title":"Template create_hymetDP.R script — template_hymet","text":"Template create_hymetDP.R script","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/template_hymet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Template create_hymetDP.R script — template_hymet","text":"","code":"template_hymet(path, dir.name)"},{"path":"https://kzollove.github.io/hymetDP/reference/template_hymet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Template create_hymetDP.R script — template_hymet","text":"path (character) Path new directory created dir.name (character) Name new directory contain create_hymetDP.R script","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/template_hymet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Template create_hymetDP.R script — template_hymet","text":"Empty create_hymetDP.R script.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/template_hymet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Template create_hymetDP.R script — template_hymet","text":"","code":"if (FALSE) { template_hymet(tempdir(), 'my_hymet') }"},{"path":"https://kzollove.github.io/hymetDP/reference/validate_arguments.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate arguments of hymetDP functions — validate_arguments","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"Validate input arguments to hymetDP functions."},{"path":"https://kzollove.github.io/hymetDP/reference/validate_arguments.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"validate_arguments(fun.name, fun.args)"},{"path":"https://kzollove.github.io/hymetDP/reference/validate_arguments.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate arguments of hymetDP functions — validate_arguments","text":"fun.name (character) Name function validate_arguments() called. fun.args (named list) Arguments passed calling function formatted .list(environment()).","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/validate_arguments.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate arguments of hymetDP functions — validate_arguments","text":"","code":"Validation checks are function specific."},{"path":"https://kzollove.github.io/hymetDP/reference/validate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate tables against the model — validate_data","title":"Validate tables against the model — validate_data","text":"Validate tables model","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/validate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate tables against the model — validate_data","text":"","code":"validate_data(dataset = NULL, path = NULL)"},{"path":"https://kzollove.github.io/hymetDP/reference/validate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate tables against the model — validate_data","text":"dataset (list) dataset structure returned read_data(). path (character) Path directory containing hymetDP tables files.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/validate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate tables against the model — validate_data","text":"(list) checks fail, list validation issues returned along warning. issues found NULL returned.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/validate_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate tables against the model — validate_data","text":"Validation checks: File names - File names hymetDP table names. Table presence - Required tables present. Column names - Column names tables match model. Column presence - Required columns present. Column classes - Column classes match model specification. Datetime format - Date time formats follow model specification. Primary keys - Primary keys tables unique. Composite keys - Composite keys (unique constraints) table unique. Referential integrity - Foreign keys corresponding primary key. Coordinate format - Values decimal degree format. Coordinate range - Values within -90 90 -180 180. Elevation - Values less Mount Everest (8848 m) greater Mariana Trench (-10984 m). CV Terms - Terms used valid ODM controlled vocabulary terms, required.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/validate_data.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Validate tables against the model — validate_data","text":"function used hymetDP creators (ensure created valid), maintainers (improve quality archived hymetDP datasets), users (ensure data used free error).","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/validate_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate tables against the model — validate_data","text":"","code":"if (FALSE) { # Write a set of hymetDP tables to file for validation  mydir <- paste0(tempdir(), \"/dataset\") dir.create(mydir) write_tables(   path = mydir,   DataValues = hymet_L1$tables$DataValues,   Methods = hymet_L1$tables$Methods,   Variables = hymet_L1$tables$Variables,   Sources = hymet_L1$tables$Sources,   Sites = hymet_L1$tables$Sites,   QualityControlLevels = hymet_L1$tables$QualityControlLevels,   Qualifiers = hymet_L1$tables$Qualifiers,   SeriesCatalog = hymet_L1$tables$SeriesCatalog)  # Validate validate_data(path = mydir)  # Clean up unlink(mydir, recursive = TRUE) }"},{"path":"https://kzollove.github.io/hymetDP/reference/validate_odm_terms.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"Validate input arguments to hymetDP functions that should have direct matches to terms in CUAHSI ODM CVs."},{"path":"https://kzollove.github.io/hymetDP/reference/validate_odm_terms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"validate_odm_terms(fun.name, fun.args)"},{"path":"https://kzollove.github.io/hymetDP/reference/validate_odm_terms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"fun.name (character) Name function validate_omd_terms() called. fun.args (named list) Arguments passed calling function formatted .list(environment()).","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/validate_odm_terms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate arguments of hymetDP functions that should be using CUAHSI ODM CV terms — validate_odm_terms","text":"","code":"Validation checks are function specific."},{"path":"https://kzollove.github.io/hymetDP/reference/write_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Write tables to file — write_tables","title":"Write tables to file — write_tables","text":"Write tables file","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/write_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write tables to file — write_tables","text":"","code":"write_tables(   path,   sep = \",\",   DataValues = NULL,   Variables = NULL,   Methods = NULL,   Sources = NULL,   Sites = NULL,   QualityControlLevels = NULL,   SeriesCatalog = NULL,   Qualifiers = NULL )"},{"path":"https://kzollove.github.io/hymetDP/reference/write_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write tables to file — write_tables","text":"path (character) path directory files written. sep (character) Field delimiter use writing files. Default comma. DataValues (tbl_df, tbl, data.frame) DataValues table. Variables (tbl_df, tbl, data.frame) Variables table. Methods (tbl_df, tbl, data.frame) Methods table. Sources (tbl_df, tbl, data.frame) Sources table. Sites (tbl_df, tbl, data.frame) Sites table. QualityControlLevels (tbl_df, tbl, data.frame) QualityControlLevels table. SeriesCatalog (tbl_df, tbl, data.frame) SeriesCatalog table.","code":""},{"path":"https://kzollove.github.io/hymetDP/reference/write_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write tables to file — write_tables","text":"hymetDP tables sep delimited files","code":""},{"path":[]}]
